{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case txp\n",
    "\n",
    "> In this case study, we are exploring deep learning interpretability on BSI prognosis, before, during and after training a CNN model on multi-variate time series medical record.\n",
    " \n",
    "> we use hourly aggregated physiological data and lab results from 10,000 ICU patients. 1824 positive events and 31496 control group events are generated from the population. \n",
    "\n",
    "> we use 25 features selected by domain knowledge, 96 hours prior to the blood culture acquisition to classify positive test results from the control group -- negative test results and 4 days of randomly sliced baseline patient data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import FAIRStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Querier has initiated a csv source dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd/meta_data/csv_source_dict_demo.json\n",
      "Success: Querier has initiated a variable dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd/meta_data/variable_dict_demo.json\n",
      "Unable to read sql source dictionary. Use Querier.update_sql_source_dict() to build one.\n",
      "{'__uid': {'src_names': ['id', 'ID', 'subject_id', 'subject_id', 'oldid'], 'label': 'subject id', 'unique_per_sbj': True}, '__time': {'src_names': ['tsa', 'timeMinutes'], 'label': 'Time since admission', 'unit': 'minute'}, '__anchor': {'src_names': ['True_positive', 'True positive', 'label'], 'label': 'episode anchor', 'unique_per_sbj': False, 'factor': {'levels': {'__nbc': ['nan'], '__ctm': ['contaminant'], '__neg': ['0', '0.0', 'negative'], '__pos': ['1', '1.0', 'true_positive']}, 'impute_per_sbj': {'nan_level': '__nbc'}}}, 'y': {'output': True, 'src_names': ['True_positive', 'True positive', 'label'], 'label': 'Blood culture result', 'unique_per_sbj': False, 'factor': {'levels': {'nbc': ['nan'], 'ctm': ['contaminant'], 'neg': ['0', '0.0', 'negative'], 'pos': ['1', '1.0', 'true_positive']}, 'impute_per_sbj': {'nan_level': 'nbc'}}}, 'age': {'input': True, 'src_names': ['age', 'AGE'], 'label': 'Age', 'unique_per_sbj': True, 'numeric': {'scaler': 'none', 'unit': 'year', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 110}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'albumin': {'input': True, 'src_names': ['Albumin', 'ALBUMIN', 'albumin'], 'label': 'Albumin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 5}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'alp': {'input': True, 'src_names': ['ALKALINE.PHOSPHATASE', 'ALP', 'alp'], 'label': 'ALP', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 800}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'alt': {'input': True, 'src_names': ['ALT.GPT', 'ALT', 'alt'], 'label': 'ALT', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 1085}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'ast': {'input': True, 'src_names': ['AST.GOT', 'AST', 'ast'], 'label': 'AST', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 1300}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'bicarbonate': {'input': True, 'src_names': ['bicarbonate', 'BICARBONATE'], 'label': 'Bicarbonate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 60}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'bun': {'input': True, 'src_names': ['BLOOD.UREA.NITROGEN', 'BUN', 'bun'], 'label': 'BUN', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 150}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'calcium': {'input': True, 'src_names': ['CALCIUM', 'Calcium', 'calcium'], 'label': 'Calcium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 4, 'value_max': 15}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'chloride': {'input': True, 'src_names': ['CHLORIDE', 'Chloride', 'chloride'], 'label': 'Chloride', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 50, 'value_max': 140}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'co2': {'input': True, 'src_names': ['CO2', 'co2'], 'label': 'CO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 40}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'creatinine': {'input': True, 'src_names': ['CREATININE', 'Creatinine', 'creatinine'], 'label': 'Creatinine', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'dbp': {'input': True, 'src_names': ['DBP', 'diasbp', 'dbp'], 'label': 'subject diastolic blood pressure', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'mm Hg', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 20, 'value_max': 150}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'fio2_pct': {'input': True, 'src_names': ['FIO2', 'fio2_pct'], 'label': 'FIO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 100}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'glucose': {'input': True, 'src_names': ['GLUCOSE', 'Glucose', 'glucose'], 'label': 'Glucose', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 40, 'value_max': 500}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'hematocrit': {'input': True, 'src_names': ['HEMATOCRIT', 'hematocrit'], 'label': 'Hematocrit', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 10, 'value_max': 60}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'hemoglobin': {'input': True, 'src_names': ['HEMOGLOBIN', 'hemoglobin'], 'label': 'Hemoglobin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 20}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'heart_rate': {'input': True, 'src_names': ['hr', 'heartrate'], 'label': 'Heart rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'beats per minute', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 10, 'value_max': 200}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'lactic_acid': {'input': True, 'src_names': ['LACTIC.ACID', 'lactic_acid'], 'label': 'Lactic Acid', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 19.1}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'magnesium': {'input': True, 'src_names': ['MAGNESIUM', 'Magnesium', 'magnesium'], 'label': 'Magnesium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 5}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'o2_flow': {'input': True, 'src_names': ['o2_flow', 'O2.Flow'], 'label': 'O2 Flow', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 80}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'pco2': {'input': True, 'src_names': ['PCO2', 'PaCO2', 'pco2'], 'label': 'PCO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 110}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'peep': {'input': True, 'src_names': ['peep', 'PEEP'], 'label': 'peep', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 40}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'ph_arterial': {'input': True, 'src_names': ['ph_arterial', 'PH.ARTERIAL'], 'label': 'PH in Arterial', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 6.5, 'value_max': 8}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'phosphorus': {'input': True, 'src_names': ['PHOSPHORUS', 'phosphorus'], 'label': 'Phosphorus', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'po2': {'input': True, 'src_names': ['po2', 'PO2'], 'label': 'PO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 650}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'potassium': {'input': True, 'src_names': ['POTASSIUM', 'Potassium', 'potassium'], 'label': 'Potassium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 9}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'protime_inr': {'input': True, 'src_names': ['PROTIME.INR', 'protime_inr'], 'label': 'Protime INR', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 5}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'ptt': {'input': True, 'src_names': ['PARTIAL.THROMBOPLASTIN.TIME', 'PTT', 'ptt'], 'label': 'partial_thromboplastin_time', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 140}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'platelet_count': {'input': True, 'src_names': ['platelet', 'PLATELET.COUNT', 'plateletcount'], 'label': 'platelet count', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 1000}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'resp_rate': {'input': True, 'src_names': ['rr', 'resprate'], 'label': 'subject respiratory rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 70}, 'unit': 'mm Hg', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'sbp': {'input': True, 'src_names': ['SBP', 'sysbp', 'sbp'], 'label': 'subject systolic blood pressure', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'mm Hg', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 40, 'value_max': 250}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'sodium': {'input': True, 'src_names': ['SODIUM', 'Sodium', 'sodium'], 'label': 'Sodium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 100, 'value_max': 180}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'spo2': {'input': True, 'src_names': ['so2', 'spo2'], 'label': 'SpO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 100}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'temp': {'input': True, 'src_names': ['Temp', 'temp'], 'label': 'Temperature', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'Fahrenheit', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 80, 'value_max': 104}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'total_bilirubin': {'input': True, 'src_names': ['TOTAL.BILIRUBIN', 'bilirubin', 'total_bilirubin'], 'label': 'Total Bilirubin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 50}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'total_protein': {'input': True, 'src_names': ['total_protein', 'TOTAL.PROTEIN'], 'label': 'Total Protein', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 2, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'txp': {'input': True, 'src_names': ['Confirmed Txp', 'txp'], 'label': 'Transplant recipient', 'unique_per_sbj': True, 'factor': {'levels': {'no': ['0', '0.0', 'nan'], 'yes': ['1', '1.0', 'yes']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'troponin': {'input': True, 'src_names': ['TROPONIN.I', 'Troponin', 'troponin'], 'label': 'Troponin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 30}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'wbc': {'input': True, 'src_names': ['WHITE.BLOOD.CELL.COUNT', 'WBC', 'wbc'], 'label': 'WBC', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 50}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'gram_positive': {'input': False, 'src_names': ['GP', 'Gram positive', 'gram_positive'], 'label': 'Gram Positive', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'gram_negative': {'input': False, 'src_names': ['GN', 'Gram negative', 'gram_negative'], 'label': 'Gram Negative', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'fungus': {'input': False, 'src_names': ['fungus', 'Fungus', 'fungal'], 'label': 'Fungus', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'mycobacterial': {'input': False, 'src_names': ['mycobacterial', 'mycobacteria', 'Mycobacterial'], 'label': 'Mycobacterial', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'x_hr_rr': {'src_names': ['x.hr.rr'], 'label': 'cross correlation between HR and resp_rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'x_hr_spo2': {'src_names': ['x.hr.spo2'], 'label': 'cross correlation between HR and spo2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'x_rr_spo2': {'src_names': ['x.hr.spo2'], 'label': 'cross correlation between resp_rate and spo2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 's_hr': {'src_names': ['s.hr'], 'label': 'HR sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 's_rr': {'src_names': ['s.rr'], 'label': 'resp_rate sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 's_so2': {'src_names': ['s.so2'], 'label': 'SPO2 sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}, 'o2sat': {'src_names': ['OXYGEN_SATURATION'], 'label': 'Oxygen Satuation', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 17.6}, 'unit': '', 'impute_per_sbj': {'forward': 5760, 'backward': 0}}}}\n",
      "{'uva': {'vital': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/bsi_old_deidentified_final.csv', 'info': 'Vital signs data from UVA'}, 'lab': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/uva_lab.csv', 'info': 'Lab results data from UVA'}}, 'uvaold': {'all': {'include': True, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2011_2015/data_ml/bsi_old_final.csv', 'info': 'Data from UVA 2011 - 2015 '}}, 'uvanewbc': {'all': {'include': False, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2016_2021/data_ml/bsi_new_deidentified_bc.csv', 'info': 'Data from UVA 2017 - 2021 (cohort who have at least one blood culture )'}}, 'uvanewnbc': {'all': {'include': False, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2016_2021/data_ml/bsi_new_deidentified_nbc.csv', 'info': 'Data from UVA 2017 - 2021 (cohort who have non blood culture)'}}, 'mimic': {'vital': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/mimic_patient_data_minutes.csv', 'info': 'Vital signs data from MIMIC'}, 'lab': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/mimic_labs_minutes_combined.csv', 'info': 'Lab results data from MIMIC'}}}\n"
     ]
    }
   ],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd'\n",
    "\n",
    "# initiate dataframe to return\n",
    "all_df=None\n",
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "print(bsi_stream.engineer.variable_dict)\n",
    "print(bsi_stream.engineer.csv_source_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.querier.create_csv_pool(csv_pool_dir = csv_pool_path,\n",
    "#                                   source_key=\"uvanewbc\",\n",
    "#                                   file_key=\"all\",\n",
    "#                                   sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.querier.create_csv_pool(csv_pool_dir = csv_pool_path,\n",
    "#                                   source_key=\"uvanewnbc\",\n",
    "#                                   file_key=\"all\",\n",
    "#                                   sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nbc (baseline) group \n",
    "# # define an episode (notice that the engineer now has new attributes)\n",
    "# bsi_stream.engineer.DefineEpisode(input_time_len=1*60, # using vital signs and labs 4 days prior to a culture \n",
    "#                                   output_time_len=(4*24-1)*60, # predict one time unit into the future\n",
    "#                                   time_resolution=60, # aggregate minutely data to one row per hour \n",
    "#                                   time_lag=0,  # no time lag between predictors and response\n",
    "#                                   anchor_gap=4*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Engineer has updated attributes --- episode. \n"
     ]
    }
   ],
   "source": [
    "# bc group \n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=2*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=2*24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = pd.read_csv(\"/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2016_2021/data_ml/bsi_new_deidentified_bc.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineer is sampling without replacement --- \n",
      "-- __time fixed\n",
      "-- __anchor fixed\n",
      "-- y fixed\n",
      "--- fix upper boundary for age by 90.0\n",
      "--- fix lower boundary for age by 18.04\n",
      "-- age fixed\n",
      "--- fix upper boundary for albumin by 5.0\n",
      "--- fix lower boundary for albumin by 1.2\n",
      "-- albumin fixed\n",
      "--- fix upper boundary for alp by 396.0\n",
      "--- fix lower boundary for alp by 29.0\n",
      "-- alp fixed\n",
      "--- fix upper boundary for alt by 1085.0\n",
      "--- fix lower boundary for alt by 6.0\n",
      "-- alt fixed\n",
      "--- fix upper boundary for ast by 1300.0\n",
      "--- fix lower boundary for ast by 9.0\n",
      "-- ast fixed\n",
      "--- fix upper boundary for bicarbonate by 60.0\n",
      "--- fix lower boundary for bicarbonate by 5.3\n",
      "-- bicarbonate fixed\n",
      "--- fix upper boundary for bun by 150.0\n",
      "--- fix lower boundary for bun by 2.0\n",
      "-- bun fixed\n",
      "--- fix upper boundary for calcium by 13.6\n",
      "--- fix lower boundary for calcium by 5.2\n",
      "-- calcium fixed\n",
      "--- fix upper boundary for chloride by 136.0\n",
      "--- fix lower boundary for chloride by 73.0\n",
      "-- chloride fixed\n",
      "--- fix upper boundary for co2 by 40.0\n",
      "--- fix lower boundary for co2 by 7.0\n",
      "-- co2 fixed\n",
      "--- fix upper boundary for creatinine by 10.0\n",
      "--- fix lower boundary for creatinine by 0.2\n",
      "-- creatinine fixed\n",
      "--- fix upper boundary for dbp by 150.0\n",
      "--- fix lower boundary for dbp by 26.0\n",
      "-- dbp fixed\n",
      "--- fix upper boundary for fio2_pct by 100.0\n",
      "--- fix lower boundary for fio2_pct by 21.0\n",
      "-- fio2_pct fixed\n",
      "--- fix upper boundary for glucose by 500.0\n",
      "--- fix lower boundary for glucose by 40.76425\n",
      "-- glucose fixed\n",
      "--- fix upper boundary for hematocrit by 57.0\n",
      "--- fix lower boundary for hematocrit by 14.4\n",
      "-- hematocrit fixed\n",
      "--- fix upper boundary for hemoglobin by 18.8882500000007\n",
      "--- fix lower boundary for hemoglobin by 4.7\n",
      "-- hemoglobin fixed\n",
      "--- fix upper boundary for heart_rate by 200.0\n",
      "--- fix lower boundary for heart_rate by 30.0\n",
      "-- heart_rate fixed\n",
      "--- fix upper boundary for lactic_acid by 19.1\n",
      "--- fix lower boundary for lactic_acid by 0.3\n",
      "-- lactic_acid fixed\n",
      "--- fix upper boundary for magnesium by 5.0\n",
      "--- fix lower boundary for magnesium by 0.9\n",
      "-- magnesium fixed\n",
      "--- fix upper boundary for o2_flow by 80.0\n",
      "--- fix lower boundary for o2_flow by 0.0\n",
      "-- o2_flow fixed\n",
      "--- fix upper boundary for pco2 by 110.0\n",
      "--- fix lower boundary for pco2 by 16.26635\n",
      "-- pco2 fixed\n",
      "--- fix upper boundary for peep by 40.0\n",
      "--- fix lower boundary for peep by 0.0\n",
      "-- peep fixed\n",
      "--- fix upper boundary for ph_arterial by 7.593\n",
      "--- fix lower boundary for ph_arterial by 7.138\n",
      "-- ph_arterial fixed\n",
      "--- fix upper boundary for phosphorus by 10.0\n",
      "--- fix lower boundary for phosphorus by 1.0\n",
      "-- phosphorus fixed\n",
      "--- fix upper boundary for po2 by 569.7599\n",
      "--- fix lower boundary for po2 by 18.90365\n",
      "-- po2 fixed\n",
      "--- fix upper boundary for potassium by 7.4\n",
      "--- fix lower boundary for potassium by 2.2\n",
      "-- potassium fixed\n",
      "--- fix upper boundary for protime_inr by 5.0\n",
      "--- fix lower boundary for protime_inr by 0.8\n",
      "-- protime_inr fixed\n",
      "--- fix upper boundary for ptt by 140.0\n",
      "--- fix lower boundary for ptt by 20.1\n",
      "-- ptt fixed\n",
      "--- fix upper boundary for platelet_count by 1000.0\n",
      "--- fix lower boundary for platelet_count by 2.0\n",
      "-- platelet_count fixed\n",
      "--- fix upper boundary for resp_rate by 70.0\n",
      "--- fix lower boundary for resp_rate by 5.5\n",
      "-- resp_rate fixed\n",
      "--- fix upper boundary for sbp by 250.0\n",
      "--- fix lower boundary for sbp by 40.0\n",
      "-- sbp fixed\n",
      "--- fix upper boundary for sodium by 167.78630000000098\n",
      "--- fix lower boundary for sodium by 112.0\n",
      "-- sodium fixed\n",
      "--- fix upper boundary for spo2 by 100.0\n",
      "--- fix lower boundary for spo2 by 79.0\n",
      "-- spo2 fixed\n",
      "--- fix upper boundary for temp by 104.0\n",
      "--- fix lower boundary for temp by 80.0\n",
      "-- temp fixed\n",
      "--- fix upper boundary for total_bilirubin by 46.6935\n",
      "--- fix lower boundary for total_bilirubin by 0.1\n",
      "-- total_bilirubin fixed\n",
      "--- fix upper boundary for total_protein by 9.2\n",
      "--- fix lower boundary for total_protein by 2.4\n",
      "-- total_protein fixed\n"
     ]
    }
   ],
   "source": [
    "# Build MVTS dataframe or tfds from external table object!!!\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              nsbj = 50, # number of subjects / patients to sample from the pool \n",
    "                              replace = False, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='none', # imputation on predictors\n",
    "                              impute_output='none',# imputation on response (no need in BSI project)\n",
    "                              sep=\"_\", \n",
    "                              return_episode=True,\n",
    "                              df_raw=df_bc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Engineer has updated attributes --- episode. \n"
     ]
    }
   ],
   "source": [
    "## bc group \n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=2*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=2*24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineer is sampling without replacement --- \n",
      "50---out of---9954---subjects are sampled from csv pool of size---61865\n",
      "-- __time fixed\n",
      "-- __anchor fixed\n",
      "-- y fixed\n",
      "--- fix upper boundary for age by 90.0\n",
      "--- fix lower boundary for age by 19.92191\n",
      "-- age fixed\n",
      "--- fix upper boundary for albumin by 4.9\n",
      "--- fix lower boundary for albumin by 1.3\n",
      "-- albumin fixed\n",
      "--- fix upper boundary for alp by 800.0\n",
      "--- fix lower boundary for alp by 26.0\n",
      "-- alp fixed\n",
      "--- fix upper boundary for alt by 547.0\n",
      "--- fix lower boundary for alt by 7.0\n",
      "-- alt fixed\n",
      "--- fix upper boundary for ast by 1053.0\n",
      "--- fix lower boundary for ast by 11.0\n",
      "-- ast fixed\n",
      "--- fix upper boundary for bicarbonate by 60.0\n",
      "--- fix lower boundary for bicarbonate by 7.9\n",
      "-- bicarbonate fixed\n",
      "--- fix upper boundary for bun by 121.0\n",
      "--- fix lower boundary for bun by 3.0\n",
      "-- bun fixed\n",
      "--- fix upper boundary for calcium by 10.5\n",
      "--- fix lower boundary for calcium by 5.9\n",
      "-- calcium fixed\n",
      "--- fix upper boundary for chloride by 125.0\n",
      "--- fix lower boundary for chloride by 84.0\n",
      "-- chloride fixed\n",
      "--- fix upper boundary for co2 by 40.0\n",
      "--- fix lower boundary for co2 by 5.0\n",
      "-- co2 fixed\n",
      "--- fix upper boundary for creatinine by 5.7\n",
      "--- fix lower boundary for creatinine by 0.4\n",
      "-- creatinine fixed\n",
      "--- fix upper boundary for dbp by 150.0\n",
      "--- fix lower boundary for dbp by 20.0\n",
      "-- dbp fixed\n",
      "--- fix upper boundary for fio2_pct by 100.0\n",
      "--- fix lower boundary for fio2_pct by 21.0\n",
      "-- fio2_pct fixed\n",
      "--- fix upper boundary for glucose by 500.0\n",
      "--- fix lower boundary for glucose by 49.0\n",
      "-- glucose fixed\n",
      "--- fix upper boundary for hematocrit by 58.0\n",
      "--- fix lower boundary for hematocrit by 19.9\n",
      "-- hematocrit fixed\n",
      "--- fix upper boundary for hemoglobin by 19.7\n",
      "--- fix lower boundary for hemoglobin by 6.3\n",
      "-- hemoglobin fixed\n",
      "--- fix upper boundary for heart_rate by 162.3547\n",
      "--- fix lower boundary for heart_rate by 43.00333\n",
      "-- heart_rate fixed\n",
      "--- fix upper boundary for lactic_acid by 12.7\n",
      "--- fix lower boundary for lactic_acid by 0.5\n",
      "-- lactic_acid fixed\n",
      "--- fix upper boundary for magnesium by 3.1\n",
      "--- fix lower boundary for magnesium by 1.0\n",
      "-- magnesium fixed\n",
      "--- fix upper boundary for o2_flow by 80.0\n",
      "--- fix lower boundary for o2_flow by 0.0\n",
      "-- o2_flow fixed\n",
      "--- fix upper boundary for pco2 by 110.0\n",
      "--- fix lower boundary for pco2 by 18.0\n",
      "-- pco2 fixed\n",
      "--- fix upper boundary for peep by 18.0\n",
      "--- fix lower boundary for peep by 0.0\n",
      "-- peep fixed\n",
      "--- fix upper boundary for ph_arterial by 7.629\n",
      "--- fix lower boundary for ph_arterial by 6.827000000000001\n",
      "-- ph_arterial fixed\n",
      "--- fix upper boundary for phosphorus by 8.0\n",
      "--- fix lower boundary for phosphorus by 1.0\n",
      "-- phosphorus fixed\n",
      "--- fix upper boundary for po2 by 537.4\n",
      "--- fix lower boundary for po2 by 23.0\n",
      "-- po2 fixed\n",
      "--- fix upper boundary for potassium by 6.89\n",
      "--- fix lower boundary for potassium by 1.94\n",
      "-- potassium fixed\n",
      "--- fix upper boundary for protime_inr by 4.8\n",
      "--- fix lower boundary for protime_inr by 0.8\n",
      "-- protime_inr fixed\n",
      "--- fix upper boundary for ptt by 120.0\n",
      "--- fix lower boundary for ptt by 20.2\n",
      "-- ptt fixed\n",
      "--- fix upper boundary for platelet_count by 742.0\n",
      "--- fix lower boundary for platelet_count by 19.0\n",
      "-- platelet_count fixed\n",
      "--- fix upper boundary for resp_rate by 70.0\n",
      "--- fix lower boundary for resp_rate by 5.704498\n",
      "-- resp_rate fixed\n",
      "--- fix upper boundary for sbp by 219.0\n",
      "--- fix lower boundary for sbp by 40.0\n",
      "-- sbp fixed\n",
      "--- fix upper boundary for sodium by 156.0\n",
      "--- fix lower boundary for sodium by 121.8\n",
      "-- sodium fixed\n",
      "--- fix upper boundary for spo2 by 100.0\n",
      "--- fix lower boundary for spo2 by 79.0\n",
      "-- spo2 fixed\n",
      "--- fix upper boundary for temp by 104.0\n",
      "--- fix lower boundary for temp by 85.8\n",
      "-- temp fixed\n",
      "--- fix upper boundary for total_bilirubin by 7.4\n",
      "--- fix lower boundary for total_bilirubin by 0.2\n",
      "-- total_bilirubin fixed\n",
      "--- fix upper boundary for total_protein by 8.8\n",
      "--- fix lower boundary for total_protein by 3.7\n",
      "-- total_protein fixed\n",
      "-- txp fixed\n",
      "--- fix upper boundary for troponin by 0.89\n",
      "--- fix lower boundary for troponin by 0.02\n",
      "-- troponin fixed\n",
      "--- fix upper boundary for wbc by 50.0\n",
      "--- fix lower boundary for wbc by 0.34\n",
      "-- wbc fixed\n",
      "--- fix out-of-dictionry level/orders ['nan'] with ['no']\n",
      "-- gram_positive fixed\n",
      "--- fix out-of-dictionry level/orders ['nan'] with ['no']\n",
      "-- gram_negative fixed\n",
      "--- fix out-of-dictionry level/orders ['nan'] with ['no']\n",
      "-- fungus fixed\n",
      "--- fix out-of-dictionry level/orders ['nan'] with ['no']\n",
      "-- mycobacterial fixed\n",
      "--- prepare episodes for uvaold_10393163\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___nbc    0.0\n",
      "y___pos    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10978758\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jiaxingqiu/Documents/FAIRStream/FAIRStream/Functions/make_episodes_ts.py:75: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  upper_anchors['__ep_order']=upper_anchors.__time_bin//(anchor_gap//time_resolution)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.25\n",
      "y___nbc    0.75\n",
      "y___pos    0.00\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10656658\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.2\n",
      "y___nbc    0.8\n",
      "y___pos    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9725657\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.142857\n",
      "y___nbc    0.857143\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7547598\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.210526\n",
      "y___nbc    0.789474\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8435695\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.25\n",
      "y___nbc    0.75\n",
      "y___pos    0.00\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10079406\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.272727\n",
      "y___nbc    0.727273\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10359711\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.304348\n",
      "y___nbc    0.695652\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6060250\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.291667\n",
      "y___nbc    0.708333\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6855033\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.28\n",
      "y___nbc    0.72\n",
      "y___pos    0.00\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5984467\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.269231\n",
      "y___nbc    0.730769\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9130682\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.25\n",
      "y___nbc    0.75\n",
      "y___pos    0.00\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5174625\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.275862\n",
      "y___nbc    0.724138\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6009768\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.266667\n",
      "y___nbc    0.733333\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6613420\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.272727\n",
      "y___nbc    0.727273\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6789481\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.264706\n",
      "y___nbc    0.735294\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8485104\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.285714\n",
      "y___nbc    0.714286\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6543505\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.277778\n",
      "y___nbc    0.722222\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8693912\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.315789\n",
      "y___nbc    0.684211\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_11416846\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.341463\n",
      "y___nbc    0.658537\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_11369473\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.333333\n",
      "y___nbc    0.666667\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_4477629\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.325581\n",
      "y___nbc    0.674419\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9689064\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.311111\n",
      "y___nbc    0.688889\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5557453\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.340426\n",
      "y___nbc    0.659574\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8704581\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.333333\n",
      "y___nbc    0.666667\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9428277\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.346939\n",
      "y___nbc    0.653061\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7373283\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.36\n",
      "y___nbc    0.64\n",
      "y___pos    0.00\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5093688\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.352941\n",
      "y___nbc    0.647059\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6595429\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.365385\n",
      "y___nbc    0.634615\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7793705\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.351852\n",
      "y___nbc    0.648148\n",
      "y___pos    0.000000\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9911169\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.339286\n",
      "y___nbc    0.642857\n",
      "y___pos    0.017857\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7582507\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.327586\n",
      "y___nbc    0.655172\n",
      "y___pos    0.017241\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7896011\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.338983\n",
      "y___nbc    0.644068\n",
      "y___pos    0.016949\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8932061\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.333333\n",
      "y___nbc    0.650000\n",
      "y___pos    0.016667\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5374672\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.327869\n",
      "y___nbc    0.655738\n",
      "y___pos    0.016393\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_11651966\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.333333\n",
      "y___nbc    0.650794\n",
      "y___pos    0.015873\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8421769\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.348485\n",
      "y___nbc    0.636364\n",
      "y___pos    0.015152\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10403266\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.358209\n",
      "y___nbc    0.626866\n",
      "y___pos    0.014925\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9141621\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.367647\n",
      "y___nbc    0.617647\n",
      "y___pos    0.014706\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_10087723\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.371429\n",
      "y___nbc    0.614286\n",
      "y___pos    0.014286\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7955669\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.366197\n",
      "y___nbc    0.619718\n",
      "y___pos    0.014085\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9391005\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.361111\n",
      "y___nbc    0.611111\n",
      "y___pos    0.027778\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_11555467\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.356164\n",
      "y___nbc    0.602740\n",
      "y___pos    0.041096\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6613443\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.364865\n",
      "y___nbc    0.594595\n",
      "y___pos    0.040541\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_11083058\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.3500\n",
      "y___nbc    0.6125\n",
      "y___pos    0.0375\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_7137982\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.345679\n",
      "y___nbc    0.604938\n",
      "y___pos    0.049383\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_6250721\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.341463\n",
      "y___nbc    0.609756\n",
      "y___pos    0.048780\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_5205748\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.345238\n",
      "y___nbc    0.607143\n",
      "y___pos    0.047619\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_8010837\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.341176\n",
      "y___nbc    0.611765\n",
      "y___pos    0.047059\n",
      "dtype: float64\n",
      "--- prepare episodes for uvaold_9218930\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.337209\n",
      "y___nbc    0.616279\n",
      "y___pos    0.046512\n",
      "dtype: float64\n",
      "Success! Engineer has updated attributes --- mvts_df, input_vars, output_vars, input_vars_byside, output_vars_byside. \n",
      "Success! Engineer has updated attributes --- train_df, valid_df and test_df. \n",
      "Using 'mask' for predictor imputation (constant value -333) because too few subjects are sampled.\n",
      "Using 'mode' for response imputation because too few subjects are sampled.\n",
      "Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
      "Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. \n"
     ]
    }
   ],
   "source": [
    "# Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              nsbj = 50, # number of subjects / patients to sample from the pool \n",
    "                              replace = False, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='none', # imputation on predictors\n",
    "                              impute_output='none',# imputation on response (no need in BSI project)\n",
    "                              sep=\"_\", \n",
    "                              return_episode=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "txp___yes  y___pos\n",
       "0.0        0.0        4763\n",
       "           1.0         351\n",
       "1.0        0.0          86\n",
       "           1.0          10\n",
       "Name: __uid, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_df_new = pd.concat( [bsi_stream.engineer.train_df, bsi_stream.engineer.valid_df], axis=0)\n",
    "all_df_new = pd.concat( [all_df_new, bsi_stream.engineer.test_df], axis=0)\n",
    "all_df_new.groupby(['txp___yes','y___pos'])['__uid'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9954\n"
     ]
    }
   ],
   "source": [
    "all_df_new = pd.concat( [bsi_stream.engineer.train_df, bsi_stream.engineer.valid_df], axis=0)\n",
    "all_df_new = pd.concat( [all_df_new, bsi_stream.engineer.test_df], axis=0)\n",
    "\n",
    "if all_df is None:\n",
    "    all_df = all_df_new\n",
    "else:\n",
    "    all_df = pd.concat( [all_df, all_df_new], axis=0)\n",
    "print(len(set(all_df.__uid))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"./data_bsi_txp_4d_11_15_old.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbc\n",
    "#all_df.to_csv(\"./data_bsi_txp_4d_nbc.csv\",index=False)\n",
    "# bc\n",
    "#all_df.to_csv(\"./data_bsi_txp_4d_bc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import FAIRStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_txp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "bsi_stream.engineer.variable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an episode (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=2*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bsi_stream.engineer.episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              nsbj = 6000, # number of subjects / patients to sample from the pool \n",
    "                              replace=False, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='median', # imputation on predictors\n",
    "                              impute_output='median',\n",
    "                              sep=\"_\")# imputation on response (no need in BSI project)\n",
    "# please see the end of console \n",
    "# --- Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
    "# --- Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat( [bsi_stream.engineer.train_df, bsi_stream.engineer.valid_df], axis=0)\n",
    "all_df = pd.concat( [all_df, bsi_stream.engineer.test_df], axis=0)\n",
    "print(len(set(all_df.__uid)))\n",
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"./whole_df_uvanew.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import matplotlib.pylab as plt \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "def get_feature_maps(model, layer_id, input_image):\n",
    "    model_ = Model(inputs=[model.input], outputs=[model.layers[layer_id].output])\n",
    "    return model_.predict(np.expand_dims(input_image, axis=0))[0,:,:,:].transpose((2,1,0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_features_map(input_image_list, \n",
    "                      cnn,\n",
    "                      img_title_list,\n",
    "                      layer_idx):\n",
    "    \n",
    "    nrow = len(layer_idx)\n",
    "    ncol = len(input_image_list)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrow+1, ncol, figsize=(20,20))\n",
    "    \n",
    "    for j in range(ncol):\n",
    "        input_image = input_image_list[j]\n",
    "        ax[0][j].imshow(input_image[:,:,0].transpose(1,0))\n",
    "        ax[0][j].set_title(img_title_list[j])\n",
    "        for i in range(nrow):\n",
    "            feature_map = get_feature_maps(cnn, layer_idx[i], input_image)\n",
    "            ax[i+1][j].imshow(feature_map[0,:,:])\n",
    "            ax[i+1][j].set_title('layer {} - {}'.format(layer_idx[i], cnn.layers[layer_idx[i]].get_config()['name']))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "\n",
    "\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "bsi_stream.engineer.variable_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define an episode (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=4*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=1, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MVTS (multi-variable time series) data objects\n",
    "- train_df_imputed, valid_df_imputed and test_df_imputed are dataframes\n",
    "- train_tfds, valid_tfds and test_tfds are tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "# bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "#                               nsbj = 10, # number of subjects / patients to sample from the pool \n",
    "#                               valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "#                               test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "#                               batch_size = 64, # batch size (usually 32,64,128..)\n",
    "#                               impute_input='median', # imputation on predictors\n",
    "#                               impute_output='median' )# imputation on response (no need in BSI project)\n",
    "\n",
    "# # please see the end of console \n",
    "# # --- Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
    "# # --- Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print all the attributes of the engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.engineer.info()\n",
    "\n",
    "# # extract X, Y numpy array by engineer build-in function\n",
    "# X_train, Y_train, X_valid, Y_valid, X_test, Y_test = bsi_stream.engineer.ExtractXY()\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "# X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], X_valid.shape[2], 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_valid = X_valid.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "\n",
    "# Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[2])\n",
    "# Y_valid = Y_valid.reshape(Y_valid.shape[0], Y_valid.shape[2])\n",
    "# Y_test = Y_test.reshape(Y_test.shape[0], Y_test.shape[2])\n",
    "\n",
    "# X_all = np.concatenate((X_train, X_valid, X_test), axis=0)\n",
    "# Y_all = np.concatenate((Y_train, Y_valid, Y_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input column names\n",
    "bsi_stream.engineer.input_vars = ['age___vital', 'age___lab', 'temp___vital', 'heart_rate___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'resp_rate___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'wbc___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'paco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Pre-modeling Interpretability (raw scale) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load(\"./X_all.npy\")\n",
    "Y_all = np.load(\"./Y_all.npy\")\n",
    "X_train = np.load(\"./X_train.npy\")\n",
    "Y_train = np.load(\"./Y_train.npy\")\n",
    "X_valid = np.load(\"./X_valid.npy\")\n",
    "Y_valid = np.load(\"./Y_valid.npy\")\n",
    "X_test = np.load(\"./X_test.npy\")\n",
    "Y_test = np.load(\"./Y_test.npy\")\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_test shape\", Y_test.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "X_pos = X_all[Y_all[:,1]==1.0][:,:,:,0]\n",
    "X_ctrl = X_all[Y_all[:,1]==0.0][:,:,:,0]\n",
    "print(\"X_pos shape\", X_pos.shape)\n",
    "print(\"X_ctrl shape\", X_ctrl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. print a few episode as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10): \n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0,  # change zero to be not white \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_pos[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('postive episode {}'.format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10):\n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_ctrl[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('control episode {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize Statistical Moments -- Positive VS Control Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 1 -- mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.mean(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.mean(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.mean(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "\n",
    "im = ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im = ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 2 -- std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.std(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.std(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.std(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 3 -- skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = scipy.stats.skew(X_pos, axis=0).transpose((1,0))\n",
    "X_ctrl_stat = scipy.stats.skew(X_ctrl, axis=0).transpose((1,0))\n",
    "X_all_stat = scipy.stats.skew(X_all, axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 4 -- Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = scipy.stats.kurtosis(X_pos, axis=0).transpose((1,0))\n",
    "X_ctrl_stat = scipy.stats.kurtosis(X_ctrl, axis=0).transpose((1,0))\n",
    "X_all_stat = scipy.stats.kurtosis(X_all, axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Modeling interpretation raw scale (CNN) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2d = X_train[:,:,:,0].reshape(X_train[:,:,:,0].shape[0],-1)\n",
    "X_valid_2d = X_valid[:,:,:,0].reshape(X_valid[:,:,:,0].shape[0],-1)\n",
    "Y_train_binary = Y_train[:,1]\n",
    "Y_valid_binary = Y_valid[:,1]\n",
    "print(X_train_2d.shape)\n",
    "print(Y_train_binary.shape)\n",
    "print(X_valid_2d.shape)\n",
    "print(Y_valid_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear').fit(X_train_2d, Y_train_binary)\n",
    "\n",
    "#to check the shape of the coefficient matrix\n",
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.max(np.abs(clf.coef_))\n",
    "\n",
    "p = plt.figure(figsize=(25, 25));\n",
    "nclasses=1\n",
    "for i in range(nclasses):\n",
    "    p = plt.subplot(1, nclasses, i + 1)\n",
    "    p = plt.imshow(clf.coef_[i].reshape(96, 25).T,\n",
    "                  cmap=plt.cm.RdBu, vmin=-scale, vmax=scale);\n",
    "    p = plt.axis('off')\n",
    "    p = plt.title('positive');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_pred = clf.predict_proba(X_valid_2d)\n",
    "sklearn.metrics.roc_auc_score(Y_valid_binary, Y_valid_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary setup logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train_binary, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid_binary), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train_binary, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid_binary), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple classification setup logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC', multi_label=True),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR', multi_label=True),\n",
    "    #keras.metrics.recall(....),\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC', multi_label=True),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR', multi_label=True),\n",
    "    keras.metrics.recall(....),\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same',\n",
    "                        input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(1, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_pos_img = X_train[Y_train[:,0]==1.0].mean(axis=0)\n",
    "X_train_ctrl_img = X_train[Y_train[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "X_valid_pos_img = X_valid[Y_valid[:,0]==1.0].mean(axis=0)\n",
    "X_valid_ctrl_img = X_valid[Y_valid[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "X_all_pos_img = X_all[Y_all[:,0]==1.0].mean(axis=0)\n",
    "X_all_ctrl_img = X_all[Y_all[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "plot_features_map(input_image_list=[X_all_pos_img, X_all_ctrl_img,\n",
    "                                    X_train_pos_img, X_train_ctrl_img, \n",
    "                                    X_valid_pos_img, X_valid_ctrl_img],\n",
    "                  img_title_list=[\"POS (all)\", \"CTRL (all)\",\n",
    "                                  \"POS (train)\", \"CTRL (train)\", \n",
    "                                  \"POS (valid)\", \" CTRL (valid)\"],\n",
    "                  layer_idx=[0,3,6], \n",
    "                  cnn=mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Post-Modeling interpretation (raw scale + saliency map) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "def plot_saliency(img_idx):\n",
    "    grads = visualize_saliency(mdl,\n",
    "                               \"visualized_layer\",\n",
    "                               filter_indices=Y_all[img_idx][0], \n",
    "                               seed_input=X_all[img_idx], \n",
    "                               backprop_modifier=None,\n",
    "                               grad_modifier=\"absolute\")\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].imshow(X_all[img_idx])\n",
    "    ax[0].set_title('original img id {}'.format(img_idx))\n",
    "    ax[1].imshow(grads, cmap='jet')\n",
    "    ax[1].set_title('saliency - predicted {}'.format(img_idx))\n",
    "\n",
    "plot_saliency(img_idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Pre-training Interpretability (standardized) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load(\"./X_all.npy\")\n",
    "Y_all = np.load(\"./Y_all.npy\")\n",
    "X_train = np.load(\"./X_train.npy\")\n",
    "Y_train = np.load(\"./Y_train.npy\")\n",
    "X_valid = np.load(\"./X_valid.npy\")\n",
    "Y_valid = np.load(\"./Y_valid.npy\")\n",
    "X_test = np.load(\"./X_test.npy\")\n",
    "Y_test = np.load(\"./Y_test.npy\")\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_test shape\", Y_test.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "X_train = (X_train - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "X_valid = (X_valid - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "X_all = (X_all - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "\n",
    "X_pos = X_all[Y_all[:,1]==1.0][:,:,:,0]\n",
    "X_ctrl = X_all[Y_all[:,1]==0.0][:,:,:,0]\n",
    "print(\"X_pos shape\", X_pos.shape)\n",
    "print(\"X_ctrl shape\", X_ctrl.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10): \n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_pos[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('postive episode {}'.format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10):\n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_ctrl[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('control episode {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 1 -- mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.mean(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.mean(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.mean(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "\n",
    "im = ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im = ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic Moment 2 -- std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.std(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.std(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.std(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 3 -- skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 4 -- Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
