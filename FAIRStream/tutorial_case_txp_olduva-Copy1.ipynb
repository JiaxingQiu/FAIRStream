{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Case txp\n",
    "\n",
    "> In this case study, we are exploring deep learning interpretability on BSI prognosis, before, during and after training a CNN model on multi-variate time series medical record.\n",
    " \n",
    "> we use hourly aggregated physiological data and lab results from 10,000 ICU patients. 1824 positive events and 31496 control group events are generated from the population. \n",
    "\n",
    "> we use 25 features selected by domain knowledge, 96 hours prior to the blood culture acquisition to classify positive test results from the control group -- negative test results and 4 days of randomly sliced baseline patient data.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import FAIRStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Querier has initiated a csv source dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd/meta_data/csv_source_dict_demo.json\n",
      "Success: Querier has initiated a variable dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd/meta_data/variable_dict_demo.json\n",
      "Unable to read sql source dictionary. Use Querier.update_sql_source_dict() to build one.\n",
      "{'__uid': {'src_names': ['id', 'ID', 'subject_id', 'subject_id', 'oldid'], 'label': 'subject id', 'unique_per_sbj': True}, '__time': {'src_names': ['tsa', 'timeMinutes'], 'label': 'Time since admission', 'unit': 'minute'}, '__anchor': {'src_names': ['True_positive', 'True positive', 'label'], 'label': 'episode anchor', 'unique_per_sbj': False, 'shuffle': ['__nbc'], 'factor': {'levels': {'__nbc': ['nan'], '__ctm': ['contaminant'], '__neg': ['0', '0.0', 'negative'], '__pos': ['1', '1.0', 'true_positive']}, 'impute_per_sbj': {'nan_level': '__nbc'}}}, 'y': {'output': True, 'src_names': ['True_positive', 'True positive', 'label'], 'label': 'Blood culture result', 'unique_per_sbj': False, 'factor': {'levels': {'nbc': ['nan'], 'ctm': ['contaminant'], 'neg': ['0', '0.0', 'negative'], 'pos': ['1', '1.0', 'true_positive']}, 'impute_per_sbj': {'nan_level': 'nbc'}}}, 'age': {'input': True, 'src_names': ['age', 'AGE'], 'label': 'Age', 'unique_per_sbj': True, 'numeric': {'scaler': 'none', 'unit': 'year', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 110}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'albumin': {'input': True, 'src_names': ['Albumin', 'ALBUMIN', 'albumin'], 'label': 'Albumin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 5}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'alp': {'input': True, 'src_names': ['ALKALINE.PHOSPHATASE', 'ALP', 'alp'], 'label': 'ALP', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 1000}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'alt': {'input': True, 'src_names': ['ALT.GPT', 'ALT', 'alt'], 'label': 'ALT', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 2500}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'ast': {'input': True, 'src_names': ['AST.GOT', 'AST', 'ast'], 'label': 'AST', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 2500}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'bicarbonate': {'input': True, 'src_names': ['bicarbonate', 'BICARBONATE'], 'label': 'Bicarbonate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 60}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'bun': {'input': True, 'src_names': ['BLOOD.UREA.NITROGEN', 'BUN', 'bun'], 'label': 'BUN', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 150}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'calcium': {'input': True, 'src_names': ['CALCIUM', 'Calcium', 'calcium'], 'label': 'Calcium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 4, 'value_max': 15}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'chloride': {'input': True, 'src_names': ['CHLORIDE', 'Chloride', 'chloride'], 'label': 'Chloride', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 50, 'value_max': 140}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'co2': {'input': True, 'src_names': ['CO2', 'co2'], 'label': 'CO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 45}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'creatinine': {'input': True, 'src_names': ['CREATININE', 'Creatinine', 'creatinine'], 'label': 'Creatinine', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'dbp': {'input': True, 'src_names': ['DBP', 'diasbp', 'dbp'], 'label': 'subject diastolic blood pressure', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'mm Hg', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 20, 'value_max': 150}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'fio2_pct': {'input': True, 'src_names': ['FIO2', 'fio2_pct'], 'label': 'FIO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 100}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'glucose': {'input': True, 'src_names': ['GLUCOSE', 'Glucose', 'glucose'], 'label': 'Glucose', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 40, 'value_max': 500}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'hematocrit': {'input': True, 'src_names': ['HEMATOCRIT', 'hematocrit'], 'label': 'Hematocrit', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 10, 'value_max': 60}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'hemoglobin': {'input': True, 'src_names': ['HEMOGLOBIN', 'hemoglobin'], 'label': 'Hemoglobin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 20}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'heart_rate': {'input': True, 'src_names': ['hr', 'heartrate'], 'label': 'Heart rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'beats per minute', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 10, 'value_max': 200}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'lactic_acid': {'input': True, 'src_names': ['LACTIC.ACID', 'lactic_acid'], 'label': 'Lactic Acid', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 19.1}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'magnesium': {'input': True, 'src_names': ['MAGNESIUM', 'Magnesium', 'magnesium'], 'label': 'Magnesium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 5}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'o2_flow': {'input': True, 'src_names': ['o2_flow', 'O2.Flow'], 'label': 'O2 Flow', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 80}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'pco2': {'input': True, 'src_names': ['PCO2', 'PaCO2', 'pco2'], 'label': 'PCO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 110}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'peep': {'input': True, 'src_names': ['peep', 'PEEP'], 'label': 'peep', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 40}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'ph_arterial': {'input': True, 'src_names': ['ph_arterial', 'PH.ARTERIAL'], 'label': 'PH in Arterial', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 6.5, 'value_max': 8}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'phosphorus': {'input': True, 'src_names': ['PHOSPHORUS', 'phosphorus'], 'label': 'Phosphorus', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'po2': {'input': True, 'src_names': ['po2', 'PO2'], 'label': 'PO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 650}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'potassium': {'input': True, 'src_names': ['POTASSIUM', 'Potassium', 'potassium'], 'label': 'Potassium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'protime_inr': {'input': True, 'src_names': ['PROTIME.INR', 'protime_inr'], 'label': 'Protime INR', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 6}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'ptt': {'input': True, 'src_names': ['PARTIAL.THROMBOPLASTIN.TIME', 'PTT', 'ptt'], 'label': 'partial_thromboplastin_time', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 150}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'platelet_count': {'input': True, 'src_names': ['platelet', 'PLATELET.COUNT', 'plateletcount'], 'label': 'platelet count', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 1000}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'resp_rate': {'input': True, 'src_names': ['rr', 'resprate'], 'label': 'subject respiratory rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 70}, 'unit': 'mm Hg', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'sbp': {'input': True, 'src_names': ['SBP', 'sysbp', 'sbp'], 'label': 'subject systolic blood pressure', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'mm Hg', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 40, 'value_max': 250}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'sodium': {'input': True, 'src_names': ['SODIUM', 'Sodium', 'sodium'], 'label': 'Sodium', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 100, 'value_max': 180}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'spo2': {'input': True, 'src_names': ['so2', 'spo2'], 'label': 'SpO2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 100}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'temp': {'input': True, 'src_names': ['Temp', 'temp'], 'label': 'Temperature', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': 'Fahrenheit', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 80, 'value_max': 104}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'total_bilirubin': {'input': True, 'src_names': ['TOTAL.BILIRUBIN', 'bilirubin', 'total_bilirubin'], 'label': 'Total Bilirubin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 50}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'total_protein': {'input': True, 'src_names': ['total_protein', 'TOTAL.PROTEIN'], 'label': 'Total Protein', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 2, 'value_max': 10}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'txp': {'input': True, 'src_names': ['Confirmed Txp', 'txp'], 'label': 'Transplant recipient', 'unique_per_sbj': True, 'factor': {'levels': {'no': ['0', '0.0', 'nan'], 'yes': ['1', '1.0', 'yes']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'troponin': {'input': True, 'src_names': ['TROPONIN.I', 'Troponin', 'troponin'], 'label': 'Troponin', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 50}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'wbc': {'input': True, 'src_names': ['WHITE.BLOOD.CELL.COUNT', 'WBC', 'wbc'], 'label': 'WBC', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 60}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'gram_positive': {'input': False, 'src_names': ['GP', 'Gram positive', 'gram_positive'], 'label': 'Gram Positive', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'gram_negative': {'input': False, 'src_names': ['GN', 'Gram negative', 'gram_negative'], 'label': 'Gram Negative', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'fungus': {'input': False, 'src_names': ['fungus', 'Fungus', 'fungal'], 'label': 'Fungus', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'mycobacterial': {'input': False, 'src_names': ['mycobacterial', 'mycobacteria', 'Mycobacterial'], 'label': 'Mycobacterial', 'unique_per_sbj': False, 'factor': {'levels': {'no': ['0', '0.0'], 'yes': ['1', '1.0']}, 'impute_per_sbj': {'nan_level': 'no'}}}, 'x_hr_rr': {'src_names': ['x.hr.rr'], 'label': 'cross correlation between HR and resp_rate', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'x_hr_spo2': {'src_names': ['x.hr.spo2'], 'label': 'cross correlation between HR and spo2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'x_rr_spo2': {'src_names': ['x.hr.spo2'], 'label': 'cross correlation between resp_rate and spo2', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -1, 'value_max': 1}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 's_hr': {'src_names': ['s.hr'], 'label': 'HR sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 's_rr': {'src_names': ['s.rr'], 'label': 'resp_rate sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 's_so2': {'src_names': ['s.so2'], 'label': 'SPO2 sd', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'unit': '', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': -99999, 'value_max': 99999}, 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}, 'o2sat': {'src_names': ['OXYGEN_SATURATION'], 'label': 'Oxygen Satuation', 'unique_per_sbj': False, 'numeric': {'scaler': 'none', 'cutoff': {'quantile_min': 0.0, 'quantile_max': 1, 'value_min': 0, 'value_max': 17.6}, 'unit': '', 'impute_per_sbj': {'forward': 1440, 'backward': 0}}}}\n",
      "{'uva': {'vital': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/bsi_old_deidentified_final.csv', 'info': 'Vital signs data from UVA'}, 'lab': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/uva_lab.csv', 'info': 'Lab results data from UVA'}}, 'uvaold': {'all': {'include': True, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2011_2015/data_ml/bsi_old_final.csv', 'info': 'Data from UVA 2011 - 2015 '}}, 'uvanewbc': {'all': {'include': False, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2016_2021/data_ml/bsi_new_deidentified_bc.csv', 'info': 'Data from UVA 2017 - 2021 (cohort who have at least one blood culture )'}}, 'uvanewnbc': {'all': {'include': False, 'path': '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2016_2021/data_ml/bsi_new_deidentified_nbc.csv', 'info': 'Data from UVA 2017 - 2021 (cohort who have non blood culture)'}}, 'mimic': {'vital': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/mimic_patient_data_minutes.csv', 'info': 'Vital signs data from MIMIC'}, 'lab': {'include': False, 'path': '/Users/jiaxingqiu/Documents/BSI/code/DeepDiag/data/mimic_labs_minutes_combined.csv', 'info': 'Lab results data from MIMIC'}}}\n"
     ]
    }
   ],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_fwd'\n",
    "\n",
    "# initiate dataframe to return\n",
    "all_df=None\n",
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "print(bsi_stream.engineer.variable_dict)\n",
    "print(bsi_stream.engineer.csv_source_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.querier.create_csv_pool(csv_pool_dir = csv_pool_path,\n",
    "#                                   source_key=\"uvaold\",\n",
    "#                                   file_key=\"all\",\n",
    "#                                   sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.querier.create_csv_pool(csv_pool_dir = csv_pool_path,\n",
    "#                                   source_key=\"uvanewbc\",\n",
    "#                                   file_key=\"all\",\n",
    "#                                   sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.querier.create_csv_pool(csv_pool_dir = csv_pool_path,\n",
    "#                                   source_key=\"uvanewnbc\",\n",
    "#                                   file_key=\"all\",\n",
    "#                                   sep=\"_\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## nbc (baseline) group \n",
    "# # define an episode (notice that the engineer now has new attributes)\n",
    "# bsi_stream.engineer.DefineEpisode(input_time_len=1*60, # using vital signs and labs 4 days prior to a culture \n",
    "#                                   output_time_len=(4*24-1)*60, # predict one time unit into the future\n",
    "#                                   time_resolution=60, # aggregate minutely data to one row per hour \n",
    "#                                   time_lag=0,  # no time lag between predictors and response\n",
    "#                                   anchor_gap=4*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc = pd.read_csv(\"/Users/jiaxingqiu/Documents/CAMA_projects/BSI/2011_2015/data_ml/bsi_old_final.csv\", low_memory=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(list(df_bc['oldid'].unique())))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_list = list(df_bc['oldid'].unique())[3000:6000]\n",
    "df_bc_now = df_bc.loc[df_bc.oldid.isin(id_list),:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_bc_now.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bc group \n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=4*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=3*24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Build MVTS dataframe or tfds from external table object!!!\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              nsbj = 50, # number of subjects / patients to sample from the pool \n",
    "                              replace = False, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='none', # imputation on predictors\n",
    "                              impute_output='none',# imputation on response (no need in BSI project)\n",
    "                              sep=\"_\", \n",
    "                              return_episode=True,\n",
    "                              df_raw=df_bc_now)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df_new = pd.concat( [bsi_stream.engineer.train_df, bsi_stream.engineer.valid_df], axis=0)\n",
    "all_df_new = pd.concat( [all_df_new, bsi_stream.engineer.test_df], axis=0)\n",
    "\n",
    "if all_df is None:\n",
    "    all_df = all_df_new\n",
    "else:\n",
    "    all_df = pd.concat( [all_df, all_df_new], axis=0)\n",
    "print(len(set(all_df.__uid))) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"./data_bsi_txp_7d_11_15_2.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nbc\n",
    "#all_df.to_csv(\"./data_bsi_txp_4d_nbc.csv\",index=False)\n",
    "# bc\n",
    "#all_df.to_csv(\"./data_bsi_txp_4d_bc.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_columns', 500)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "import FAIRStream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_txp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "bsi_stream.engineer.variable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define an episode (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=2*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(bsi_stream.engineer.episode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              nsbj = 6000, # number of subjects / patients to sample from the pool \n",
    "                              replace=False, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='median', # imputation on predictors\n",
    "                              impute_output='median',\n",
    "                              sep=\"_\")# imputation on response (no need in BSI project)\n",
    "# please see the end of console \n",
    "# --- Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
    "# --- Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df = pd.concat( [bsi_stream.engineer.train_df, bsi_stream.engineer.valid_df], axis=0)\n",
    "all_df = pd.concat( [all_df, bsi_stream.engineer.test_df], axis=0)\n",
    "print(len(set(all_df.__uid)))\n",
    "all_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_df.to_csv(\"./whole_df_uvanew.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "import matplotlib.pylab as plt \n",
    "import numpy as np\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "def get_feature_maps(model, layer_id, input_image):\n",
    "    model_ = Model(inputs=[model.input], outputs=[model.layers[layer_id].output])\n",
    "    return model_.predict(np.expand_dims(input_image, axis=0))[0,:,:,:].transpose((2,1,0))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def plot_features_map(input_image_list, \n",
    "                      cnn,\n",
    "                      img_title_list,\n",
    "                      layer_idx):\n",
    "    \n",
    "    nrow = len(layer_idx)\n",
    "    ncol = len(input_image_list)\n",
    "    \n",
    "    fig, ax = plt.subplots(nrow+1, ncol, figsize=(20,20))\n",
    "    \n",
    "    for j in range(ncol):\n",
    "        input_image = input_image_list[j]\n",
    "        ax[0][j].imshow(input_image[:,:,0].transpose(1,0))\n",
    "        ax[0][j].set_title(img_title_list[j])\n",
    "        for i in range(nrow):\n",
    "            feature_map = get_feature_maps(cnn, layer_idx[i], input_image)\n",
    "            ax[i+1][j].imshow(feature_map[0,:,:])\n",
    "            ax[i+1][j].set_title('layer {} - {}'.format(layer_idx[i], cnn.layers[layer_idx[i]].get_config()['name']))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "\n",
    "\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case4'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "bsi_stream.engineer.variable_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Episode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# define an episode (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=4*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=1, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build MVTS (multi-variable time series) data objects\n",
    "- train_df_imputed, valid_df_imputed and test_df_imputed are dataframes\n",
    "- train_tfds, valid_tfds and test_tfds are tensorflow datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# # Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "# bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "#                               nsbj = 10, # number of subjects / patients to sample from the pool \n",
    "#                               valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "#                               test_frac = 0.1, # fraction of number of subjects in left-out test dataset\n",
    "#                               batch_size = 64, # batch size (usually 32,64,128..)\n",
    "#                               impute_input='median', # imputation on predictors\n",
    "#                               impute_output='median' )# imputation on response (no need in BSI project)\n",
    "\n",
    "# # please see the end of console \n",
    "# # --- Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
    "# # --- Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### print all the attributes of the engineer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bsi_stream.engineer.info()\n",
    "\n",
    "# # extract X, Y numpy array by engineer build-in function\n",
    "# X_train, Y_train, X_valid, Y_valid, X_test, Y_test = bsi_stream.engineer.ExtractXY()\n",
    "\n",
    "# X_train = X_train.reshape(X_train.shape[0], X_train.shape[1], X_train.shape[2], 1)\n",
    "# X_valid = X_valid.reshape(X_valid.shape[0], X_valid.shape[1], X_valid.shape[2], 1)\n",
    "# X_test = X_test.reshape(X_test.shape[0], X_test.shape[1], X_test.shape[2], 1)\n",
    "# X_train = X_train.astype('float32')\n",
    "# X_valid = X_valid.astype('float32')\n",
    "# X_test = X_test.astype('float32')\n",
    "\n",
    "# Y_train = Y_train.reshape(Y_train.shape[0], Y_train.shape[2])\n",
    "# Y_valid = Y_valid.reshape(Y_valid.shape[0], Y_valid.shape[2])\n",
    "# Y_test = Y_test.reshape(Y_test.shape[0], Y_test.shape[2])\n",
    "\n",
    "# X_all = np.concatenate((X_train, X_valid, X_test), axis=0)\n",
    "# Y_all = np.concatenate((Y_train, Y_valid, Y_test), axis=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# specify input column names\n",
    "bsi_stream.engineer.input_vars = ['age___vital', 'age___lab', 'temp___vital', 'heart_rate___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'resp_rate___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'wbc___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'paco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Pre-modeling Interpretability (raw scale) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load(\"./X_all.npy\")\n",
    "Y_all = np.load(\"./Y_all.npy\")\n",
    "X_train = np.load(\"./X_train.npy\")\n",
    "Y_train = np.load(\"./Y_train.npy\")\n",
    "X_valid = np.load(\"./X_valid.npy\")\n",
    "Y_valid = np.load(\"./Y_valid.npy\")\n",
    "X_test = np.load(\"./X_test.npy\")\n",
    "Y_test = np.load(\"./Y_test.npy\")\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_test shape\", Y_test.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "X_pos = X_all[Y_all[:,1]==1.0][:,:,:,0]\n",
    "X_ctrl = X_all[Y_all[:,1]==0.0][:,:,:,0]\n",
    "print(\"X_pos shape\", X_pos.shape)\n",
    "print(\"X_ctrl shape\", X_ctrl.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. print a few episode as images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10): \n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0,  # change zero to be not white \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_pos[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('postive episode {}'.format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10):\n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_ctrl[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('control episode {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Visualize Statistical Moments -- Positive VS Control Group"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 1 -- mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# outlier in image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.mean(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.mean(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.mean(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "\n",
    "im = ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im = ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 2 -- std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.std(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.std(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.std(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 3 -- skewness"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = scipy.stats.skew(X_pos, axis=0).transpose((1,0))\n",
    "X_ctrl_stat = scipy.stats.skew(X_ctrl, axis=0).transpose((1,0))\n",
    "X_all_stat = scipy.stats.skew(X_all, axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 4 -- Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = scipy.stats.kurtosis(X_pos, axis=0).transpose((1,0))\n",
    "X_ctrl_stat = scipy.stats.kurtosis(X_ctrl, axis=0).transpose((1,0))\n",
    "X_all_stat = scipy.stats.kurtosis(X_all, axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Modeling interpretation raw scale (CNN) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2d = X_train[:,:,:,0].reshape(X_train[:,:,:,0].shape[0],-1)\n",
    "X_valid_2d = X_valid[:,:,:,0].reshape(X_valid[:,:,:,0].shape[0],-1)\n",
    "Y_train_binary = Y_train[:,1]\n",
    "Y_valid_binary = Y_valid[:,1]\n",
    "print(X_train_2d.shape)\n",
    "print(Y_train_binary.shape)\n",
    "print(X_valid_2d.shape)\n",
    "print(Y_valid_binary.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "clf = LogisticRegression(solver='liblinear').fit(X_train_2d, Y_train_binary)\n",
    "\n",
    "#to check the shape of the coefficient matrix\n",
    "clf.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scale = np.max(np.abs(clf.coef_))\n",
    "\n",
    "p = plt.figure(figsize=(25, 25));\n",
    "nclasses=1\n",
    "for i in range(nclasses):\n",
    "    p = plt.subplot(1, nclasses, i + 1)\n",
    "    p = plt.imshow(clf.coef_[i].reshape(96, 25).T,\n",
    "                  cmap=plt.cm.RdBu, vmin=-scale, vmax=scale);\n",
    "    p = plt.axis('off')\n",
    "    p = plt.title('positive');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AUROC for logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_valid_pred = clf.predict_proba(X_valid_2d)\n",
    "sklearn.metrics.roc_auc_score(Y_valid_binary, Y_valid_pred[:,1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### binary setup logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train_binary, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid_binary), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train_binary, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid_binary), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### multiple classification setup logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC', multi_label=True),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR', multi_label=True),\n",
    "    #keras.metrics.recall(....),\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC', multi_label=True),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR', multi_label=True),\n",
    "    keras.metrics.recall(....),\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Conv2D(64, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same',\n",
    "                        input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(1, \n",
    "                        kernel_size=(3,3),\n",
    "                        activation='relu', \n",
    "                        padding='same'),\n",
    "    keras.layers.MaxPool2D(pool_size=(1,1)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(32, activation='relu'),\n",
    "    keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_pos_img = X_train[Y_train[:,0]==1.0].mean(axis=0)\n",
    "X_train_ctrl_img = X_train[Y_train[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "X_valid_pos_img = X_valid[Y_valid[:,0]==1.0].mean(axis=0)\n",
    "X_valid_ctrl_img = X_valid[Y_valid[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "X_all_pos_img = X_all[Y_all[:,0]==1.0].mean(axis=0)\n",
    "X_all_ctrl_img = X_all[Y_all[:,0]==0.0].mean(axis=0)\n",
    "\n",
    "plot_features_map(input_image_list=[X_all_pos_img, X_all_ctrl_img,\n",
    "                                    X_train_pos_img, X_train_ctrl_img, \n",
    "                                    X_valid_pos_img, X_valid_ctrl_img],\n",
    "                  img_title_list=[\"POS (all)\", \"CTRL (all)\",\n",
    "                                  \"POS (train)\", \"CTRL (train)\", \n",
    "                                  \"POS (valid)\", \" CTRL (valid)\"],\n",
    "                  layer_idx=[0,3,6], \n",
    "                  cnn=mdl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Post-Modeling interpretation (raw scale + saliency map) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from vis.visualization import visualize_saliency\n",
    "from vis.utils import utils\n",
    "from keras import activations\n",
    "def plot_saliency(img_idx):\n",
    "    grads = visualize_saliency(mdl,\n",
    "                               \"visualized_layer\",\n",
    "                               filter_indices=Y_all[img_idx][0], \n",
    "                               seed_input=X_all[img_idx], \n",
    "                               backprop_modifier=None,\n",
    "                               grad_modifier=\"absolute\")\n",
    "    fig, ax = plt.subplots(1,2, figsize=(10,5))\n",
    "    ax[0].imshow(X_all[img_idx])\n",
    "    ax[0].set_title('original img id {}'.format(img_idx))\n",
    "    ax[1].imshow(grads, cmap='jet')\n",
    "    ax[1].set_title('saliency - predicted {}'.format(img_idx))\n",
    "\n",
    "plot_saliency(img_idx = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --- Pre-training Interpretability (standardized) ---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_all = np.load(\"./X_all.npy\")\n",
    "Y_all = np.load(\"./Y_all.npy\")\n",
    "X_train = np.load(\"./X_train.npy\")\n",
    "Y_train = np.load(\"./Y_train.npy\")\n",
    "X_valid = np.load(\"./X_valid.npy\")\n",
    "Y_valid = np.load(\"./Y_valid.npy\")\n",
    "X_test = np.load(\"./X_test.npy\")\n",
    "Y_test = np.load(\"./Y_test.npy\")\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_test shape\", X_test.shape)\n",
    "print(\"Y_test shape\", Y_test.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "X_train = (X_train - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "X_valid = (X_valid - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "X_all = (X_all - X_all.mean(axis=0))/X_all.std(axis=0)\n",
    "\n",
    "print(\"X_train shape\", X_train.shape)\n",
    "print(\"Y_train shape\", Y_train.shape)\n",
    "print(\"X_valid shape\", X_valid.shape)\n",
    "print(\"Y_valid shape\", Y_valid.shape)\n",
    "print(\"X_all shape\", X_all.shape)\n",
    "print(\"Y_all shape\", Y_all.shape)\n",
    "\n",
    "\n",
    "X_pos = X_all[Y_all[:,1]==1.0][:,:,:,0]\n",
    "X_ctrl = X_all[Y_all[:,1]==0.0][:,:,:,0]\n",
    "print(\"X_pos shape\", X_pos.shape)\n",
    "print(\"X_ctrl shape\", X_ctrl.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10): \n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_pos[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('postive episode {}'.format(i))\n",
    "\n",
    "fig, ax = plt.subplots(1,10,figsize=(20,20))\n",
    "axes = ax.flatten()\n",
    "for i in range(10):\n",
    "    norm = colors.TwoSlopeNorm(vmin = -np.max(np.abs(X_pos[i])), \n",
    "                               vcenter = 0, \n",
    "                               vmax = np.max(np.abs(X_pos[i])) )\n",
    "    axes[i].imshow(X_ctrl[i], cmap='bwr', norm=norm)\n",
    "    axes[i].set_title('control episode {}'.format(i))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 1 -- mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.mean(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.mean(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.mean(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "\n",
    "im = ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im = ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im = ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12))\n",
    "fig.colorbar(im, ax=ax[2])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistic Moment 2 -- std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_pos_stat = X_pos.std(axis=0).transpose((1,0))\n",
    "X_ctrl_stat = X_ctrl.std(axis=0).transpose((1,0))\n",
    "X_all_stat = X_all.std(axis=0)[:,:,0].transpose((1,0))\n",
    "\n",
    "norm = colors.TwoSlopeNorm(vmin = -max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ), \n",
    "                               vcenter = 0, \n",
    "                               vmax = max( np.max(np.abs(X_all_stat)),np.max(np.abs(X_pos_stat)),np.max(np.abs(X_ctrl_stat)) ) )\n",
    "\n",
    "\n",
    "fig, axes = plt.subplots(3,1, figsize=(20,20))\n",
    "ax = axes.flatten()\n",
    "im=ax[0].imshow(X_pos_stat, cmap='bwr', norm=norm)\n",
    "ax[0].set_title(\"Positive Episode\")\n",
    "ax[0].tick_params(axis='y', labelrotation=0)\n",
    "ax[0].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[0].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[0].set_xticks(range(0,96,12))\n",
    "ax[0].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[0])\n",
    "\n",
    "im=ax[1].imshow(X_ctrl_stat, cmap='bwr', norm=norm)\n",
    "ax[1].set_title(\"Control Group Episode\")\n",
    "ax[1].tick_params(axis='y', labelrotation=0)\n",
    "ax[1].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[1].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[1].set_xticks(range(0,96,12))\n",
    "ax[1].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[1])\n",
    "\n",
    "im=ax[2].imshow(X_all_stat, cmap='bwr', norm=norm)\n",
    "ax[2].set_title(\"Combined Episode\")\n",
    "ax[2].tick_params(axis='y', labelrotation=0)\n",
    "ax[2].set_yticks(range(len(bsi_stream.engineer.input_vars)))\n",
    "ax[2].set_yticklabels(bsi_stream.engineer.input_vars);\n",
    "ax[2].set_xticks(range(0,96,12))\n",
    "ax[2].set_xticklabels(range(-96,0,12));\n",
    "fig.colorbar(im, ax=ax[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 3 -- skewness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistic Moment 4 -- Kurtosis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
