{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (-24,0) to predict BSI positive VS negative and baseline \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "import scipy\n",
    "from matplotlib import colors\n",
    "\n",
    "import FAIRStream"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# csv pool folder directory\n",
    "csv_pool_path = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/csv_pool'\n",
    "# current experiment working directory\n",
    "work_dir = '/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_txp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success: Querier has initiated a csv source dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_txp/meta_data/csv_source_dict_demo.json\n",
      "Success: Querier has initiated a variable dictionary in:/Users/jiaxingqiu/Documents/CAMA_projects/BSI/code/projects/case_txp/meta_data/variable_dict_demo.json\n",
      "Unable to read sql source dictionary. Use Querier.update_sql_source_dict() to build one.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'__uid': {'src_names': ['id', 'ID', 'subject_id', 'subject_id'],\n",
       "  'label': 'unique subject id for current study',\n",
       "  'unique_per_sbj': True},\n",
       " '__time': {'src_names': ['tsa', 'tsa', 'timeMinutes', 'timeMinutes'],\n",
       "  'label': 'time since admission',\n",
       "  'unit': 'minute'},\n",
       " '__anchor': {'src_names': ['True_positive', 'True positive'],\n",
       "  'label': 'anchor for an episode',\n",
       "  'unique_per_sbj': False,\n",
       "  'factor': {'levels': {'__neg_nbc': ['0', '0.0', 'nan'],\n",
       "    '__pos': ['1', '1.0']},\n",
       "   'impute_per_sbj': {'nan_level': '__neg_nbc'}}},\n",
       " 'y': {'output': True,\n",
       "  'src_names': ['True_positive', 'True positive'],\n",
       "  'label': 'Event outcome result',\n",
       "  'unique_per_sbj': False,\n",
       "  'factor': {'levels': {'nbc': ['nan'],\n",
       "    'neg': ['0', '0.0'],\n",
       "    'pos': ['1', '1.0']},\n",
       "   'impute_per_sbj': {'nan_level': 'nbc'}}},\n",
       " 'txp': {'input': True,\n",
       "  'src_names': ['Confirmed Txp'],\n",
       "  'label': 'Transplant recipient',\n",
       "  'unique_per_sbj': True,\n",
       "  'factor': {'levels': {'no': ['0', '0.0', 'nan'], 'yes': ['1', '1.0']},\n",
       "   'impute_per_sbj': {'nan_level': 'no'}}},\n",
       " 'age': {'input': True,\n",
       "  'src_names': ['age', 'AGE'],\n",
       "  'label': 'age at admission',\n",
       "  'unique_per_sbj': True,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': 'year',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 110},\n",
       "   'impute_per_sbj': {'forward': 0, 'backward': 0}}},\n",
       " 'temp': {'input': True,\n",
       "  'src_names': ['Temp', 'tempc'],\n",
       "  'label': 'subject body temperature',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': 'celsius',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 33,\n",
       "    'value_max': 50},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'heart_rate': {'input': True,\n",
       "  'src_names': ['hr', 'heartrate'],\n",
       "  'label': 'subject heart rate',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': 'beats per minute',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 10,\n",
       "    'value_max': 200},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'resp_rate': {'input': True,\n",
       "  'src_names': ['rr', 'resprate'],\n",
       "  'label': 'subject respiratory rate',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 200},\n",
       "   'unit': 'mm Hg',\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'spo2': {'input': True,\n",
       "  'src_names': ['so2'],\n",
       "  'label': 'SpO2',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 79},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'x_hr_rr': {'input': True,\n",
       "  'src_names': ['x.hr.rr'],\n",
       "  'label': 'cross correlation between HR and resp_rate',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -1,\n",
       "    'value_max': 1},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'x_hr_spo2': {'input': True,\n",
       "  'src_names': ['x.hr.spo2'],\n",
       "  'label': 'cross correlation between HR and spo2',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -1,\n",
       "    'value_max': 1},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'x_rr_spo2': {'input': True,\n",
       "  'src_names': ['x.hr.spo2'],\n",
       "  'label': 'cross correlation between resp_rate and spo2',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -1,\n",
       "    'value_max': 1},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 's_hr': {'input': True,\n",
       "  'src_names': ['s.hr'],\n",
       "  'label': 'HR sd',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -99999,\n",
       "    'value_max': 99999},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 's_rr': {'input': True,\n",
       "  'src_names': ['s.rr'],\n",
       "  'label': 'resp_rate sd',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -99999,\n",
       "    'value_max': 99999},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 's_so2': {'input': True,\n",
       "  'src_names': ['s.so2'],\n",
       "  'label': 'SPO2 sd',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': '',\n",
       "   'cutoff': {'quantile_min': 0.0,\n",
       "    'quantile_max': 1,\n",
       "    'value_min': -99999,\n",
       "    'value_max': 99999},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'systolic_blood_pressure': {'input': True,\n",
       "  'src_names': ['SBP', 'sysbp'],\n",
       "  'label': 'subject systolic blood pressure',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': 'mm Hg',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 40,\n",
       "    'value_max': 250},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'diastolic_blood_pressure': {'input': True,\n",
       "  'src_names': ['DBP', 'diasbp'],\n",
       "  'label': 'subject diastolic blood pressure',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'unit': 'mm Hg',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 26,\n",
       "    'value_max': 150},\n",
       "   'impute_per_sbj': {'forward': 1440, 'backward': 720}}},\n",
       " 'glucose': {'input': True,\n",
       "  'src_names': ['GLUCOSE', 'Glucose'],\n",
       "  'label': 'Glucose',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 49,\n",
       "    'value_max': 460},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'bilirubin': {'input': True,\n",
       "  'src_names': ['TOTAL.BILIRUBIN', 'bilirubin'],\n",
       "  'label': 'Bilirubin',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 50},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'potassium': {'input': True,\n",
       "  'src_names': ['POTASSIUM', 'Potassium'],\n",
       "  'label': 'Potassium',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 2.4,\n",
       "    'value_max': 6.6},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'albumin': {'input': True,\n",
       "  'src_names': ['Albumin', 'ALBUMIN'],\n",
       "  'label': 'Albumin',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 5},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'calcium': {'input': True,\n",
       "  'src_names': ['CALCIUM', 'Calcium'],\n",
       "  'label': 'Calcium',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 6.1,\n",
       "    'value_max': 12},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'sodium': {'input': True,\n",
       "  'src_names': ['SODIUM', 'Sodium'],\n",
       "  'label': 'Sodium',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 119,\n",
       "    'value_max': 172},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'wbc': {'input': True,\n",
       "  'src_names': ['WHITE.BLOOD.CELL.COUNT', 'WBC'],\n",
       "  'label': 'WBC',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 33.85},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'phosphorus': {'input': True,\n",
       "  'src_names': ['PHOSPHORUS'],\n",
       "  'label': 'Phosphorus',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 5,\n",
       "    'value_max': 8},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'protin_inr': {'input': True,\n",
       "  'src_names': ['PROTIME_INR'],\n",
       "  'label': 'Protin_inr',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 5},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'creatinine': {'input': True,\n",
       "  'src_names': ['CREATININE', 'Creatinine'],\n",
       "  'label': 'Creatinine',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 10},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'platelet_count': {'input': True,\n",
       "  'src_names': ['PLATELET.COUNT', 'plateletcount'],\n",
       "  'label': 'PlateletCount',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 1001},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'alt': {'input': True,\n",
       "  'src_names': ['ALT.GPT', 'ALT'],\n",
       "  'label': 'ALT',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 1085},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'alp': {'input': True,\n",
       "  'src_names': ['ALKALINE.PHOSPHATASE', 'ALP'],\n",
       "  'label': 'ALP',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 800},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'ast': {'input': True,\n",
       "  'src_names': ['AST.GOT', 'AST'],\n",
       "  'label': 'AST',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 1203},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'pco2': {'input': True,\n",
       "  'src_names': ['PCO2', 'PaCO2'],\n",
       "  'label': 'PCO2',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 100.5},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'chloride': {'input': True,\n",
       "  'src_names': ['CHLORIDE', 'Chloride'],\n",
       "  'label': 'Chloride',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 83,\n",
       "    'value_max': 132},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'troponin': {'input': True,\n",
       "  'src_names': ['TROPONIN.I', 'Troponin'],\n",
       "  'label': 'Troponin',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 23.5},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'ptt': {'input': True,\n",
       "  'src_names': ['PARTIAL.THROMBOPLASTIN.TIME', 'PTT'],\n",
       "  'label': 'partial_thromboplastin_time',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 140},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'lactate': {'input': True,\n",
       "  'src_names': ['Lactate', 'LACTIC.ACID'],\n",
       "  'label': 'Lactate',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 19.1},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'bun': {'input': True,\n",
       "  'src_names': ['BLOOD.UREA.NITROGEN', 'BUN'],\n",
       "  'label': 'BUN',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 143},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'o2sat': {'input': True,\n",
       "  'src_names': ['OXYGEN_SATURATION'],\n",
       "  'label': 'Oxygen Satuation',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 17.6},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}},\n",
       " 'magnesium': {'input': True,\n",
       "  'src_names': ['MAGNESIUM', 'Magnesium'],\n",
       "  'label': 'Magnesium',\n",
       "  'unique_per_sbj': False,\n",
       "  'numeric': {'scaler': 'none',\n",
       "   'cutoff': {'quantile_min': 0.0001,\n",
       "    'quantile_max': 0.9999,\n",
       "    'value_min': 0,\n",
       "    'value_max': 3.4},\n",
       "   'unit': '',\n",
       "   'impute_per_sbj': {'forward': 2880, 'backward': 1440}}}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# initiate a FAIRStream object instance for BSI project\n",
    "bsi_stream = FAIRStream.FAIRStream(work_dir)\n",
    "# take a look at dictionaries in engineer's hands\n",
    "#bsi_stream.engineer.csv_source_dict\n",
    "bsi_stream.engineer.variable_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " \n",
      "Success! An episode is defined to \n",
      "--- use 2880 minute(s) long input variables \n",
      "--- predict 1440 minute(s) response variables into the future\n",
      "--- lag 0 minute(s) between predictors and responses\n",
      "--- increase by every 60 minute(s)\n",
      "--- last at most 10080 minute(s) long\n",
      "Success! Engineer has updated attributes --- episode. \n"
     ]
    }
   ],
   "source": [
    "# define an episode (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.DefineEpisode(input_time_len=2*24*60, # using vital signs and labs 4 days prior to a culture \n",
    "                                  output_time_len=24*60, # predict one time unit into the future\n",
    "                                  time_resolution=60, # aggregate minutely data to one row per hour \n",
    "                                  time_lag=0,  # no time lag between predictors and response\n",
    "                                  anchor_gap=7*24*60) # the minimum distance between two episodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Engineer is sampling with replacement --- \n",
      "Success!  60 out of 5671 subjects are sampled from csv pool of size 26093 !\n",
      "--- fix upper boundary for age by nan\n",
      "--- fix lower boundary for age by nan\n",
      "--- fix upper boundary for temp by nan\n",
      "--- fix lower boundary for temp by nan\n",
      "--- fix upper boundary for heart_rate by nan\n",
      "--- fix lower boundary for heart_rate by nan\n",
      "--- fix upper boundary for resp_rate by nan\n",
      "--- fix lower boundary for resp_rate by nan\n",
      "--- fix upper boundary for spo2 by nan\n",
      "--- fix lower boundary for spo2 by nan\n",
      "--- fix upper boundary for x_hr_rr by nan\n",
      "--- fix lower boundary for x_hr_rr by nan\n",
      "--- fix upper boundary for s_hr by nan\n",
      "--- fix lower boundary for s_hr by nan\n",
      "--- fix upper boundary for s_rr by nan\n",
      "--- fix lower boundary for s_rr by nan\n",
      "--- fix upper boundary for s_so2 by nan\n",
      "--- fix lower boundary for s_so2 by nan\n",
      "--- fix upper boundary for systolic_blood_pressure by nan\n",
      "--- fix lower boundary for systolic_blood_pressure by nan\n",
      "--- fix upper boundary for diastolic_blood_pressure by nan\n",
      "--- fix lower boundary for diastolic_blood_pressure by nan\n",
      "--- fix upper boundary for glucose by nan\n",
      "--- fix lower boundary for glucose by nan\n",
      "--- fix upper boundary for bilirubin by nan\n",
      "--- fix lower boundary for bilirubin by nan\n",
      "--- fix upper boundary for potassium by nan\n",
      "--- fix lower boundary for potassium by nan\n",
      "--- fix upper boundary for albumin by nan\n",
      "--- fix lower boundary for albumin by nan\n",
      "--- fix upper boundary for calcium by nan\n",
      "--- fix lower boundary for calcium by nan\n",
      "--- fix upper boundary for sodium by nan\n",
      "--- fix lower boundary for sodium by nan\n",
      "--- fix upper boundary for wbc by nan\n",
      "--- fix lower boundary for wbc by nan\n",
      "--- fix upper boundary for phosphorus by nan\n",
      "--- fix lower boundary for phosphorus by nan\n",
      "--- fix upper boundary for creatinine by nan\n",
      "--- fix lower boundary for creatinine by nan\n",
      "--- fix upper boundary for platelet_count by nan\n",
      "--- fix lower boundary for platelet_count by nan\n",
      "--- fix upper boundary for alt by nan\n",
      "--- fix lower boundary for alt by nan\n",
      "--- fix upper boundary for alp by nan\n",
      "--- fix lower boundary for alp by nan\n",
      "--- fix upper boundary for ast by nan\n",
      "--- fix lower boundary for ast by nan\n",
      "--- fix upper boundary for pco2 by nan\n",
      "--- fix lower boundary for pco2 by nan\n",
      "--- fix upper boundary for chloride by nan\n",
      "--- fix lower boundary for chloride by nan\n",
      "--- fix upper boundary for troponin by nan\n",
      "--- fix lower boundary for troponin by nan\n",
      "--- fix upper boundary for ptt by nan\n",
      "--- fix lower boundary for ptt by nan\n",
      "--- fix upper boundary for lactate by nan\n",
      "--- fix lower boundary for lactate by nan\n",
      "--- fix upper boundary for bun by nan\n",
      "--- fix lower boundary for bun by nan\n",
      "--- fix upper boundary for magnesium by nan\n",
      "--- fix lower boundary for magnesium by nan\n",
      "--- fix out-of-dictionry level/orders --- [' ']--- with NA for subject ---uva_4693\n",
      "--- prepare episodes for uva_3806\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1651\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_2752\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_300\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1928\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3479\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8901\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    1.0\n",
      "y___pos    0.0\n",
      "y___nbc    0.0\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7043\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.777778\n",
      "y___pos    0.111111\n",
      "y___nbc    0.111111\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5357\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.8\n",
      "y___pos    0.1\n",
      "y___nbc    0.1\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1847\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.727273\n",
      "y___pos    0.090909\n",
      "y___nbc    0.181818\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_6631\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.750000\n",
      "y___pos    0.083333\n",
      "y___nbc    0.166667\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5950\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.769231\n",
      "y___pos    0.076923\n",
      "y___nbc    0.153846\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_526\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.785714\n",
      "y___pos    0.071429\n",
      "y___nbc    0.142857\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4612\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.733333\n",
      "y___pos    0.066667\n",
      "y___nbc    0.200000\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3542\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.7500\n",
      "y___pos    0.0625\n",
      "y___nbc    0.1875\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4629\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.764706\n",
      "y___pos    0.058824\n",
      "y___nbc    0.176471\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1565\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.777778\n",
      "y___pos    0.055556\n",
      "y___nbc    0.166667\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1127\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.789474\n",
      "y___pos    0.052632\n",
      "y___nbc    0.157895\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5319\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.80\n",
      "y___pos    0.05\n",
      "y___nbc    0.15\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_6311\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.809524\n",
      "y___pos    0.047619\n",
      "y___nbc    0.142857\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8808\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.818182\n",
      "y___pos    0.045455\n",
      "y___nbc    0.136364\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_228\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.826087\n",
      "y___pos    0.043478\n",
      "y___nbc    0.130435\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_104\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.750000\n",
      "y___pos    0.107143\n",
      "y___nbc    0.142857\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3177\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.758621\n",
      "y___pos    0.103448\n",
      "y___nbc    0.137931\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_9150\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.766667\n",
      "y___pos    0.100000\n",
      "y___nbc    0.133333\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_553\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.774194\n",
      "y___pos    0.096774\n",
      "y___nbc    0.129032\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4180\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.78125\n",
      "y___pos    0.09375\n",
      "y___nbc    0.12500\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5637\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.787879\n",
      "y___pos    0.090909\n",
      "y___nbc    0.121212\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_6586\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.794118\n",
      "y___pos    0.088235\n",
      "y___nbc    0.117647\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8371\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.777778\n",
      "y___pos    0.111111\n",
      "y___nbc    0.111111\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_696\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.783784\n",
      "y___pos    0.108108\n",
      "y___nbc    0.108108\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3345\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.789474\n",
      "y___pos    0.105263\n",
      "y___nbc    0.105263\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.769231\n",
      "y___pos    0.102564\n",
      "y___nbc    0.128205\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_291\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.775\n",
      "y___pos    0.100\n",
      "y___nbc    0.125\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_2531\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.780488\n",
      "y___pos    0.097561\n",
      "y___nbc    0.121951\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8255\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.785714\n",
      "y___pos    0.095238\n",
      "y___nbc    0.119048\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7943\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.772727\n",
      "y___pos    0.090909\n",
      "y___nbc    0.136364\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7605\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.777778\n",
      "y___pos    0.088889\n",
      "y___nbc    0.133333\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_72\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.782609\n",
      "y___pos    0.086957\n",
      "y___nbc    0.130435\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1863\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.787234\n",
      "y___pos    0.085106\n",
      "y___nbc    0.127660\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3451\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.791667\n",
      "y___pos    0.083333\n",
      "y___nbc    0.125000\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_6247\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.795918\n",
      "y___pos    0.081633\n",
      "y___nbc    0.122449\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3956\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.78\n",
      "y___pos    0.10\n",
      "y___nbc    0.12\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4068\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.764706\n",
      "y___pos    0.098039\n",
      "y___nbc    0.137255\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_2945\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.769231\n",
      "y___pos    0.096154\n",
      "y___nbc    0.134615\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4693\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.773585\n",
      "y___pos    0.094340\n",
      "y___nbc    0.132075\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7156\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.777778\n",
      "y___pos    0.092593\n",
      "y___nbc    0.129630\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4964\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.781818\n",
      "y___pos    0.090909\n",
      "y___nbc    0.127273\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1273\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.785714\n",
      "y___pos    0.089286\n",
      "y___nbc    0.125000\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7530\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.789474\n",
      "y___pos    0.087719\n",
      "y___nbc    0.122807\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7467\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.793103\n",
      "y___pos    0.086207\n",
      "y___nbc    0.120690\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_5900\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.796610\n",
      "y___pos    0.084746\n",
      "y___nbc    0.118644\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1605\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.800000\n",
      "y___pos    0.083333\n",
      "y___nbc    0.116667\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_1846\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.803279\n",
      "y___pos    0.081967\n",
      "y___nbc    0.114754\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_4833\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.806452\n",
      "y___pos    0.080645\n",
      "y___nbc    0.112903\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_3027\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.793651\n",
      "y___pos    0.079365\n",
      "y___nbc    0.126984\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8333\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.796875\n",
      "y___pos    0.078125\n",
      "y___nbc    0.125000\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_7446\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.800000\n",
      "y___pos    0.076923\n",
      "y___nbc    0.123077\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_8496\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.803030\n",
      "y___pos    0.075758\n",
      "y___nbc    0.121212\n",
      "dtype: float64\n",
      "--- prepare episodes for uva_434\n",
      "Success! Output/responce variable mean in current sample space  --- \n",
      "y___neg    0.805970\n",
      "y___pos    0.074627\n",
      "y___nbc    0.119403\n",
      "dtype: float64\n",
      "Success! Engineer has updated attributes --- mvts_df, input_vars, output_vars. \n",
      "Success! Engineer has updated attributes --- train_df, valid_df and test_df. \n",
      "Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
      "Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. \n"
     ]
    }
   ],
   "source": [
    "# Build MVTS dataframe or tfds  (notice that the engineer now has new attributes)\n",
    "bsi_stream.engineer.BuildMVTS(csv_pool_path, \n",
    "                              #nsbj = 6000, # number of subjects / patients to sample from the pool \n",
    "                              nsbj = 60, # number of subjects / patients to sample from the pool \n",
    "                              replace=True, # sample with replacement or not \n",
    "                              valid_frac = 0.2, # fraction of number of subjects in validation dataset\n",
    "                              test_frac = 0, # fraction of number of subjects in left-out test dataset\n",
    "                              batch_size = 64, # batch size (usually 32,64,128..)\n",
    "                              impute_input='median', # imputation on predictors\n",
    "                              impute_output='median' )# imputation on response (no need in BSI project)\n",
    "\n",
    "# please see the end of console \n",
    "# # --- Success! Engineer has updated attributes --- train_df_imputed, valid_df_imputed and test_df_imputed. \n",
    "# # --- Success! Engineer has updated attributes --- train_tfds, valid_tfds and test_tfds. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "----------------------------- Engineer Attributes List ------------------------\n",
      "\n",
      "['work_dir', 'meta_dir', 'variable_dict', 'csv_source_dict', 'sql_source_dict', 'input_vars', 'output_vars', 'episode', 'sample_info', 'mvts_df', 'mvts_tfds', 'train_df', 'valid_df', 'test_df', 'train_df_imputed', 'valid_df_imputed', 'test_df_imputed', 'train_tfds', 'valid_tfds', 'test_tfds', 'df_csv_fullname_ls']\n",
      "\n",
      "------------------------------------- Inputs  --------------------------------- \n",
      "\n",
      "['txp___yes', 'txp___no', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
      "\n",
      "------------------------------------- Outputs --------------------------------- \n",
      "\n",
      "['y___neg', 'y___pos', 'y___nbc']\n",
      "\n",
      "------------------ train_tfds / valid_tfds / test_tfds batch shape --------------\n",
      "\n",
      "Inputs shape (batch size, time bins, variables): (55, 48, 33)\n",
      "Labels shape (batch size, time bins, variables): (55, 24, 3)\n",
      "\n",
      "---------------------- train_df / train_df_imputed shape ---------------------- \n",
      "\n",
      "(3960, 41)\n",
      "\n",
      "---------------------- valid_df / valid_df_imputed shape ---------------------- \n",
      "\n",
      "(864, 41)\n",
      "\n",
      "------------------------ test_df / test_df_imputed shape ---------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bsi_stream.engineer.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save raw dataframe in a csv\n",
    "# bsi_stream.engineer.train_df.to_csv(\"./train_df.csv\", index=False)\n",
    "# bsi_stream.engineer.valid_df.to_csv(\"./valid_df.csv\", index=False)\n",
    "# bsi_stream.engineer.train_df_imputed.to_csv(\"./train_df_median.csv\", index=False)\n",
    "# bsi_stream.engineer.valid_df_imputed.to_csv(\"./valid_df_median.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modeling -- Binary classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>txp___yes</th>\n",
       "      <th>txp___no</th>\n",
       "      <th>age___vital</th>\n",
       "      <th>temp___vital</th>\n",
       "      <th>heart_rate___vital</th>\n",
       "      <th>resp_rate___vital</th>\n",
       "      <th>spo2___vital</th>\n",
       "      <th>x_hr_rr___vital</th>\n",
       "      <th>s_hr___vital</th>\n",
       "      <th>s_rr___vital</th>\n",
       "      <th>...</th>\n",
       "      <th>ptt___vital</th>\n",
       "      <th>lactate___vital</th>\n",
       "      <th>bun___vital</th>\n",
       "      <th>magnesium___vital</th>\n",
       "      <th>y___pos</th>\n",
       "      <th>y___neg</th>\n",
       "      <th>y___nbc</th>\n",
       "      <th>__time_bin</th>\n",
       "      <th>__ep_relative_time</th>\n",
       "      <th>__ep_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>count</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "      <td>163925.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>mean</td>\n",
       "      <td>0.031569</td>\n",
       "      <td>0.959280</td>\n",
       "      <td>59.053610</td>\n",
       "      <td>98.130162</td>\n",
       "      <td>92.198995</td>\n",
       "      <td>22.233793</td>\n",
       "      <td>97.465885</td>\n",
       "      <td>0.200550</td>\n",
       "      <td>3.772581</td>\n",
       "      <td>4.182335</td>\n",
       "      <td>...</td>\n",
       "      <td>31.718885</td>\n",
       "      <td>2.142800</td>\n",
       "      <td>28.747296</td>\n",
       "      <td>1.894027</td>\n",
       "      <td>0.133750</td>\n",
       "      <td>0.658685</td>\n",
       "      <td>0.207564</td>\n",
       "      <td>73.844136</td>\n",
       "      <td>-720.000000</td>\n",
       "      <td>1.208327</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>std</td>\n",
       "      <td>0.174851</td>\n",
       "      <td>0.197641</td>\n",
       "      <td>16.534095</td>\n",
       "      <td>1.284749</td>\n",
       "      <td>9.032714</td>\n",
       "      <td>3.062896</td>\n",
       "      <td>1.312926</td>\n",
       "      <td>0.087419</td>\n",
       "      <td>1.484878</td>\n",
       "      <td>1.399994</td>\n",
       "      <td>...</td>\n",
       "      <td>9.304526</td>\n",
       "      <td>1.845225</td>\n",
       "      <td>22.660112</td>\n",
       "      <td>0.340634</td>\n",
       "      <td>0.340385</td>\n",
       "      <td>0.474152</td>\n",
       "      <td>0.405564</td>\n",
       "      <td>444.434054</td>\n",
       "      <td>432.667473</td>\n",
       "      <td>0.672273</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>min</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.101500</td>\n",
       "      <td>60.800000</td>\n",
       "      <td>39.448590</td>\n",
       "      <td>5.735512</td>\n",
       "      <td>80.141327</td>\n",
       "      <td>-0.630122</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>19.200000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-4235.000000</td>\n",
       "      <td>-1440.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>25%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>49.424096</td>\n",
       "      <td>98.100000</td>\n",
       "      <td>91.940753</td>\n",
       "      <td>22.072590</td>\n",
       "      <td>97.606914</td>\n",
       "      <td>0.195842</td>\n",
       "      <td>3.616698</td>\n",
       "      <td>4.083966</td>\n",
       "      <td>...</td>\n",
       "      <td>27.700000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.800000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-15.000000</td>\n",
       "      <td>-1080.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>50%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>60.267953</td>\n",
       "      <td>98.100000</td>\n",
       "      <td>91.940753</td>\n",
       "      <td>22.072590</td>\n",
       "      <td>97.606914</td>\n",
       "      <td>0.195842</td>\n",
       "      <td>3.616698</td>\n",
       "      <td>4.083966</td>\n",
       "      <td>...</td>\n",
       "      <td>29.700000</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-7.000000</td>\n",
       "      <td>-720.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>75%</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>71.116943</td>\n",
       "      <td>98.100000</td>\n",
       "      <td>91.940753</td>\n",
       "      <td>22.072590</td>\n",
       "      <td>97.606914</td>\n",
       "      <td>0.195842</td>\n",
       "      <td>3.616698</td>\n",
       "      <td>4.083966</td>\n",
       "      <td>...</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>1.900000</td>\n",
       "      <td>34.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-360.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>max</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>105.100000</td>\n",
       "      <td>168.179487</td>\n",
       "      <td>70.228390</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.928040</td>\n",
       "      <td>47.721125</td>\n",
       "      <td>17.975902</td>\n",
       "      <td>...</td>\n",
       "      <td>136.000000</td>\n",
       "      <td>34.200000</td>\n",
       "      <td>246.000000</td>\n",
       "      <td>7.900000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>16454.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows  39 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           txp___yes       txp___no    age___vital   temp___vital  \\\n",
       "count  163925.000000  163925.000000  163925.000000  163925.000000   \n",
       "mean        0.031569       0.959280      59.053610      98.130162   \n",
       "std         0.174851       0.197641      16.534095       1.284749   \n",
       "min         0.000000       0.000000      14.101500      60.800000   \n",
       "25%         0.000000       1.000000      49.424096      98.100000   \n",
       "50%         0.000000       1.000000      60.267953      98.100000   \n",
       "75%         0.000000       1.000000      71.116943      98.100000   \n",
       "max         1.000000       1.000000      90.000000     105.100000   \n",
       "\n",
       "       heart_rate___vital  resp_rate___vital   spo2___vital  x_hr_rr___vital  \\\n",
       "count       163925.000000      163925.000000  163925.000000    163925.000000   \n",
       "mean            92.198995          22.233793      97.465885         0.200550   \n",
       "std              9.032714           3.062896       1.312926         0.087419   \n",
       "min             39.448590           5.735512      80.141327        -0.630122   \n",
       "25%             91.940753          22.072590      97.606914         0.195842   \n",
       "50%             91.940753          22.072590      97.606914         0.195842   \n",
       "75%             91.940753          22.072590      97.606914         0.195842   \n",
       "max            168.179487          70.228390     100.000000         0.928040   \n",
       "\n",
       "        s_hr___vital   s_rr___vital  ...    ptt___vital  lactate___vital  \\\n",
       "count  163925.000000  163925.000000  ...  163925.000000    163925.000000   \n",
       "mean        3.772581       4.182335  ...      31.718885         2.142800   \n",
       "std         1.484878       1.399994  ...       9.304526         1.845225   \n",
       "min         0.000000       0.000000  ...      19.200000         0.200000   \n",
       "25%         3.616698       4.083966  ...      27.700000         1.600000   \n",
       "50%         3.616698       4.083966  ...      29.700000         1.700000   \n",
       "75%         3.616698       4.083966  ...      32.000000         1.900000   \n",
       "max        47.721125      17.975902  ...     136.000000        34.200000   \n",
       "\n",
       "         bun___vital  magnesium___vital        y___pos        y___neg  \\\n",
       "count  163925.000000      163925.000000  163925.000000  163925.000000   \n",
       "mean       28.747296           1.894027       0.133750       0.658685   \n",
       "std        22.660112           0.340634       0.340385       0.474152   \n",
       "min         2.000000           0.600000       0.000000       0.000000   \n",
       "25%        15.000000           1.800000       0.000000       0.000000   \n",
       "50%        22.000000           1.900000       0.000000       1.000000   \n",
       "75%        34.000000           2.000000       0.000000       1.000000   \n",
       "max       246.000000           7.900000       1.000000       1.000000   \n",
       "\n",
       "             y___nbc     __time_bin  __ep_relative_time     __ep_order  \n",
       "count  163925.000000  163925.000000       163925.000000  163925.000000  \n",
       "mean        0.207564      73.844136         -720.000000       1.208327  \n",
       "std         0.405564     444.434054          432.667473       0.672273  \n",
       "min         0.000000   -4235.000000        -1440.000000       1.000000  \n",
       "25%         0.000000     -15.000000        -1080.000000       1.000000  \n",
       "50%         0.000000      -7.000000         -720.000000       1.000000  \n",
       "75%         0.000000       0.000000         -360.000000       1.000000  \n",
       "max         1.000000   16454.000000            0.000000      14.000000  \n",
       "\n",
       "[8 rows x 39 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read datasets\n",
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "\n",
    "# select modeling time window\n",
    "train_df = train_df.loc[(train_df['__ep_relative_time']/60>=-24) & (train_df['__ep_relative_time']/60<=0) ,:]\n",
    "valid_df = valid_df.loc[(valid_df['__ep_relative_time']/60>=-24) & (valid_df['__ep_relative_time']/60<=0) ,:]\n",
    "\n",
    "# median imputation\n",
    "train_df.fillna(train_df.median(), inplace=True)\n",
    "valid_df.fillna(train_df.median(), inplace=True)\n",
    "\n",
    "# input and output variable name lists\n",
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos']\n",
    "\n",
    "# # standardize inputs\n",
    "# train_df[input_vars] = (train_df[input_vars] - train_df[input_vars].mean(axis=0))/train_df[input_vars].std(axis=0)\n",
    "# valid_df[input_vars] = (valid_df[input_vars] - train_df[input_vars].mean(axis=0))/train_df[input_vars].std(axis=0)\n",
    "\n",
    "# combine to one dataframe\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "whole_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 25, 32)\n",
      "(6557, 1)\n",
      "(5226, 25, 32)\n",
      "(5226, 1)\n",
      "(1331, 25, 32)\n",
      "(1331, 1)\n"
     ]
    }
   ],
   "source": [
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,25,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,25,1) )[:,0,:]\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_train = train_df[input_vars].values\n",
    "Y_train = train_df[output_var].values\n",
    "X_train = np.reshape(X_train, (-1,25,32) )\n",
    "Y_train = np.reshape(Y_train, (-1,25,1) )[:,0,:]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_valid = valid_df[input_vars].values\n",
    "Y_valid = valid_df[output_var].values\n",
    "X_valid = np.reshape(X_valid, (-1,25,32) )\n",
    "Y_valid = np.reshape(Y_valid, (-1,25,1) )[:,0,:]\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "flatten (Flatten)            (None, 800)               0         \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 800)               3200      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 801       \n",
      "=================================================================\n",
      "Total params: 4,001\n",
      "Trainable params: 2,401\n",
      "Non-trainable params: 1,600\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 1s 3ms/step - loss: 0.5155 - AUROC: 0.6206 - AUPRC: 0.2190 - val_loss: 4.0327 - val_AUROC: 0.6906 - val_AUPRC: 0.2402\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3186 - AUROC: 0.7947 - AUPRC: 0.4381 - val_loss: 0.3889 - val_AUROC: 0.7458 - val_AUPRC: 0.3872\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3159 - AUROC: 0.8042 - AUPRC: 0.4560 - val_loss: 0.3651 - val_AUROC: 0.7473 - val_AUPRC: 0.4012\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3113 - AUROC: 0.8216 - AUPRC: 0.4720 - val_loss: 0.3587 - val_AUROC: 0.7544 - val_AUPRC: 0.4070\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3021 - AUROC: 0.8133 - AUPRC: 0.4650 - val_loss: 0.3526 - val_AUROC: 0.7605 - val_AUPRC: 0.4133\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3096 - AUROC: 0.8139 - AUPRC: 0.4546 - val_loss: 0.3564 - val_AUROC: 0.7587 - val_AUPRC: 0.4113\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3120 - AUROC: 0.8135 - AUPRC: 0.4883 - val_loss: 0.3561 - val_AUROC: 0.7719 - val_AUPRC: 0.4259\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3276 - AUROC: 0.8031 - AUPRC: 0.4475 - val_loss: 0.3580 - val_AUROC: 0.7707 - val_AUPRC: 0.4218\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3057 - AUROC: 0.8210 - AUPRC: 0.4550 - val_loss: 0.3526 - val_AUROC: 0.7697 - val_AUPRC: 0.4193\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2969 - AUROC: 0.8389 - AUPRC: 0.5106 - val_loss: 0.3520 - val_AUROC: 0.7685 - val_AUPRC: 0.4292\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2969 - AUROC: 0.8249 - AUPRC: 0.4988 - val_loss: 0.3514 - val_AUROC: 0.7692 - val_AUPRC: 0.4174\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3087 - AUROC: 0.8218 - AUPRC: 0.5040 - val_loss: 0.3551 - val_AUROC: 0.7751 - val_AUPRC: 0.4210\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2935 - AUROC: 0.8222 - AUPRC: 0.4946 - val_loss: 0.3532 - val_AUROC: 0.7783 - val_AUPRC: 0.4223\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3004 - AUROC: 0.8293 - AUPRC: 0.5032 - val_loss: 0.3603 - val_AUROC: 0.7647 - val_AUPRC: 0.4187\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2987 - AUROC: 0.8297 - AUPRC: 0.5169 - val_loss: 0.3509 - val_AUROC: 0.7765 - val_AUPRC: 0.4240\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3043 - AUROC: 0.8180 - AUPRC: 0.5045 - val_loss: 0.3489 - val_AUROC: 0.7687 - val_AUPRC: 0.4420\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2957 - AUROC: 0.8308 - AUPRC: 0.4924 - val_loss: 0.3585 - val_AUROC: 0.7641 - val_AUPRC: 0.4199\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2980 - AUROC: 0.8387 - AUPRC: 0.5305 - val_loss: 0.3483 - val_AUROC: 0.7717 - val_AUPRC: 0.4547\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3078 - AUROC: 0.8294 - AUPRC: 0.5118 - val_loss: 0.3506 - val_AUROC: 0.7792 - val_AUPRC: 0.4248\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2830 - AUROC: 0.8297 - AUPRC: 0.4829 - val_loss: 0.3455 - val_AUROC: 0.7745 - val_AUPRC: 0.4566\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3088 - AUROC: 0.8137 - AUPRC: 0.4709 - val_loss: 0.3512 - val_AUROC: 0.7780 - val_AUPRC: 0.4300\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.3070 - AUROC: 0.8198 - AUPRC: 0.5102 - val_loss: 0.3605 - val_AUROC: 0.7725 - val_AUPRC: 0.4222\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2996 - AUROC: 0.8349 - AUPRC: 0.5301 - val_loss: 0.3543 - val_AUROC: 0.7687 - val_AUPRC: 0.4381\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2840 - AUROC: 0.8508 - AUPRC: 0.5360 - val_loss: 0.3467 - val_AUROC: 0.7837 - val_AUPRC: 0.4489\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2794 - AUROC: 0.8481 - AUPRC: 0.5137 - val_loss: 0.3513 - val_AUROC: 0.7797 - val_AUPRC: 0.4281\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2721 - AUROC: 0.8545 - AUPRC: 0.5264 - val_loss: 0.3490 - val_AUROC: 0.7801 - val_AUPRC: 0.4578\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2842 - AUROC: 0.8541 - AUPRC: 0.5601 - val_loss: 0.3501 - val_AUROC: 0.7831 - val_AUPRC: 0.4387\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2935 - AUROC: 0.8334 - AUPRC: 0.5046 - val_loss: 0.3598 - val_AUROC: 0.7709 - val_AUPRC: 0.4328\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2959 - AUROC: 0.8277 - AUPRC: 0.5137 - val_loss: 0.3652 - val_AUROC: 0.7725 - val_AUPRC: 0.4243\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2839 - AUROC: 0.8534 - AUPRC: 0.5683 - val_loss: 0.3550 - val_AUROC: 0.7817 - val_AUPRC: 0.4377\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2802 - AUROC: 0.8519 - AUPRC: 0.5591 - val_loss: 0.3491 - val_AUROC: 0.7833 - val_AUPRC: 0.4471\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2740 - AUROC: 0.8591 - AUPRC: 0.5760 - val_loss: 0.3496 - val_AUROC: 0.7828 - val_AUPRC: 0.4433\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2803 - AUROC: 0.8551 - AUPRC: 0.5542 - val_loss: 0.3489 - val_AUROC: 0.7814 - val_AUPRC: 0.4460\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2774 - AUROC: 0.8583 - AUPRC: 0.5594 - val_loss: 0.3492 - val_AUROC: 0.7813 - val_AUPRC: 0.4454\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2817 - AUROC: 0.8484 - AUPRC: 0.5537 - val_loss: 0.3469 - val_AUROC: 0.7800 - val_AUPRC: 0.4470\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2773 - AUROC: 0.8547 - AUPRC: 0.5650 - val_loss: 0.3466 - val_AUROC: 0.7803 - val_AUPRC: 0.4460\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2778 - AUROC: 0.8548 - AUPRC: 0.5656 - val_loss: 0.3493 - val_AUROC: 0.7802 - val_AUPRC: 0.4414\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2800 - AUROC: 0.8532 - AUPRC: 0.5590 - val_loss: 0.3516 - val_AUROC: 0.7803 - val_AUPRC: 0.4408\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2785 - AUROC: 0.8525 - AUPRC: 0.5636 - val_loss: 0.3497 - val_AUROC: 0.7801 - val_AUPRC: 0.4425\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2758 - AUROC: 0.8563 - AUPRC: 0.5729 - val_loss: 0.3503 - val_AUROC: 0.7789 - val_AUPRC: 0.4403\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2763 - AUROC: 0.8557 - AUPRC: 0.5704 - val_loss: 0.3518 - val_AUROC: 0.7798 - val_AUPRC: 0.4396\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2755 - AUROC: 0.8562 - AUPRC: 0.5714 - val_loss: 0.3511 - val_AUROC: 0.7783 - val_AUPRC: 0.4422\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2800 - AUROC: 0.8559 - AUPRC: 0.5483 - val_loss: 0.3511 - val_AUROC: 0.7780 - val_AUPRC: 0.4398\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2754 - AUROC: 0.8589 - AUPRC: 0.5693 - val_loss: 0.3528 - val_AUROC: 0.7792 - val_AUPRC: 0.4367\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2811 - AUROC: 0.8543 - AUPRC: 0.5467 - val_loss: 0.3490 - val_AUROC: 0.7788 - val_AUPRC: 0.4420\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2786 - AUROC: 0.8575 - AUPRC: 0.5548 - val_loss: 0.3480 - val_AUROC: 0.7799 - val_AUPRC: 0.4453\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2757 - AUROC: 0.8598 - AUPRC: 0.5697 - val_loss: 0.3491 - val_AUROC: 0.7805 - val_AUPRC: 0.4428\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2726 - AUROC: 0.8577 - AUPRC: 0.5833 - val_loss: 0.3479 - val_AUROC: 0.7797 - val_AUPRC: 0.4439\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2758 - AUROC: 0.8566 - AUPRC: 0.5718 - val_loss: 0.3490 - val_AUROC: 0.7808 - val_AUPRC: 0.4435\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2753 - AUROC: 0.8602 - AUPRC: 0.5701 - val_loss: 0.3495 - val_AUROC: 0.7801 - val_AUPRC: 0.4429\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2741 - AUROC: 0.8574 - AUPRC: 0.5785 - val_loss: 0.3481 - val_AUROC: 0.7798 - val_AUPRC: 0.4432\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2789 - AUROC: 0.8545 - AUPRC: 0.5595 - val_loss: 0.3490 - val_AUROC: 0.7803 - val_AUPRC: 0.4433\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2731 - AUROC: 0.8586 - AUPRC: 0.5804 - val_loss: 0.3485 - val_AUROC: 0.7793 - val_AUPRC: 0.4434\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2796 - AUROC: 0.8548 - AUPRC: 0.5586 - val_loss: 0.3493 - val_AUROC: 0.7806 - val_AUPRC: 0.4431\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2749 - AUROC: 0.8570 - AUPRC: 0.5744 - val_loss: 0.3501 - val_AUROC: 0.7803 - val_AUPRC: 0.4415\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2751 - AUROC: 0.8588 - AUPRC: 0.5732 - val_loss: 0.3505 - val_AUROC: 0.7786 - val_AUPRC: 0.4409\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2765 - AUROC: 0.8595 - AUPRC: 0.5626 - val_loss: 0.3500 - val_AUROC: 0.7799 - val_AUPRC: 0.4412\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2807 - AUROC: 0.8507 - AUPRC: 0.5586 - val_loss: 0.3491 - val_AUROC: 0.7787 - val_AUPRC: 0.4424\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2773 - AUROC: 0.8602 - AUPRC: 0.5587 - val_loss: 0.3500 - val_AUROC: 0.7790 - val_AUPRC: 0.4419\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2736 - AUROC: 0.8582 - AUPRC: 0.5777 - val_loss: 0.3505 - val_AUROC: 0.7800 - val_AUPRC: 0.4407\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2739 - AUROC: 0.8614 - AUPRC: 0.5687 - val_loss: 0.3472 - val_AUROC: 0.7791 - val_AUPRC: 0.4447\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2782 - AUROC: 0.8548 - AUPRC: 0.5615 - val_loss: 0.3478 - val_AUROC: 0.7783 - val_AUPRC: 0.4432\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2731 - AUROC: 0.8627 - AUPRC: 0.5762 - val_loss: 0.3485 - val_AUROC: 0.7785 - val_AUPRC: 0.4425\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2770 - AUROC: 0.8602 - AUPRC: 0.5587 - val_loss: 0.3508 - val_AUROC: 0.7799 - val_AUPRC: 0.4406\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2750 - AUROC: 0.8590 - AUPRC: 0.5734 - val_loss: 0.3496 - val_AUROC: 0.7796 - val_AUPRC: 0.4415\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2715 - AUROC: 0.8619 - AUPRC: 0.5858 - val_loss: 0.3510 - val_AUROC: 0.7788 - val_AUPRC: 0.4400\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2793 - AUROC: 0.8542 - AUPRC: 0.5576 - val_loss: 0.3492 - val_AUROC: 0.7796 - val_AUPRC: 0.4433\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2741 - AUROC: 0.8579 - AUPRC: 0.5756 - val_loss: 0.3496 - val_AUROC: 0.7795 - val_AUPRC: 0.4417\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2764 - AUROC: 0.8539 - AUPRC: 0.5703 - val_loss: 0.3484 - val_AUROC: 0.7785 - val_AUPRC: 0.4424\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2757 - AUROC: 0.8589 - AUPRC: 0.5656 - val_loss: 0.3480 - val_AUROC: 0.7790 - val_AUPRC: 0.4439\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2719 - AUROC: 0.8625 - AUPRC: 0.5823 - val_loss: 0.3479 - val_AUROC: 0.7790 - val_AUPRC: 0.4440\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2759 - AUROC: 0.8617 - AUPRC: 0.5653 - val_loss: 0.3505 - val_AUROC: 0.7795 - val_AUPRC: 0.4422\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2750 - AUROC: 0.8632 - AUPRC: 0.5675 - val_loss: 0.3478 - val_AUROC: 0.7799 - val_AUPRC: 0.4442\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2741 - AUROC: 0.8561 - AUPRC: 0.5787 - val_loss: 0.3498 - val_AUROC: 0.7799 - val_AUPRC: 0.4430\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2722 - AUROC: 0.8600 - AUPRC: 0.5883 - val_loss: 0.3488 - val_AUROC: 0.7809 - val_AUPRC: 0.4433\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2723 - AUROC: 0.8628 - AUPRC: 0.5773 - val_loss: 0.3477 - val_AUROC: 0.7801 - val_AUPRC: 0.4439\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2730 - AUROC: 0.8617 - AUPRC: 0.5773 - val_loss: 0.3501 - val_AUROC: 0.7801 - val_AUPRC: 0.4424\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2772 - AUROC: 0.8543 - AUPRC: 0.5688 - val_loss: 0.3501 - val_AUROC: 0.7793 - val_AUPRC: 0.4422\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2757 - AUROC: 0.8574 - AUPRC: 0.5674 - val_loss: 0.3513 - val_AUROC: 0.7791 - val_AUPRC: 0.4412\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2789 - AUROC: 0.8516 - AUPRC: 0.5612 - val_loss: 0.3476 - val_AUROC: 0.7796 - val_AUPRC: 0.4451\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2752 - AUROC: 0.8575 - AUPRC: 0.5698 - val_loss: 0.3502 - val_AUROC: 0.7800 - val_AUPRC: 0.4413\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2736 - AUROC: 0.8593 - AUPRC: 0.5816 - val_loss: 0.3505 - val_AUROC: 0.7794 - val_AUPRC: 0.4408\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2808 - AUROC: 0.8529 - AUPRC: 0.5558 - val_loss: 0.3503 - val_AUROC: 0.7790 - val_AUPRC: 0.4407\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2775 - AUROC: 0.8570 - AUPRC: 0.5577 - val_loss: 0.3494 - val_AUROC: 0.7788 - val_AUPRC: 0.4405\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2725 - AUROC: 0.8596 - AUPRC: 0.5819 - val_loss: 0.3519 - val_AUROC: 0.7792 - val_AUPRC: 0.4401\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2771 - AUROC: 0.8587 - AUPRC: 0.5610 - val_loss: 0.3500 - val_AUROC: 0.7793 - val_AUPRC: 0.4422\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2737 - AUROC: 0.8583 - AUPRC: 0.5788 - val_loss: 0.3505 - val_AUROC: 0.7800 - val_AUPRC: 0.4420\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2755 - AUROC: 0.8578 - AUPRC: 0.5691 - val_loss: 0.3502 - val_AUROC: 0.7792 - val_AUPRC: 0.4424\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2740 - AUROC: 0.8629 - AUPRC: 0.5753 - val_loss: 0.3522 - val_AUROC: 0.7800 - val_AUPRC: 0.4425\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 0s 1ms/step - loss: 0.2762 - AUROC: 0.8558 - AUPRC: 0.5676 - val_loss: 0.3499 - val_AUROC: 0.7800 - val_AUPRC: 0.4430\n"
     ]
    }
   ],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.Flatten(input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-6)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-7)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 25, 16)            3136      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 25, 16)            64        \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 16)                2112      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 16)                64        \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 5,393\n",
      "Trainable params: 5,329\n",
      "Non-trainable params: 64\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 6s 18ms/step - loss: 0.7291 - AUROC: 0.5428 - AUPRC: 0.1343 - val_loss: 0.4772 - val_AUROC: 0.6220 - val_AUPRC: 0.2194\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.4554 - AUROC: 0.6251 - AUPRC: 0.1927 - val_loss: 0.3992 - val_AUROC: 0.6480 - val_AUPRC: 0.2361\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3794 - AUROC: 0.6540 - AUPRC: 0.2388 - val_loss: 0.3790 - val_AUROC: 0.6923 - val_AUPRC: 0.2937\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3745 - AUROC: 0.6690 - AUPRC: 0.2563 - val_loss: 0.3901 - val_AUROC: 0.6673 - val_AUPRC: 0.2810\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3597 - AUROC: 0.6756 - AUPRC: 0.2935 - val_loss: 0.3749 - val_AUROC: 0.6937 - val_AUPRC: 0.3117\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3686 - AUROC: 0.7039 - AUPRC: 0.3139 - val_loss: 0.3818 - val_AUROC: 0.6658 - val_AUPRC: 0.2677\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3562 - AUROC: 0.6880 - AUPRC: 0.2662 - val_loss: 0.3859 - val_AUROC: 0.6629 - val_AUPRC: 0.2621\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3545 - AUROC: 0.6950 - AUPRC: 0.2907 - val_loss: 0.3857 - val_AUROC: 0.6714 - val_AUPRC: 0.2707\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3644 - AUROC: 0.6933 - AUPRC: 0.2767 - val_loss: 0.3997 - val_AUROC: 0.6357 - val_AUPRC: 0.2455\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3611 - AUROC: 0.7028 - AUPRC: 0.2921 - val_loss: 0.3718 - val_AUROC: 0.7228 - val_AUPRC: 0.3095\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 2s 13ms/step - loss: 0.3596 - AUROC: 0.7206 - AUPRC: 0.3225 - val_loss: 0.3685 - val_AUROC: 0.7403 - val_AUPRC: 0.2971\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3443 - AUROC: 0.7299 - AUPRC: 0.3032 - val_loss: 0.3739 - val_AUROC: 0.7170 - val_AUPRC: 0.2881\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3408 - AUROC: 0.7320 - AUPRC: 0.3187 - val_loss: 0.3749 - val_AUROC: 0.7070 - val_AUPRC: 0.3099\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3445 - AUROC: 0.6834 - AUPRC: 0.2806 - val_loss: 0.3964 - val_AUROC: 0.6800 - val_AUPRC: 0.2976\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3636 - AUROC: 0.6939 - AUPRC: 0.2996 - val_loss: 0.3703 - val_AUROC: 0.6961 - val_AUPRC: 0.3283\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3562 - AUROC: 0.7246 - AUPRC: 0.3520 - val_loss: 0.4477 - val_AUROC: 0.5900 - val_AUPRC: 0.2049\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3609 - AUROC: 0.6875 - AUPRC: 0.3060 - val_loss: 0.3666 - val_AUROC: 0.7146 - val_AUPRC: 0.3232\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3494 - AUROC: 0.7074 - AUPRC: 0.3569 - val_loss: 0.3810 - val_AUROC: 0.6813 - val_AUPRC: 0.2912\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3766 - AUROC: 0.6461 - AUPRC: 0.2510 - val_loss: 0.3759 - val_AUROC: 0.6751 - val_AUPRC: 0.3051\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3592 - AUROC: 0.7168 - AUPRC: 0.3369 - val_loss: 0.3695 - val_AUROC: 0.7057 - val_AUPRC: 0.3355\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3508 - AUROC: 0.7064 - AUPRC: 0.3185 - val_loss: 0.3823 - val_AUROC: 0.6557 - val_AUPRC: 0.2927\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3578 - AUROC: 0.6909 - AUPRC: 0.3181 - val_loss: 0.3741 - val_AUROC: 0.6838 - val_AUPRC: 0.3243\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3426 - AUROC: 0.7199 - AUPRC: 0.3285 - val_loss: 0.3653 - val_AUROC: 0.7184 - val_AUPRC: 0.3385\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3487 - AUROC: 0.7138 - AUPRC: 0.2913 - val_loss: 0.3791 - val_AUROC: 0.6960 - val_AUPRC: 0.2894\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3575 - AUROC: 0.7066 - AUPRC: 0.3234 - val_loss: 0.3621 - val_AUROC: 0.7161 - val_AUPRC: 0.3448\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3320 - AUROC: 0.7101 - AUPRC: 0.3199 - val_loss: 0.3615 - val_AUROC: 0.7243 - val_AUPRC: 0.3574\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3432 - AUROC: 0.7268 - AUPRC: 0.2978 - val_loss: 0.3506 - val_AUROC: 0.7536 - val_AUPRC: 0.3778\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3257 - AUROC: 0.7403 - AUPRC: 0.3204 - val_loss: 0.3598 - val_AUROC: 0.7353 - val_AUPRC: 0.3677\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3390 - AUROC: 0.7304 - AUPRC: 0.3373 - val_loss: 0.3646 - val_AUROC: 0.7192 - val_AUPRC: 0.3547\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3608 - AUROC: 0.7012 - AUPRC: 0.2943 - val_loss: 0.3727 - val_AUROC: 0.6985 - val_AUPRC: 0.3346\n",
      "Epoch 31/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3525 - AUROC: 0.6984 - AUPRC: 0.3338 - val_loss: 0.3832 - val_AUROC: 0.6401 - val_AUPRC: 0.3231\n",
      "Epoch 32/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3690 - AUROC: 0.6600 - AUPRC: 0.2719 - val_loss: 0.3753 - val_AUROC: 0.6875 - val_AUPRC: 0.3223\n",
      "Epoch 33/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3513 - AUROC: 0.7206 - AUPRC: 0.3203 - val_loss: 0.3953 - val_AUROC: 0.6335 - val_AUPRC: 0.2994\n",
      "Epoch 34/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3662 - AUROC: 0.6810 - AUPRC: 0.2959 - val_loss: 0.3741 - val_AUROC: 0.6840 - val_AUPRC: 0.3480\n",
      "Epoch 35/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3574 - AUROC: 0.7036 - AUPRC: 0.2994 - val_loss: 0.3854 - val_AUROC: 0.7117 - val_AUPRC: 0.2677\n",
      "Epoch 36/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3464 - AUROC: 0.7036 - AUPRC: 0.3136 - val_loss: 0.3671 - val_AUROC: 0.7079 - val_AUPRC: 0.3299\n",
      "Epoch 37/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3593 - AUROC: 0.6991 - AUPRC: 0.3339 - val_loss: 0.3611 - val_AUROC: 0.7233 - val_AUPRC: 0.3518\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3416 - AUROC: 0.7337 - AUPRC: 0.3325 - val_loss: 0.3571 - val_AUROC: 0.7409 - val_AUPRC: 0.3433\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3374 - AUROC: 0.7415 - AUPRC: 0.3558 - val_loss: 0.3547 - val_AUROC: 0.7438 - val_AUPRC: 0.3415\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3352 - AUROC: 0.7411 - AUPRC: 0.3754 - val_loss: 0.3537 - val_AUROC: 0.7442 - val_AUPRC: 0.3441\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3348 - AUROC: 0.7493 - AUPRC: 0.3584 - val_loss: 0.3525 - val_AUROC: 0.7436 - val_AUPRC: 0.3459\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3356 - AUROC: 0.7471 - AUPRC: 0.3551 - val_loss: 0.3524 - val_AUROC: 0.7481 - val_AUPRC: 0.3517\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3348 - AUROC: 0.7518 - AUPRC: 0.3587 - val_loss: 0.3514 - val_AUROC: 0.7477 - val_AUPRC: 0.3517\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3355 - AUROC: 0.7436 - AUPRC: 0.3659 - val_loss: 0.3523 - val_AUROC: 0.7497 - val_AUPRC: 0.3582\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3319 - AUROC: 0.7568 - AUPRC: 0.3800 - val_loss: 0.3514 - val_AUROC: 0.7459 - val_AUPRC: 0.3606\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3325 - AUROC: 0.7513 - AUPRC: 0.3706 - val_loss: 0.3517 - val_AUROC: 0.7521 - val_AUPRC: 0.3615\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3325 - AUROC: 0.7511 - AUPRC: 0.3555 - val_loss: 0.3496 - val_AUROC: 0.7578 - val_AUPRC: 0.3735\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3312 - AUROC: 0.7544 - AUPRC: 0.3735 - val_loss: 0.3474 - val_AUROC: 0.7621 - val_AUPRC: 0.3743\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3296 - AUROC: 0.7601 - AUPRC: 0.3707 - val_loss: 0.3501 - val_AUROC: 0.7537 - val_AUPRC: 0.3613\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3301 - AUROC: 0.7578 - AUPRC: 0.3764 - val_loss: 0.3485 - val_AUROC: 0.7551 - val_AUPRC: 0.3674\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3289 - AUROC: 0.7603 - AUPRC: 0.3774 - val_loss: 0.3485 - val_AUROC: 0.7524 - val_AUPRC: 0.3724\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3277 - AUROC: 0.7611 - AUPRC: 0.3901 - val_loss: 0.3515 - val_AUROC: 0.7497 - val_AUPRC: 0.3639\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3307 - AUROC: 0.7547 - AUPRC: 0.3742 - val_loss: 0.3519 - val_AUROC: 0.7483 - val_AUPRC: 0.3618\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3264 - AUROC: 0.7683 - AUPRC: 0.3847 - val_loss: 0.3495 - val_AUROC: 0.7545 - val_AUPRC: 0.3759\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3285 - AUROC: 0.7551 - AUPRC: 0.3823 - val_loss: 0.3496 - val_AUROC: 0.7610 - val_AUPRC: 0.3740\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3278 - AUROC: 0.7616 - AUPRC: 0.3955 - val_loss: 0.3526 - val_AUROC: 0.7548 - val_AUPRC: 0.3631\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3263 - AUROC: 0.7697 - AUPRC: 0.3996 - val_loss: 0.3492 - val_AUROC: 0.7583 - val_AUPRC: 0.3714\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3271 - AUROC: 0.7640 - AUPRC: 0.3766 - val_loss: 0.3503 - val_AUROC: 0.7566 - val_AUPRC: 0.3638\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3256 - AUROC: 0.7654 - AUPRC: 0.3813 - val_loss: 0.3493 - val_AUROC: 0.7588 - val_AUPRC: 0.3655\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3225 - AUROC: 0.7731 - AUPRC: 0.4022 - val_loss: 0.3492 - val_AUROC: 0.7585 - val_AUPRC: 0.3669\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3254 - AUROC: 0.7680 - AUPRC: 0.3860 - val_loss: 0.3492 - val_AUROC: 0.7570 - val_AUPRC: 0.3674\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3244 - AUROC: 0.7644 - AUPRC: 0.3977 - val_loss: 0.3490 - val_AUROC: 0.7568 - val_AUPRC: 0.3674\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3270 - AUROC: 0.7663 - AUPRC: 0.3837 - val_loss: 0.3496 - val_AUROC: 0.7567 - val_AUPRC: 0.3667\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3253 - AUROC: 0.7657 - AUPRC: 0.3881 - val_loss: 0.3497 - val_AUROC: 0.7543 - val_AUPRC: 0.3673\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3253 - AUROC: 0.7683 - AUPRC: 0.3986 - val_loss: 0.3494 - val_AUROC: 0.7551 - val_AUPRC: 0.3680\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3254 - AUROC: 0.7710 - AUPRC: 0.3869 - val_loss: 0.3497 - val_AUROC: 0.7546 - val_AUPRC: 0.3670\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3250 - AUROC: 0.7703 - AUPRC: 0.3931 - val_loss: 0.3500 - val_AUROC: 0.7545 - val_AUPRC: 0.3633\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3262 - AUROC: 0.7607 - AUPRC: 0.3835 - val_loss: 0.3498 - val_AUROC: 0.7554 - val_AUPRC: 0.3651\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3259 - AUROC: 0.7622 - AUPRC: 0.4010 - val_loss: 0.3490 - val_AUROC: 0.7598 - val_AUPRC: 0.3672\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3267 - AUROC: 0.7656 - AUPRC: 0.3833 - val_loss: 0.3491 - val_AUROC: 0.7585 - val_AUPRC: 0.3670\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3242 - AUROC: 0.7706 - AUPRC: 0.3990 - val_loss: 0.3494 - val_AUROC: 0.7599 - val_AUPRC: 0.3669\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3251 - AUROC: 0.7698 - AUPRC: 0.3919 - val_loss: 0.3491 - val_AUROC: 0.7573 - val_AUPRC: 0.3679\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3253 - AUROC: 0.7647 - AUPRC: 0.3922 - val_loss: 0.3486 - val_AUROC: 0.7582 - val_AUPRC: 0.3693\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3284 - AUROC: 0.7595 - AUPRC: 0.3864 - val_loss: 0.3489 - val_AUROC: 0.7567 - val_AUPRC: 0.3693\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3252 - AUROC: 0.7694 - AUPRC: 0.3861 - val_loss: 0.3490 - val_AUROC: 0.7571 - val_AUPRC: 0.3684\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3261 - AUROC: 0.7671 - AUPRC: 0.3869 - val_loss: 0.3489 - val_AUROC: 0.7582 - val_AUPRC: 0.3684\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3251 - AUROC: 0.7705 - AUPRC: 0.3879 - val_loss: 0.3491 - val_AUROC: 0.7571 - val_AUPRC: 0.3694\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3255 - AUROC: 0.7689 - AUPRC: 0.3938 - val_loss: 0.3495 - val_AUROC: 0.7566 - val_AUPRC: 0.3679\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3247 - AUROC: 0.7669 - AUPRC: 0.4064 - val_loss: 0.3495 - val_AUROC: 0.7564 - val_AUPRC: 0.3680\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3253 - AUROC: 0.7667 - AUPRC: 0.4075 - val_loss: 0.3502 - val_AUROC: 0.7574 - val_AUPRC: 0.3673\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3242 - AUROC: 0.7735 - AUPRC: 0.3956 - val_loss: 0.3494 - val_AUROC: 0.7558 - val_AUPRC: 0.3639\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3257 - AUROC: 0.7652 - AUPRC: 0.3931 - val_loss: 0.3492 - val_AUROC: 0.7557 - val_AUPRC: 0.3651\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3258 - AUROC: 0.7647 - AUPRC: 0.3956 - val_loss: 0.3501 - val_AUROC: 0.7574 - val_AUPRC: 0.3673\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3254 - AUROC: 0.7631 - AUPRC: 0.3995 - val_loss: 0.3498 - val_AUROC: 0.7571 - val_AUPRC: 0.3669\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3253 - AUROC: 0.7709 - AUPRC: 0.3952 - val_loss: 0.3496 - val_AUROC: 0.7553 - val_AUPRC: 0.3660\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3241 - AUROC: 0.7646 - AUPRC: 0.4026 - val_loss: 0.3498 - val_AUROC: 0.7560 - val_AUPRC: 0.3658\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3252 - AUROC: 0.7703 - AUPRC: 0.3927 - val_loss: 0.3497 - val_AUROC: 0.7566 - val_AUPRC: 0.3669\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3242 - AUROC: 0.7700 - AUPRC: 0.4102 - val_loss: 0.3496 - val_AUROC: 0.7569 - val_AUPRC: 0.3662\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3260 - AUROC: 0.7690 - AUPRC: 0.3829 - val_loss: 0.3497 - val_AUROC: 0.7564 - val_AUPRC: 0.3666\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3241 - AUROC: 0.7739 - AUPRC: 0.3956 - val_loss: 0.3498 - val_AUROC: 0.7567 - val_AUPRC: 0.3646\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3224 - AUROC: 0.7739 - AUPRC: 0.3979 - val_loss: 0.3497 - val_AUROC: 0.7571 - val_AUPRC: 0.3659\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3263 - AUROC: 0.7674 - AUPRC: 0.3846 - val_loss: 0.3495 - val_AUROC: 0.7572 - val_AUPRC: 0.3680\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3248 - AUROC: 0.7718 - AUPRC: 0.3929 - val_loss: 0.3499 - val_AUROC: 0.7565 - val_AUPRC: 0.3655\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3271 - AUROC: 0.7627 - AUPRC: 0.3870 - val_loss: 0.3497 - val_AUROC: 0.7560 - val_AUPRC: 0.3652\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3266 - AUROC: 0.7642 - AUPRC: 0.3976 - val_loss: 0.3496 - val_AUROC: 0.7561 - val_AUPRC: 0.3659\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3256 - AUROC: 0.7664 - AUPRC: 0.3909 - val_loss: 0.3498 - val_AUROC: 0.7561 - val_AUPRC: 0.3649\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3284 - AUROC: 0.7615 - AUPRC: 0.3741 - val_loss: 0.3497 - val_AUROC: 0.7576 - val_AUPRC: 0.3688\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3271 - AUROC: 0.7612 - AUPRC: 0.3862 - val_loss: 0.3495 - val_AUROC: 0.7576 - val_AUPRC: 0.3665\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3234 - AUROC: 0.7735 - AUPRC: 0.4050 - val_loss: 0.3495 - val_AUROC: 0.7560 - val_AUPRC: 0.3674\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3292 - AUROC: 0.7599 - AUPRC: 0.3743 - val_loss: 0.3495 - val_AUROC: 0.7572 - val_AUPRC: 0.3681\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3245 - AUROC: 0.7696 - AUPRC: 0.3905 - val_loss: 0.3495 - val_AUROC: 0.7561 - val_AUPRC: 0.3667\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3256 - AUROC: 0.7673 - AUPRC: 0.3871 - val_loss: 0.3494 - val_AUROC: 0.7576 - val_AUPRC: 0.3676\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3250 - AUROC: 0.7604 - AUPRC: 0.4056 - val_loss: 0.3492 - val_AUROC: 0.7566 - val_AUPRC: 0.3677\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3239 - AUROC: 0.7683 - AUPRC: 0.4009 - val_loss: 0.3494 - val_AUROC: 0.7581 - val_AUPRC: 0.3683\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3236 - AUROC: 0.7658 - AUPRC: 0.3993 - val_loss: 0.3495 - val_AUROC: 0.7577 - val_AUPRC: 0.3646\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3248 - AUROC: 0.7705 - AUPRC: 0.3963 - val_loss: 0.3492 - val_AUROC: 0.7571 - val_AUPRC: 0.3676\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3240 - AUROC: 0.7687 - AUPRC: 0.4042 - val_loss: 0.3490 - val_AUROC: 0.7572 - val_AUPRC: 0.3671\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3249 - AUROC: 0.7709 - AUPRC: 0.3934 - val_loss: 0.3491 - val_AUROC: 0.7574 - val_AUPRC: 0.3677\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 3s 15ms/step - loss: 0.3260 - AUROC: 0.7626 - AUPRC: 0.3920 - val_loss: 0.3493 - val_AUROC: 0.7572 - val_AUPRC: 0.3660\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3227 - AUROC: 0.7752 - AUPRC: 0.3906 - val_loss: 0.3491 - val_AUROC: 0.7568 - val_AUPRC: 0.3661\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3266 - AUROC: 0.7616 - AUPRC: 0.3869 - val_loss: 0.3491 - val_AUROC: 0.7578 - val_AUPRC: 0.3691\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3247 - AUROC: 0.7683 - AUPRC: 0.4003 - val_loss: 0.3490 - val_AUROC: 0.7587 - val_AUPRC: 0.3684\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3249 - AUROC: 0.7666 - AUPRC: 0.4006 - val_loss: 0.3496 - val_AUROC: 0.7571 - val_AUPRC: 0.3673\n",
      "Epoch 31/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3243 - AUROC: 0.7713 - AUPRC: 0.3928 - val_loss: 0.3496 - val_AUROC: 0.7576 - val_AUPRC: 0.3671\n",
      "Epoch 32/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3254 - AUROC: 0.7658 - AUPRC: 0.3917 - val_loss: 0.3495 - val_AUROC: 0.7572 - val_AUPRC: 0.3663\n",
      "Epoch 33/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3235 - AUROC: 0.7710 - AUPRC: 0.4029 - val_loss: 0.3495 - val_AUROC: 0.7582 - val_AUPRC: 0.3675\n",
      "Epoch 34/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3257 - AUROC: 0.7678 - AUPRC: 0.3977 - val_loss: 0.3493 - val_AUROC: 0.7564 - val_AUPRC: 0.3687\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3272 - AUROC: 0.7619 - AUPRC: 0.3862 - val_loss: 0.3494 - val_AUROC: 0.7552 - val_AUPRC: 0.3675\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3263 - AUROC: 0.7645 - AUPRC: 0.3840 - val_loss: 0.3493 - val_AUROC: 0.7570 - val_AUPRC: 0.3686\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3241 - AUROC: 0.7673 - AUPRC: 0.4060 - val_loss: 0.3494 - val_AUROC: 0.7594 - val_AUPRC: 0.3684\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3242 - AUROC: 0.7698 - AUPRC: 0.4085 - val_loss: 0.3493 - val_AUROC: 0.7563 - val_AUPRC: 0.3667\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3258 - AUROC: 0.7712 - AUPRC: 0.3990 - val_loss: 0.3495 - val_AUROC: 0.7565 - val_AUPRC: 0.3689\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3249 - AUROC: 0.7691 - AUPRC: 0.3950 - val_loss: 0.3493 - val_AUROC: 0.7577 - val_AUPRC: 0.3681\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3259 - AUROC: 0.7649 - AUPRC: 0.3964 - val_loss: 0.3494 - val_AUROC: 0.7571 - val_AUPRC: 0.3648\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3218 - AUROC: 0.7716 - AUPRC: 0.4074 - val_loss: 0.3495 - val_AUROC: 0.7582 - val_AUPRC: 0.3664\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3247 - AUROC: 0.7694 - AUPRC: 0.3885 - val_loss: 0.3494 - val_AUROC: 0.7563 - val_AUPRC: 0.3655\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3244 - AUROC: 0.7666 - AUPRC: 0.3978 - val_loss: 0.3495 - val_AUROC: 0.7582 - val_AUPRC: 0.3663\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3249 - AUROC: 0.7675 - AUPRC: 0.3931 - val_loss: 0.3493 - val_AUROC: 0.7580 - val_AUPRC: 0.3682\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3260 - AUROC: 0.7682 - AUPRC: 0.3806 - val_loss: 0.3494 - val_AUROC: 0.7577 - val_AUPRC: 0.3677\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3248 - AUROC: 0.7714 - AUPRC: 0.4006 - val_loss: 0.3494 - val_AUROC: 0.7577 - val_AUPRC: 0.3694\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3243 - AUROC: 0.7725 - AUPRC: 0.4061 - val_loss: 0.3496 - val_AUROC: 0.7567 - val_AUPRC: 0.3662\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 2s 14ms/step - loss: 0.3241 - AUROC: 0.7707 - AUPRC: 0.3912 - val_loss: 0.3495 - val_AUROC: 0.7580 - val_AUPRC: 0.3678\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 2s 15ms/step - loss: 0.3237 - AUROC: 0.7694 - AUPRC: 0.4051 - val_loss: 0.3497 - val_AUROC: 0.7582 - val_AUPRC: 0.3669\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 3s 16ms/step - loss: 0.3272 - AUROC: 0.7626 - AUPRC: 0.3800 - val_loss: 0.3496 - val_AUROC: 0.7579 - val_AUPRC: 0.3670\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3240 - AUROC: 0.7688 - AUPRC: 0.4004 - val_loss: 0.3493 - val_AUROC: 0.7577 - val_AUPRC: 0.3689\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3240 - AUROC: 0.7719 - AUPRC: 0.3864 - val_loss: 0.3493 - val_AUROC: 0.7558 - val_AUPRC: 0.3671\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 3s 21ms/step - loss: 0.3240 - AUROC: 0.7671 - AUPRC: 0.3968 - val_loss: 0.3492 - val_AUROC: 0.7567 - val_AUPRC: 0.3670\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 3s 20ms/step - loss: 0.3247 - AUROC: 0.7682 - AUPRC: 0.3943 - val_loss: 0.3493 - val_AUROC: 0.7565 - val_AUPRC: 0.3674\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3256 - AUROC: 0.7678 - AUPRC: 0.3833 - val_loss: 0.3494 - val_AUROC: 0.7569 - val_AUPRC: 0.3682\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3260 - AUROC: 0.7672 - AUPRC: 0.3895 - val_loss: 0.3495 - val_AUROC: 0.7567 - val_AUPRC: 0.3654\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3225 - AUROC: 0.7736 - AUPRC: 0.4026 - val_loss: 0.3493 - val_AUROC: 0.7585 - val_AUPRC: 0.3685\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3254 - AUROC: 0.7623 - AUPRC: 0.3933 - val_loss: 0.3493 - val_AUROC: 0.7593 - val_AUPRC: 0.3669\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3255 - AUROC: 0.7688 - AUPRC: 0.3915 - val_loss: 0.3494 - val_AUROC: 0.7590 - val_AUPRC: 0.3686\n",
      "Epoch 27/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3228 - AUROC: 0.7738 - AUPRC: 0.4017 - val_loss: 0.3496 - val_AUROC: 0.7578 - val_AUPRC: 0.3661\n",
      "Epoch 28/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3234 - AUROC: 0.7671 - AUPRC: 0.3974 - val_loss: 0.3492 - val_AUROC: 0.7574 - val_AUPRC: 0.3673\n",
      "Epoch 29/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3234 - AUROC: 0.7687 - AUPRC: 0.4053 - val_loss: 0.3493 - val_AUROC: 0.7565 - val_AUPRC: 0.3678\n",
      "Epoch 30/50\n",
      "164/164 [==============================] - 3s 18ms/step - loss: 0.3263 - AUROC: 0.7674 - AUPRC: 0.3994 - val_loss: 0.3494 - val_AUROC: 0.7561 - val_AUPRC: 0.3659\n",
      "Epoch 31/50\n",
      "164/164 [==============================] - 3s 17ms/step - loss: 0.3257 - AUROC: 0.7683 - AUPRC: 0.3917 - val_loss: 0.3493 - val_AUROC: 0.7568 - val_AUPRC: 0.3670\n",
      "Epoch 32/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3248 - AUROC: 0.7674 - AUPRC: 0.3925 - val_loss: 0.3493 - val_AUROC: 0.7570 - val_AUPRC: 0.3671\n",
      "Epoch 33/50\n",
      "164/164 [==============================] - 3s 20ms/step - loss: 0.3238 - AUROC: 0.7709 - AUPRC: 0.4005 - val_loss: 0.3496 - val_AUROC: 0.7573 - val_AUPRC: 0.3658\n",
      "Epoch 34/50\n",
      "164/164 [==============================] - 3s 20ms/step - loss: 0.3257 - AUROC: 0.7687 - AUPRC: 0.3835 - val_loss: 0.3494 - val_AUROC: 0.7564 - val_AUPRC: 0.3683\n",
      "Epoch 35/50\n",
      "164/164 [==============================] - 3s 20ms/step - loss: 0.3245 - AUROC: 0.7689 - AUPRC: 0.3985 - val_loss: 0.3495 - val_AUROC: 0.7566 - val_AUPRC: 0.3647\n",
      "Epoch 36/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3248 - AUROC: 0.7694 - AUPRC: 0.4001 - val_loss: 0.3495 - val_AUROC: 0.7559 - val_AUPRC: 0.3672\n",
      "Epoch 37/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3242 - AUROC: 0.7715 - AUPRC: 0.3963 - val_loss: 0.3494 - val_AUROC: 0.7567 - val_AUPRC: 0.3683\n",
      "Epoch 38/50\n",
      "164/164 [==============================] - 3s 19ms/step - loss: 0.3260 - AUROC: 0.7655 - AUPRC: 0.3927 - val_loss: 0.3494 - val_AUROC: 0.7568 - val_AUPRC: 0.3662\n"
     ]
    }
   ],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.LSTM(16, return_sequences=True, input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(16, return_sequences=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-6)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-7)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-class classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "\n",
    "# median imputation\n",
    "train_df.fillna(whole_df.median(), inplace=True)\n",
    "valid_df.fillna(whole_df.median(), inplace=True)\n",
    "whole_df.fillna(whole_df.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5226, 72, 32)\n",
      "(5226, 3)\n",
      "(1331, 72, 32)\n",
      "(1331, 3)\n",
      "(6557, 72, 32)\n",
      "(6557, 3)\n"
     ]
    }
   ],
   "source": [
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos','y___neg','y___nbc']\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_train = train_df[input_vars].values\n",
    "Y_train = train_df[output_var].values\n",
    "X_train = np.reshape(X_train, (-1,72,32) )\n",
    "Y_train = np.reshape(Y_train, (-1,72,3) )[:,0,:]\n",
    "#X_train = (X_train - X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_valid = valid_df[input_vars].values\n",
    "Y_valid = valid_df[output_var].values\n",
    "X_valid = np.reshape(X_valid, (-1,72,32) )\n",
    "Y_valid = np.reshape(Y_valid, (-1,72,3) )[:,0,:]\n",
    "#X_valid = (X_valid - X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,72,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,3) )[:,0,:]\n",
    "#X_whole = (X_whole - X_train.mean(axis=0))/X_train.std(axis=0)\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 72, 72)            30240     \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72, 72)            288       \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 32)                3360      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                528       \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 16)                272       \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16)                0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 3)                 51        \n",
      "=================================================================\n",
      "Total params: 34,867\n",
      "Trainable params: 34,659\n",
      "Non-trainable params: 208\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 9s 39ms/step - loss: 0.9101 - AUROC: 0.5199 - AUPRC: 0.3471 - val_loss: 0.8812 - val_AUROC: 0.5739 - val_AUPRC: 0.3793\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8743 - AUROC: 0.5274 - AUPRC: 0.3483 - val_loss: 0.8824 - val_AUROC: 0.5830 - val_AUPRC: 0.3888\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8575 - AUROC: 0.5706 - AUPRC: 0.3676 - val_loss: 0.8877 - val_AUROC: 0.5474 - val_AUPRC: 0.3531\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8645 - AUROC: 0.5732 - AUPRC: 0.3746 - val_loss: 0.8831 - val_AUROC: 0.5832 - val_AUPRC: 0.3764\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8587 - AUROC: 0.5587 - AUPRC: 0.3638 - val_loss: 0.8720 - val_AUROC: 0.5970 - val_AUPRC: 0.3932\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 5s 32ms/step - loss: 0.8566 - AUROC: 0.5626 - AUPRC: 0.3692 - val_loss: 0.8687 - val_AUROC: 0.6015 - val_AUPRC: 0.4067\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8513 - AUROC: 0.5748 - AUPRC: 0.3747 - val_loss: 0.8677 - val_AUROC: 0.6107 - val_AUPRC: 0.4227\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8527 - AUROC: 0.5706 - AUPRC: 0.3729 - val_loss: 0.8656 - val_AUROC: 0.6177 - val_AUPRC: 0.4224\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8532 - AUROC: 0.5709 - AUPRC: 0.3697 - val_loss: 0.8652 - val_AUROC: 0.6126 - val_AUPRC: 0.4191\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8514 - AUROC: 0.5755 - AUPRC: 0.3704 - val_loss: 0.8627 - val_AUROC: 0.6200 - val_AUPRC: 0.4244\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8493 - AUROC: 0.5804 - AUPRC: 0.3749 - val_loss: 0.8619 - val_AUROC: 0.6202 - val_AUPRC: 0.4221\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8458 - AUROC: 0.5885 - AUPRC: 0.3841 - val_loss: 0.8611 - val_AUROC: 0.6235 - val_AUPRC: 0.4286\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8456 - AUROC: 0.5870 - AUPRC: 0.3821 - val_loss: 0.8621 - val_AUROC: 0.6191 - val_AUPRC: 0.4264\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8463 - AUROC: 0.5886 - AUPRC: 0.3860 - val_loss: 0.8627 - val_AUROC: 0.6206 - val_AUPRC: 0.4233\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8431 - AUROC: 0.5914 - AUPRC: 0.3860 - val_loss: 0.8598 - val_AUROC: 0.6288 - val_AUPRC: 0.4351\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8414 - AUROC: 0.5993 - AUPRC: 0.3875 - val_loss: 0.8572 - val_AUROC: 0.6332 - val_AUPRC: 0.4405\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8399 - AUROC: 0.6019 - AUPRC: 0.4000 - val_loss: 0.8570 - val_AUROC: 0.6378 - val_AUPRC: 0.4398\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8411 - AUROC: 0.6002 - AUPRC: 0.3960 - val_loss: 0.8594 - val_AUROC: 0.6333 - val_AUPRC: 0.4403\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8399 - AUROC: 0.6015 - AUPRC: 0.3990 - val_loss: 0.8538 - val_AUROC: 0.6430 - val_AUPRC: 0.4375\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8369 - AUROC: 0.6083 - AUPRC: 0.4068 - val_loss: 0.8564 - val_AUROC: 0.6388 - val_AUPRC: 0.4332\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8418 - AUROC: 0.6005 - AUPRC: 0.3932 - val_loss: 0.8557 - val_AUROC: 0.6415 - val_AUPRC: 0.4440\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8360 - AUROC: 0.6126 - AUPRC: 0.4053 - val_loss: 0.8525 - val_AUROC: 0.6463 - val_AUPRC: 0.4396\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8321 - AUROC: 0.6204 - AUPRC: 0.4127 - val_loss: 0.8511 - val_AUROC: 0.6456 - val_AUPRC: 0.4411\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8365 - AUROC: 0.6128 - AUPRC: 0.4075 - val_loss: 0.8496 - val_AUROC: 0.6553 - val_AUPRC: 0.4529\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8282 - AUROC: 0.6266 - AUPRC: 0.4206 - val_loss: 0.8427 - val_AUROC: 0.6609 - val_AUPRC: 0.4515\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8288 - AUROC: 0.6276 - AUPRC: 0.4199 - val_loss: 0.8433 - val_AUROC: 0.6581 - val_AUPRC: 0.4535\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8235 - AUROC: 0.6381 - AUPRC: 0.4253 - val_loss: 0.8395 - val_AUROC: 0.6637 - val_AUPRC: 0.4575\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8237 - AUROC: 0.6355 - AUPRC: 0.4288 - val_loss: 0.8442 - val_AUROC: 0.6564 - val_AUPRC: 0.4576\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8273 - AUROC: 0.6308 - AUPRC: 0.4186 - val_loss: 0.8433 - val_AUROC: 0.6547 - val_AUPRC: 0.4518\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8201 - AUROC: 0.6452 - AUPRC: 0.4300 - val_loss: 0.8402 - val_AUROC: 0.6593 - val_AUPRC: 0.4619\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8222 - AUROC: 0.6381 - AUPRC: 0.4247 - val_loss: 0.8398 - val_AUROC: 0.6595 - val_AUPRC: 0.4624\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8206 - AUROC: 0.6405 - AUPRC: 0.4307 - val_loss: 0.8397 - val_AUROC: 0.6595 - val_AUPRC: 0.4615\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8232 - AUROC: 0.6382 - AUPRC: 0.4266 - val_loss: 0.8394 - val_AUROC: 0.6610 - val_AUPRC: 0.4624\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8185 - AUROC: 0.6476 - AUPRC: 0.4352 - val_loss: 0.8390 - val_AUROC: 0.6614 - val_AUPRC: 0.4629\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8207 - AUROC: 0.6423 - AUPRC: 0.4307 - val_loss: 0.8389 - val_AUROC: 0.6620 - val_AUPRC: 0.4621\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.8190 - AUROC: 0.6459 - AUPRC: 0.4336 - val_loss: 0.8380 - val_AUROC: 0.6632 - val_AUPRC: 0.4658\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8181 - AUROC: 0.6478 - AUPRC: 0.4390 - val_loss: 0.8375 - val_AUROC: 0.6641 - val_AUPRC: 0.4666\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8235 - AUROC: 0.6350 - AUPRC: 0.4294 - val_loss: 0.8372 - val_AUROC: 0.6642 - val_AUPRC: 0.4642\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8199 - AUROC: 0.6420 - AUPRC: 0.4367 - val_loss: 0.8375 - val_AUROC: 0.6636 - val_AUPRC: 0.4627\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 34ms/step - loss: 0.8186 - AUROC: 0.6473 - AUPRC: 0.4332 - val_loss: 0.8379 - val_AUROC: 0.6625 - val_AUPRC: 0.4621\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 5s 33ms/step - loss: 0.8180 - AUROC: 0.6471 - AUPRC: 0.4407 - val_loss: 0.8377 - val_AUROC: 0.6633 - val_AUPRC: 0.4633\n"
     ]
    }
   ],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC', multi_label=True),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR', multi_label=True)\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.LSTM(72, return_sequences=True, input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "#     keras.layers.LSTM(64, return_sequences=True),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "#     keras.layers.SimpleRNN(64, return_sequences=True),\n",
    "#     keras.layers.BatchNormalization(),\n",
    "    keras.layers.SimpleRNN(32, return_sequences=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(16, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.3),\n",
    "    keras.layers.Dense(16, activation='sigmoid'),\n",
    "    keras.layers.Dropout(0.1),\n",
    "    keras.layers.Dense(3, activation='softmax')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"categorical_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC of predicting positive 0.7407937792088908\n",
      "AUC of predicting negative 0.6414970553248827\n",
      "AUC of predicting baseline 0.6616761098657815\n",
      "Overall AUC of prediction 0.8218188553543523\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import sklearn\n",
    "X_whole_org = np.reshape(whole_df[input_vars].values, (-1,72,32) )\n",
    "y_prob = mdl.predict(X_whole_org)\n",
    "y_true = Y_whole\n",
    "print(\"AUC of predicting positive\",sklearn.metrics.roc_auc_score(y_true[:,0], y_prob[:,0]))\n",
    "print(\"AUC of predicting negative\",sklearn.metrics.roc_auc_score(y_true[:,1], y_prob[:,1]))\n",
    "print(\"AUC of predicting baseline\",sklearn.metrics.roc_auc_score(y_true[:,2], y_prob[:,2]))\n",
    "print(\"Overall AUC of prediction\",sklearn.metrics.roc_auc_score(y_true.reshape(-1), y_prob.reshape(-1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_index = np.where(Y_whole[:,0]==1.0)[0]\n",
    "neg_index = np.where(Y_whole[:,1]==1.0)[0]\n",
    "nbc_index = np.where(Y_whole[:,2]==1.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_whole[pos_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_pos = mdl.predict(X_new)\n",
    "x = X_whole[neg_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_neg = mdl.predict(X_new)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.07383678, 0.6684545 , 0.25770864],\n",
       "       [0.23786162, 0.62463856, 0.13749978],\n",
       "       [0.07835412, 0.6568257 , 0.26482004],\n",
       "       ...,\n",
       "       [0.1799775 , 0.564103  , 0.25591946],\n",
       "       [0.09674216, 0.643525  , 0.2597328 ],\n",
       "       [0.07455927, 0.66616875, 0.259272  ]], dtype=float32)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = X_whole[pos_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_pos = mdl.predict(X_new)\n",
    "x = X_whole[neg_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_neg = mdl.predict(X_new)\n",
    "\n",
    "for i in range(1,X_whole_org.shape[1]):\n",
    "    print(\"-------------------\")\n",
    "    x = X_whole[pos_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    print(np.mean(y))\n",
    "    y_pos = np.column_stack((y_pos,y))\n",
    "    x = X_whole[neg_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    print(np.mean(y))\n",
    "    y_neg = np.column_stack((y_neg,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(\"./tte_plot.csv\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=df_res, x=\"time\", y=\"risk\", hue=\"y_true\", palette=['orange', 'blue']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary classification normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "\n",
    "# median imputation\n",
    "train_df.fillna(whole_df.median(), inplace=True)\n",
    "valid_df.fillna(whole_df.median(), inplace=True)\n",
    "whole_df.fillna(whole_df.median(), inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 72, 32)\n",
      "(6557, 1)\n",
      "(5226, 72, 32)\n",
      "(5226, 1)\n",
      "(1331, 72, 32)\n",
      "(1331, 1)\n"
     ]
    }
   ],
   "source": [
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos']\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,72,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,1) )[:,0,:]\n",
    "X_whole = (X_whole - X_whole.mean(axis=0))/X_whole.std(axis=0)\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_train = train_df[input_vars].values\n",
    "Y_train = train_df[output_var].values\n",
    "X_train = np.reshape(X_train, (-1,72,32) )\n",
    "Y_train = np.reshape(Y_train, (-1,72,1) )[:,0,:]\n",
    "X_train = (X_train - X_whole.mean(axis=0))/X_whole.std(axis=0)\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_valid = valid_df[input_vars].values\n",
    "Y_valid = valid_df[output_var].values\n",
    "X_valid = np.reshape(X_valid, (-1,72,32) )\n",
    "Y_valid = np.reshape(Y_valid, (-1,72,1) )[:,0,:]\n",
    "X_valid = (X_valid - X_whole.mean(axis=0))/X_whole.std(axis=0)\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 72, 32)            8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 16,929\n",
      "Trainable params: 16,801\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 10s 42ms/step - loss: 0.6615 - AUROC: 0.5927 - AUPRC: 0.1989 - val_loss: 0.4298 - val_AUROC: 0.5803 - val_AUPRC: 0.2386\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.4022 - AUROC: 0.6477 - AUPRC: 0.2665 - val_loss: 0.3858 - val_AUROC: 0.6452 - val_AUPRC: 0.2872\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.3553 - AUROC: 0.6722 - AUPRC: 0.2718 - val_loss: 0.3789 - val_AUROC: 0.6730 - val_AUPRC: 0.3109\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3528 - AUROC: 0.6455 - AUPRC: 0.2797 - val_loss: 0.4380 - val_AUROC: 0.5705 - val_AUPRC: 0.2233\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3623 - AUROC: 0.6678 - AUPRC: 0.2838 - val_loss: 0.3955 - val_AUROC: 0.6225 - val_AUPRC: 0.2635\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3679 - AUROC: 0.6914 - AUPRC: 0.3488 - val_loss: 0.3996 - val_AUROC: 0.6400 - val_AUPRC: 0.2940\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3585 - AUROC: 0.6729 - AUPRC: 0.3057 - val_loss: 0.3806 - val_AUROC: 0.6688 - val_AUPRC: 0.3215\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3511 - AUROC: 0.6987 - AUPRC: 0.3314 - val_loss: 0.3793 - val_AUROC: 0.6707 - val_AUPRC: 0.3225\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 40ms/step - loss: 0.3466 - AUROC: 0.7065 - AUPRC: 0.3466 - val_loss: 0.3781 - val_AUROC: 0.6628 - val_AUPRC: 0.3287\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3431 - AUROC: 0.7194 - AUPRC: 0.3667 - val_loss: 0.3744 - val_AUROC: 0.6713 - val_AUPRC: 0.3423\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 40ms/step - loss: 0.3460 - AUROC: 0.7130 - AUPRC: 0.3552 - val_loss: 0.3750 - val_AUROC: 0.6656 - val_AUPRC: 0.3457\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3420 - AUROC: 0.7256 - AUPRC: 0.3685 - val_loss: 0.3729 - val_AUROC: 0.6737 - val_AUPRC: 0.3533\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3410 - AUROC: 0.7271 - AUPRC: 0.3684 - val_loss: 0.3700 - val_AUROC: 0.6848 - val_AUPRC: 0.3592\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3387 - AUROC: 0.7315 - AUPRC: 0.3817 - val_loss: 0.3715 - val_AUROC: 0.6844 - val_AUPRC: 0.3546\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3376 - AUROC: 0.7368 - AUPRC: 0.3885 - val_loss: 0.3691 - val_AUROC: 0.6868 - val_AUPRC: 0.3632\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3354 - AUROC: 0.7373 - AUPRC: 0.3955 - val_loss: 0.3653 - val_AUROC: 0.6969 - val_AUPRC: 0.3707\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3320 - AUROC: 0.7488 - AUPRC: 0.4096 - val_loss: 0.3651 - val_AUROC: 0.6953 - val_AUPRC: 0.3654\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3316 - AUROC: 0.7535 - AUPRC: 0.4081 - val_loss: 0.3640 - val_AUROC: 0.7008 - val_AUPRC: 0.3676\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3299 - AUROC: 0.7547 - AUPRC: 0.4159 - val_loss: 0.3610 - val_AUROC: 0.7156 - val_AUPRC: 0.3791\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3258 - AUROC: 0.7679 - AUPRC: 0.4243 - val_loss: 0.3586 - val_AUROC: 0.7204 - val_AUPRC: 0.3898\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 6s 40ms/step - loss: 0.3245 - AUROC: 0.7671 - AUPRC: 0.4353 - val_loss: 0.3536 - val_AUROC: 0.7348 - val_AUPRC: 0.3961\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3204 - AUROC: 0.7792 - AUPRC: 0.4375 - val_loss: 0.3507 - val_AUROC: 0.7406 - val_AUPRC: 0.4066\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3192 - AUROC: 0.7801 - AUPRC: 0.4423 - val_loss: 0.3499 - val_AUROC: 0.7435 - val_AUPRC: 0.4124\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3161 - AUROC: 0.7872 - AUPRC: 0.4534 - val_loss: 0.3502 - val_AUROC: 0.7423 - val_AUPRC: 0.4059\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3184 - AUROC: 0.7809 - AUPRC: 0.4403 - val_loss: 0.3532 - val_AUROC: 0.7393 - val_AUPRC: 0.3962\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3138 - AUROC: 0.7854 - AUPRC: 0.4597 - val_loss: 0.3500 - val_AUROC: 0.7405 - val_AUPRC: 0.4134\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3118 - AUROC: 0.7914 - AUPRC: 0.4716 - val_loss: 0.3498 - val_AUROC: 0.7407 - val_AUPRC: 0.4121\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3099 - AUROC: 0.7960 - AUPRC: 0.4761 - val_loss: 0.3499 - val_AUROC: 0.7413 - val_AUPRC: 0.4123\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3112 - AUROC: 0.7959 - AUPRC: 0.4568 - val_loss: 0.3507 - val_AUROC: 0.7409 - val_AUPRC: 0.4114\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3089 - AUROC: 0.8014 - AUPRC: 0.4713 - val_loss: 0.3501 - val_AUROC: 0.7415 - val_AUPRC: 0.4134\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3116 - AUROC: 0.7927 - AUPRC: 0.4702 - val_loss: 0.3501 - val_AUROC: 0.7441 - val_AUPRC: 0.4149\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3092 - AUROC: 0.7966 - AUPRC: 0.4787 - val_loss: 0.3503 - val_AUROC: 0.7424 - val_AUPRC: 0.4123\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3155 - AUROC: 0.7837 - AUPRC: 0.4561 - val_loss: 0.3503 - val_AUROC: 0.7417 - val_AUPRC: 0.4118\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3093 - AUROC: 0.7981 - AUPRC: 0.4781 - val_loss: 0.3501 - val_AUROC: 0.7426 - val_AUPRC: 0.4137\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3116 - AUROC: 0.7912 - AUPRC: 0.4673 - val_loss: 0.3503 - val_AUROC: 0.7413 - val_AUPRC: 0.4117\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3122 - AUROC: 0.7906 - AUPRC: 0.4681 - val_loss: 0.3501 - val_AUROC: 0.7423 - val_AUPRC: 0.4126\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3119 - AUROC: 0.7874 - AUPRC: 0.4659 - val_loss: 0.3500 - val_AUROC: 0.7421 - val_AUPRC: 0.4130\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3097 - AUROC: 0.7980 - AUPRC: 0.4745 - val_loss: 0.3500 - val_AUROC: 0.7418 - val_AUPRC: 0.4124\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3109 - AUROC: 0.7971 - AUPRC: 0.4672 - val_loss: 0.3499 - val_AUROC: 0.7423 - val_AUPRC: 0.4137\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3104 - AUROC: 0.7940 - AUPRC: 0.4716 - val_loss: 0.3499 - val_AUROC: 0.7423 - val_AUPRC: 0.4115\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3089 - AUROC: 0.7968 - AUPRC: 0.4722 - val_loss: 0.3500 - val_AUROC: 0.7421 - val_AUPRC: 0.4126\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3083 - AUROC: 0.7991 - AUPRC: 0.4825 - val_loss: 0.3499 - val_AUROC: 0.7425 - val_AUPRC: 0.4137\n"
     ]
    }
   ],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(32, return_sequences=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-6)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 3)\n"
     ]
    }
   ],
   "source": [
    "# reformat outcome columns into 3 categories\n",
    "output_var = ['y___pos','y___neg','y___nbc']\n",
    "\n",
    "\n",
    "Y_whole = whole_df[output_var].values\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,3) )[:,0,:]\n",
    "print(Y_whole.shape)\n",
    "\n",
    "\n",
    "pos_index = np.where(Y_whole[:,0]==1.0)[0]\n",
    "neg_index = np.where(Y_whole[:,1]==1.0)[0]\n",
    "nbc_index = np.where(Y_whole[:,2]==1.0)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD3CAYAAAANMK+RAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAQWUlEQVR4nO3df6xkd1nH8ffd7e7cBG8XsPxQAyxEfDJKEF3TLS3trklpu7TaTWOUICH4o5K4CgViaWn5oSlQFApWRXRrUzUaoy0NhLoUI7EuFVIYWsOGw0PauGCMkFLYshVm2B/XP2Yar5t7Z2bPPTNz9zvvV9Jk5szp9zzP3Duf+93vzDmzsLy8jCTpzLdp1gVIkpphoEtSIQx0SSqEgS5JhTDQJakQZ83y4A899NByq9Uauk+v12PUPqWa197ntW+w93nsvU7f3/3ud7+5Y8eOZ5y6faaB3mq1aLfbQ/epqmrkPqWa197ntW+w93nsvU7fnU7nq6ttd8lFkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLmlvdYyeKOvZMT/2XpFla3LKZ7dfdM5NjH7758sbHdIYuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKsRYgR4ROyPiX07Z9qqI+MyK+1dHxOcj4rMRcUXDdUqSRhgZ6BFxLXAbsLhi208BvwYsDO4/G3g9cAFwKfCeiJi/r++WpBka59T/R4CrgL8GiIgfBN4NXAPsH+xzLnB/ZvaAXkQ8DLwY+NywgXu9HlVVDT14t9sduU+p5rX3ee0b7H3avbfb7ake71RVVTXa98hAz8y7ImI7QERsBv4CeBPwvRW7nQ08vuL+UWDbqLFbrdbIJ7Sqqpk/6bMyr73Pa99g7/PWe7vdrtV3p9NZdfvpXpxrB/BC4E/pL8H8eER8EPgUsLRivyXgyGmOLUlah9MK9Mx8APgJgMGs/e8y85rBGvq7ImIRaAFt4FDDtUqShmjkY4uZ+XXgVuAg/dn6DZnZbWJsSdJ4xpqhZ+Zh4Lxh2zJzP//3Jqkkaco8sUiSCmGgS1IhDHRJKoSBLmnmusdOzN1n0CfBL4mWNHOz+rLmSXxR8yw5Q5ekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhRjr8rkRsRN4b2bujoiXAH8EnAB6wGsy8xsRcTXwOuA4cFNmfnxCNUuSVjFyhh4R1wK3AYuDTX8I/HZm7gY+ArwlIp4NvB64ALgUeE9EtCZSsSRpVeMsuTwCXLXi/isz86HB7bOALnAucH9m9jLzceBh4MVNFippsrrHTsy6BK3TyCWXzLwrIravuP/fABFxPvBbwEX0Z+WPr/jfjgLbRo3d6/WoqmroPt1ud+Q+pZrX3ue1b5ht7+12eybfGgTlfXPQuKqqavRnXusr6CLil4AbgMsz89GI+A6wtGKXJeDIqHFardbI7xGsqmpuv2twXnuf175hvnufR+12u9bPvNPprLr9tAM9Il5N/83P3Zn5rcHmB4B3RcQi0ALawKHTHVuSVN9pBXpEbAZuBb4GfCQiAO7LzHdExK3AQfrr8jdkZrfpYiVJaxsr0DPzMHDe4O7T19hnP7C/mbIkSafLE4skqRAGuiQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrq0wXgZW9VV62qLkiZnccvmmVzGdl4vYVsSZ+iSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklSIsc4UjYidwHszc3dE/ChwB7AMHAL2ZebJiHgHcDlwHLgmMx+YUM2SpFWMnKFHxLXAbcDiYNMtwI2ZeSGwAFwZET8N7AJ2Aq8E/mQy5UqS1jLOkssjwFUr7u8A7hvcPgBcDLwM+GRmLmfm14CzIuIZjVYqSRpq5JJLZt4VEdtXbFrIzOXB7aPANuBs4LEV+zy5/dFhY/d6PaqqGnr8brc7cp9SzWvv89o39HvX/KiqqtHf9zpXWzy54vYScAT4zuD2qduHarVatNvtoftUVTVyn1LNa+/z2jcwt3/I5lW73a71+97pdFbdXudTLg9GxO7B7T3AQeB+4NKI2BQRzwU2ZeY3a4wtSaqpzgz9zcD+iNgKVMCdmXkiIg4Cn6H/R2JfgzVKksYwVqBn5mHgvMHtr9D/RMup+7wTeGdzpUmSTocnFklSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0DVS99iJqR5v5aVEp31s6UxW52qLmjOLWzaz/bp7ZnLswzdfPpPjSmciZ+iSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0KVVzOrjkqf77e/SSn5sUVqFH9XUmahWoEfEFuAvge3ACeBq4DhwB7AMHAL2ZebJRqqUJI1Ud8nlFcBZmXk+8HvAu4BbgBsz80JgAbiymRIlSeOoG+hfAc6KiE3A2cAxYAdw3+DxA8DF6y9PkjSuumvoT9BfbvkycA5wBXBRZi4PHj8KbBs1SK/Xo6qqoft0u92R+5Rqo/Q+6zfqZvEczLpnzYeqqhp9ndcN9DcC92bm9RHxHOBTwNYVjy8BR0YN0mq1Rr5wqqqa2xfXPPe+ks+BStVut2u9zjudzqrb6y65fBt4fHD7W8AW4MGI2D3Ytgc4WHNsSVINdWfoHwBuj4iD9GfmbwU+D+yPiK1ABdzZTImSpHHUCvTMfAL4xVUe2rW+ciRJdXmmqCQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SClHrS6IBIuJ64OeBrcCHgPuAO4Bl4BCwLzNPNlCjJGkMtWboEbEbOB+4ANgFPAe4BbgxMy8EFoArG6pRkjSGujP0S4EvAncDZwO/A1xNf5YOcAC4ZPD4mnq9HlVVDT1Qt9sduU+pNkrv7XZ7psefxXMw6541H6qqavR1XjfQzwGeB1wBPB/4GLApM5cHjx8Fto0apNVqjXzhVFU1ty+uee59JZ8Dlardbtd6nXc6nVW31w30x4AvZ+b3gYyILv1llyctAUdqji1JqqHup1w+DVwWEQsR8cPAU4B/HqytA+wBDjZQnyRpTLVm6Jn58Yi4CHiA/h+FfcB/APsjYitQAXc2VqUkaaTaH1vMzGtX2bxrHbVIktbBE4skqRAG+hmke+zErEuYunnsWaqr9pKLpm9xy2a2X3fP1I97+ObLp37MJ81jz1JdztAlqRAGeg3TWgbwhBpJp8MllxpcBpC0ETlDl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SCmGgS1IhDHRJKoSBLkmFWNflcyPimUAHeDlwHLgDWAYOAfsy8+R6C5Qkjaf2DD0itgB/BnxvsOkW4MbMvBBYAK5cf3mSpHGtZ4b+PuDDwPWD+zuA+wa3DwCXAHcPG6DX61FV1dCDdLvdkftMm98kJKkJVVU1mnG1Aj0iXgs8mpn3RsSTgb6QmcuD20eBbaPGabVaI8OxqioDVFKR2u12rYzrdDqrbq87Q/9VYDkiLgZeAvwV8MwVjy8BR2qOLUmqodYaemZelJm7MnM38BDwGuBAROwe7LIHONhEgZKk8TT5JdFvBvZHxFagAu5scGxJ0gjrDvTBLP1Ju9Y7niSpHk8skqRCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQpyxgd49dmLWJUjShtLktVymanHLZrZfd89Mjn345stnclxJGuaMnaFLkv4/A12SCmGgS1IhDHRJKoSBLkmFMNAlqRAGuiQVwkCXpELUOrEoIrYAtwPbgRZwE/Al4A5gGTgE7MvMk41UKUkaqe4M/dXAY5l5IXAZ8MfALcCNg20LwJXNlChJGkfdQP8H4G2D2wvAcWAHcN9g2wHg4vWVJkk6HbWWXDLzCYCIWALuBG4E3peZy4NdjgLbRo3T6/WoqmroPt1ud9V92u32aVYtSRtLVVVrZlwdtS/OFRHPAe4GPpSZfxsRv7/i4SXgyKgxWq3WyGCuqsrwllSkdrtdK+M6nc6q22stuUTEs4BPAm/JzNsHmx+MiN2D23uAg3XGliTVU3eG/lbgacDbIuLJtfQ3ALdGxFagor8UI0makrpr6G+gH+Cn2rW+ciRJdXlikSQVwkCXpEIY6JJUCANdkgphoEtSIQx0SSqEgS5JhTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiEMdEkqhIEuSYUw0CWpEAa6JBXCQJekQhjoklQIA12SClHrS6LXEhGbgA8BPwn0gF/PzIebPIYkaXVNz9D3AouZ+VLgOuD9DY8vSVpD04H+MuATAJn5WeBnGh5fkrSGheXl5cYGi4jbgLsy88Dg/teAF2Tm8dX273Q6jwJfbawASZoPz9uxY8czTt3Y6Bo68B1gacX9TWuFOcBqBUmS6ml6yeV+4BUAEXEe8MWGx5ckraHpGfrdwMsj4t+ABeBXGh5fkrSGRtfQJUmz44lFklQIA12SCmGgS1Ihmn5TtLZRlw2IiKuB1wHHgZsy8+MzKbRhY/T9RuCVg7v/mJm/O/0qJ2OcS0UM9rkH+Ghmfnj6VTZvjJ/5HuAd9D9Y0AH2ZWYRb3aN0fubgVcBJ4F3Z+bdMyl0QiJiJ/DezNx9yvafA95OP99uz8z9dcbfSDP0vaxx2YCIeDbweuAC4FLgPRHRmkWRE7CXtft+AfDLwPnAecAlEfHiWRQ5IXsZfamIm4CnTbOoKdjL2j/zJeAPgCsycydwGDhnBjVOyl7W7v2pwBuAlwKXAB+cfnmTExHXArcBi6ds3wJ8gH7Pu4DfiIhn1TnGRgr0YZcNOBe4PzN7mfk48DBQSrAN6/s/gcsy88RghrYF6E6/xIkZeqmIiPgF+jO1T0y/tIka1vf59M/feH9EHAS+kZmPTr/EiRnW+//QP3P8KYP/Tk69usl6BLhqle1t4OHM/HZmfh/4NHBRnQNspEA/G3h8xf0TEXHWGo8dBbZNq7AJW7PvzDyWmd+MiIWIeB/wYGZ+ZSZVTsaavUfEi+j/0/vtsyhswob9rp8D/CzwFmAPcE1E/NiU65ukYb1DfxLzJeALwK3TLGzSMvMu4NgqDzWWbxsp0IddNuDUx5aAI1Oqa9KGXi4hIhaBvxns85tTrm3ShvX+GuBHgE8BrwXeFBGXTbe8iRnW92PA5zLz65n5BPCvwEumXN8kDet9D/BDwPOB5wJ7I+LcKdc3C43l20YK9GGXDXgAuDAiFiNiG/1/ohyafokTsWbfEbEAfBT498x8XWaemE2JE7Nm75l5bWbuHLx5dAdwS2aWsvQy7Hf9C8CLIuKcwcz1PPoz1lIM6/3bwPeAXmZ26YfaU6dc3yxUwAsj4ukRsZX+cstn6gy0YT7lwiqXDYiIN9FfW/pYRNwKHKT/R+iGwQ+8BGv2DWym/yZJa/DJB4DrM7PWD3sDGvozn21pEzXqd/164N7Bvn+fmaVMXmB07xcDn42Ik/TXkv9phrVOVES8CviBzPzzwXNwL/18uz0z/6vOmJ76L0mF2EhLLpKkdTDQJakQBrokFcJAl6RCGOiSVAgDXZIKYaBLUiH+Fx6qBsOSWYtrAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mdl.predict( X_whole[pos_index,:,:]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mdl.predict( X_whole[neg_index,:,:]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(mdl.predict( X_whole[nbc_index,:,:]));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "predicted mean 0.6868693232536316, basemean 0.13375019063596158, relative risk 5.135464256070766\n",
      "predicted mean 0.20216992497444153, basemean 0.3413146255909715, relative risk 0.5923271662454929\n",
      "predicted mean 0.21069438755512238, basemean 0.7924355650449901, relative risk 0.26588204372573854\n",
      "-------------------\n",
      "predicted mean 0.6835600733757019, basemean 0.13375019063596158, relative risk 5.110722236173862\n",
      "predicted mean 0.20189565420150757, basemean 0.3413146255909715, relative risk 0.5915235945483848\n",
      "predicted mean 0.20645488798618317, basemean 0.7924355650449901, relative risk 0.26053208247217147\n",
      "-------------------\n",
      "predicted mean 0.6844802498817444, basemean 0.13375019063596158, relative risk 5.117602050712198\n",
      "predicted mean 0.20040695369243622, basemean 0.3413146255909715, relative risk 0.5871619282222093\n",
      "predicted mean 0.20789897441864014, basemean 0.7924355650449901, relative risk 0.2623544217211361\n",
      "-------------------\n",
      "predicted mean 0.6820235252380371, basemean 0.13375019063596158, relative risk 5.099234042173101\n",
      "predicted mean 0.19772213697433472, basemean 0.3413146255909715, relative risk 0.5792958231191746\n",
      "predicted mean 0.21040989458560944, basemean 0.7924355650449901, relative risk 0.2655230328710241\n",
      "-------------------\n",
      "predicted mean 0.6797847151756287, basemean 0.13375019063596158, relative risk 5.082495299209346\n",
      "predicted mean 0.1984391212463379, basemean 0.3413146255909715, relative risk 0.5813964781109193\n",
      "predicted mean 0.20683589577674866, basemean 0.7924355650449901, relative risk 0.2610128884927138\n",
      "-------------------\n",
      "predicted mean 0.6820146441459656, basemean 0.13375019063596158, relative risk 5.099167641579356\n",
      "predicted mean 0.19620156288146973, basemean 0.3413146255909715, relative risk 0.5748407720347618\n",
      "predicted mean 0.20367293059825897, basemean 0.7924355650449901, relative risk 0.25702144071069744\n",
      "-------------------\n",
      "predicted mean 0.6807163953781128, basemean 0.13375019063596158, relative risk 5.089461122570451\n",
      "predicted mean 0.19614456593990326, basemean 0.3413146255909715, relative risk 0.5746737796550249\n",
      "predicted mean 0.20394137501716614, basemean 0.7924355650449901, relative risk 0.25736019938174715\n",
      "-------------------\n",
      "predicted mean 0.6805475354194641, basemean 0.13375019063596158, relative risk 5.088198620006187\n",
      "predicted mean 0.1940600574016571, basemean 0.3413146255909715, relative risk 0.5685664863193323\n",
      "predicted mean 0.20366054773330688, basemean 0.7924355650449901, relative risk 0.25700581437399794\n",
      "-------------------\n",
      "predicted mean 0.6831055879592896, basemean 0.13375019063596158, relative risk 5.107324219212156\n",
      "predicted mean 0.1958780735731125, basemean 0.3413146255909715, relative risk 0.5738929975062103\n",
      "predicted mean 0.20521867275238037, basemean 0.7924355650449901, relative risk 0.25897206259379485\n",
      "-------------------\n",
      "predicted mean 0.6799383163452148, basemean 0.13375019063596158, relative risk 5.083643717532011\n",
      "predicted mean 0.19608935713768005, basemean 0.3413146255909715, relative risk 0.5745120262519071\n",
      "predicted mean 0.20697039365768433, basemean 0.7924355650449901, relative risk 0.2611826157069738\n",
      "-------------------\n",
      "predicted mean 0.6724601984024048, basemean 0.13375019063596158, relative risk 5.027732635033715\n",
      "predicted mean 0.1958361715078354, basemean 0.3413146255909715, relative risk 0.5737702308207671\n",
      "predicted mean 0.20138099789619446, basemean 0.7924355650449901, relative risk 0.25412917690634085\n",
      "-------------------\n",
      "predicted mean 0.6759703159332275, basemean 0.13375019063596158, relative risk 5.053976467017301\n",
      "predicted mean 0.19515272974967957, basemean 0.3413146255909715, relative risk 0.5717678502987708\n",
      "predicted mean 0.2034824639558792, basemean 0.7924355650449901, relative risk 0.2567810847110662\n",
      "-------------------\n",
      "predicted mean 0.6739184856414795, basemean 0.13375019063596158, relative risk 5.03863570165471\n",
      "predicted mean 0.1966606229543686, basemean 0.3413146255909715, relative risk 0.5761857483073257\n",
      "predicted mean 0.2017824351787567, basemean 0.7924355650449901, relative risk 0.254635763561799\n",
      "-------------------\n",
      "predicted mean 0.6799652576446533, basemean 0.13375019063596158, relative risk 5.083845147521085\n",
      "predicted mean 0.19734278321266174, basemean 0.3413146255909715, relative risk 0.5781843742294116\n",
      "predicted mean 0.20455634593963623, basemean 0.7924355650449901, relative risk 0.2581362510250567\n",
      "-------------------\n",
      "predicted mean 0.6737779974937439, basemean 0.13375019063596158, relative risk 5.0375853244771704\n",
      "predicted mean 0.20029014348983765, basemean 0.3413146255909715, relative risk 0.5868196920745601\n",
      "predicted mean 0.20673473179340363, basemean 0.7924355650449901, relative risk 0.2608852263990276\n",
      "-------------------\n",
      "predicted mean 0.6749902367591858, basemean 0.13375019063596158, relative risk 5.0466487827023725\n",
      "predicted mean 0.20191757380962372, basemean 0.3413146255909715, relative risk 0.5915878156701084\n",
      "predicted mean 0.20882871747016907, basemean 0.7924355650449901, relative risk 0.263527694467263\n",
      "-------------------\n",
      "predicted mean 0.6753593683242798, basemean 0.13375019063596158, relative risk 5.049408640937631\n",
      "predicted mean 0.20117777585983276, basemean 0.3413146255909715, relative risk 0.5894203200683304\n",
      "predicted mean 0.20718902349472046, basemean 0.7924355650449901, relative risk 0.2614585117503622\n",
      "-------------------\n",
      "predicted mean 0.6720908880233765, basemean 0.13375019063596158, relative risk 5.024971439873751\n",
      "predicted mean 0.2004367560148239, basemean 0.3413146255909715, relative risk 0.5872492444991959\n",
      "predicted mean 0.20923125743865967, basemean 0.7924355650449901, relative risk 0.2640356726376619\n",
      "-------------------\n",
      "predicted mean 0.6652259826660156, basemean 0.13375019063596158, relative risk 4.973645117834737\n",
      "predicted mean 0.199393168091774, basemean 0.3413146255909715, relative risk 0.5841916904279545\n",
      "predicted mean 0.20695239305496216, basemean 0.7924355650449901, relative risk 0.26115990016577884\n",
      "-------------------\n",
      "predicted mean 0.6641181707382202, basemean 0.13375019063596158, relative risk 4.965362423637981\n",
      "predicted mean 0.1963430792093277, basemean 0.3413146255909715, relative risk 0.5752553933760329\n",
      "predicted mean 0.20480769872665405, basemean 0.7924355650449901, relative risk 0.25845344121452474\n",
      "-------------------\n",
      "predicted mean 0.666054904460907, basemean 0.13375019063596158, relative risk 4.979842655131319\n",
      "predicted mean 0.19682571291923523, basemean 0.3413146255909715, relative risk 0.5766694368236932\n",
      "predicted mean 0.2072393298149109, basemean 0.7924355650449901, relative risk 0.2615219949184701\n",
      "-------------------\n",
      "predicted mean 0.6653123497962952, basemean 0.13375019063596158, relative risk 4.974290852467853\n",
      "predicted mean 0.19733020663261414, basemean 0.3413146255909715, relative risk 0.5781475267605232\n",
      "predicted mean 0.20842546224594116, basemean 0.7924355650449901, relative risk 0.2630188136925782\n",
      "-------------------\n",
      "predicted mean 0.6720996499061584, basemean 0.13375019063596158, relative risk 5.025036949184356\n",
      "predicted mean 0.19729654490947723, basemean 0.3413146255909715, relative risk 0.5780489030256668\n",
      "predicted mean 0.20890356600284576, basemean 0.7924355650449901, relative risk 0.26362214824493063\n",
      "-------------------\n",
      "predicted mean 0.6718974709510803, basemean 0.13375019063596158, relative risk 5.023525332983162\n",
      "predicted mean 0.2332771271467209, basemean 0.3413146255909715, relative risk 0.6834665427618628\n",
      "predicted mean 0.2730138301849365, basemean 0.7924355650449901, relative risk 0.3445249585301441\n",
      "-------------------\n",
      "predicted mean 0.6557024121284485, basemean 0.13375019063596158, relative risk 4.902440953621706\n",
      "predicted mean 0.2683534622192383, basemean 0.3413146255909715, relative risk 0.7862348756798684\n",
      "predicted mean 0.31652891635894775, basemean 0.7924355650449901, relative risk 0.3994380493775251\n",
      "-------------------\n",
      "predicted mean 0.6446500420570374, basemean 0.13375019063596158, relative risk 4.819806528811851\n",
      "predicted mean 0.28620821237564087, basemean 0.3413146255909715, relative risk 0.8385465811202311\n",
      "predicted mean 0.32422319054603577, basemean 0.7924355650449901, relative risk 0.4091477021574974\n",
      "-------------------\n",
      "predicted mean 0.6435652375221252, basemean 0.13375019063596158, relative risk 4.811695852260633\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean 0.3062867224216461, basemean 0.3413146255909715, relative risk 0.8973735652005065\n",
      "predicted mean 0.32442760467529297, basemean 0.7924355650449901, relative risk 0.4094056589407036\n",
      "-------------------\n",
      "predicted mean 0.631060779094696, basemean 0.13375019063596158, relative risk 4.718204707552932\n",
      "predicted mean 0.32718101143836975, basemean 0.3413146255909715, relative risk 0.9585906577307375\n",
      "predicted mean 0.32141104340553284, basemean 0.7924355650449901, relative risk 0.40559896297345627\n",
      "-------------------\n",
      "predicted mean 0.6177211403846741, basemean 0.13375019063596158, relative risk 4.618469233183931\n",
      "predicted mean 0.34054988622665405, basemean 0.3413146255909715, relative risk 0.997759429842793\n",
      "predicted mean 0.31981417536735535, basemean 0.7924355650449901, relative risk 0.40358382368817336\n",
      "-------------------\n",
      "predicted mean 0.6224433183670044, basemean 0.13375019063596158, relative risk 4.653775186468013\n",
      "predicted mean 0.33970528841018677, basemean 0.3413146255909715, relative risk 0.9952848865529914\n",
      "predicted mean 0.31365835666656494, basemean 0.7924355650449901, relative risk 0.3958155975101359\n",
      "-------------------\n",
      "predicted mean 0.6198937892913818, basemean 0.13375019063596158, relative risk 4.634713314006374\n",
      "predicted mean 0.34171316027641296, basemean 0.3413146255909715, relative risk 1.0011676460824128\n",
      "predicted mean 0.3133094310760498, basemean 0.7924355650449901, relative risk 0.3953752770526671\n",
      "-------------------\n",
      "predicted mean 0.6236189603805542, basemean 0.13375019063596158, relative risk 4.662565020770004\n",
      "predicted mean 0.3424142003059387, basemean 0.3413146255909715, relative risk 1.0032215868659697\n",
      "predicted mean 0.3176839351654053, basemean 0.7924355650449901, relative risk 0.40089560486519676\n",
      "-------------------\n",
      "predicted mean 0.625632643699646, basemean 0.13375019063596158, relative risk 4.677620575528596\n",
      "predicted mean 0.34077808260917664, basemean 0.3413146255909715, relative risk 0.9984280105756798\n",
      "predicted mean 0.31267446279525757, basemean 0.7924355650449901, relative risk 0.3945739900978645\n",
      "-------------------\n",
      "predicted mean 0.6241492033004761, basemean 0.13375019063596158, relative risk 4.666529448165589\n",
      "predicted mean 0.3423631191253662, basemean 0.3413146255909715, relative risk 1.0030719267672146\n",
      "predicted mean 0.31429773569107056, basemean 0.7924355650449901, relative risk 0.3966224505247016\n",
      "-------------------\n",
      "predicted mean 0.6159664988517761, basemean 0.13375019063596158, relative risk 4.6053504366831195\n",
      "predicted mean 0.34369176626205444, basemean 0.3413146255909715, relative risk 1.0069646610278333\n",
      "predicted mean 0.3196088373661041, basemean 0.7924355650449901, relative risk 0.4033247010410979\n",
      "-------------------\n",
      "predicted mean 0.613487184047699, basemean 0.13375019063596158, relative risk 4.586813529989466\n",
      "predicted mean 0.35141023993492126, basemean 0.3413146255909715, relative risk 1.0295786162883283\n",
      "predicted mean 0.29921120405197144, basemean 0.7924355650449901, relative risk 0.3775842696244759\n",
      "-------------------\n",
      "predicted mean 0.6112983226776123, basemean 0.13375019063596158, relative risk 4.570448234660323\n",
      "predicted mean 0.3488987684249878, basemean 0.3413146255909715, relative risk 1.0222203863103865\n",
      "predicted mean 0.30277019739151, basemean 0.7924355650449901, relative risk 0.3820754781170383\n",
      "-------------------\n",
      "predicted mean 0.6126606464385986, basemean 0.13375019063596158, relative risk 4.580633818355634\n",
      "predicted mean 0.3489709496498108, basemean 0.3413146255909715, relative risk 1.0224318663332481\n",
      "predicted mean 0.30803635716438293, basemean 0.7924355650449901, relative risk 0.3887210149974709\n",
      "-------------------\n",
      "predicted mean 0.6199132204055786, basemean 0.13375019063596158, relative risk 4.634858593157786\n",
      "predicted mean 0.35227733850479126, basemean 0.3413146255909715, relative risk 1.0321190833672549\n",
      "predicted mean 0.3247929513454437, basemean 0.7924355650449901, relative risk 0.409866701688236\n",
      "-------------------\n",
      "predicted mean 0.6303028464317322, basemean 0.13375019063596158, relative risk 4.712537929364729\n",
      "predicted mean 0.3611777722835541, basemean 0.3413146255909715, relative risk 1.0581960021730403\n",
      "predicted mean 0.3329503536224365, basemean 0.7924355650449901, relative risk 0.4201607907433249\n",
      "-------------------\n",
      "predicted mean 0.6362783312797546, basemean 0.13375019063596158, relative risk 4.757214387914881\n",
      "predicted mean 0.36136460304260254, basemean 0.3413146255909715, relative risk 1.0587433879134696\n",
      "predicted mean 0.332841694355011, basemean 0.7924355650449901, relative risk 0.4200236701088928\n",
      "-------------------\n",
      "predicted mean 0.6304185390472412, basemean 0.13375019063596158, relative risk 4.71340291964967\n",
      "predicted mean 0.36390694975852966, basemean 0.3413146255909715, relative risk 1.0661920775543696\n",
      "predicted mean 0.3386616110801697, basemean 0.7924355650449901, relative risk 0.42736801074916714\n",
      "-------------------\n",
      "predicted mean 0.6273641586303711, basemean 0.13375019063596158, relative risk 4.690566463100733\n",
      "predicted mean 0.3647059500217438, basemean 0.3413146255909715, relative risk 1.0685330269403817\n",
      "predicted mean 0.3413277566432953, basemean 0.7924355650449901, relative risk 0.4307325058333501\n",
      "-------------------\n",
      "predicted mean 0.6233640909194946, basemean 0.13375019063596158, relative risk 4.660659457422036\n",
      "predicted mean 0.3664473295211792, basemean 0.3413146255909715, relative risk 1.0736350043209884\n",
      "predicted mean 0.3432421088218689, basemean 0.7924355650449901, relative risk 0.4331482885960343\n",
      "-------------------\n",
      "predicted mean 0.6222838163375854, basemean 0.13375019063596158, relative risk 4.652582649630043\n",
      "predicted mean 0.3671989142894745, basemean 0.3413146255909715, relative risk 1.0758370335103147\n",
      "predicted mean 0.3443407714366913, basemean 0.7924355650449901, relative risk 0.43453472638767987\n",
      "-------------------\n",
      "predicted mean 0.620926558971405, basemean 0.13375019063596158, relative risk 4.642434945468076\n",
      "predicted mean 0.36845603585243225, basemean 0.3413146255909715, relative risk 1.0795202087061655\n",
      "predicted mean 0.3437421917915344, basemean 0.7924355650449901, relative risk 0.43377935942592205\n",
      "-------------------\n",
      "predicted mean 0.6169872283935547, basemean 0.13375019063596158, relative risk 4.612982048547933\n",
      "predicted mean 0.36848700046539307, basemean 0.3413146255909715, relative risk 1.0796109303179546\n",
      "predicted mean 0.3439801037311554, basemean 0.7924355650449901, relative risk 0.43407958817651765\n",
      "-------------------\n",
      "predicted mean 0.6149229407310486, basemean 0.13375019063596158, relative risk 4.597548144097474\n",
      "predicted mean 0.3695330321788788, basemean 0.3413146255909715, relative risk 1.082675644323909\n",
      "predicted mean 0.34396764636039734, basemean 0.7924355650449901, relative risk 0.43406386781853834\n",
      "-------------------\n",
      "predicted mean 0.6208773851394653, basemean 0.13375019063596158, relative risk 4.642067291173858\n",
      "predicted mean 0.37112224102020264, basemean 0.3413146255909715, relative risk 1.0873317847942219\n",
      "predicted mean 0.34324413537979126, basemean 0.7924355650449901, relative risk 0.4331508459748443\n",
      "-------------------\n",
      "predicted mean 0.6196621656417847, basemean 0.13375019063596158, relative risk 4.632981550870219\n",
      "predicted mean 0.37117111682891846, basemean 0.3413146255909715, relative risk 1.08747498348848\n",
      "predicted mean 0.3454191982746124, basemean 0.7924355650449901, relative risk 0.435895627999737\n",
      "-------------------\n",
      "predicted mean 0.6241303086280823, basemean 0.13375019063596158, relative risk 4.666388179788296\n",
      "predicted mean 0.36852553486824036, basemean 0.3413146255909715, relative risk 1.0797238302640983\n",
      "predicted mean 0.34718331694602966, basemean 0.7924355650449901, relative risk 0.4381218262538715\n",
      "-------------------\n",
      "predicted mean 0.615227997303009, basemean 0.13375019063596158, relative risk 4.599828937646328\n",
      "predicted mean 0.3700602650642395, basemean 0.3413146255909715, relative risk 1.0842203565800796\n",
      "predicted mean 0.3504839241504669, basemean 0.7924355650449901, relative risk 0.4422869689481546\n",
      "-------------------\n",
      "predicted mean 0.6046896576881409, basemean 0.13375019063596158, relative risk 4.521037725725359\n",
      "predicted mean 0.3670802712440491, basemean 0.3413146255909715, relative risk 1.075489427411631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean 0.3524194657802582, basemean 0.7924355650449901, relative risk 0.4447294913628085\n",
      "-------------------\n",
      "predicted mean 0.6021213531494141, basemean 0.13375019063596158, relative risk 4.501835476169564\n",
      "predicted mean 0.3687407970428467, basemean 0.3413146255909715, relative risk 1.080354515732773\n",
      "predicted mean 0.35214290022850037, basemean 0.7924355650449901, relative risk 0.4443804843722627\n",
      "-------------------\n",
      "predicted mean 0.6049824357032776, basemean 0.13375019063596158, relative risk 4.52322671711105\n",
      "predicted mean 0.3671259582042694, basemean 0.3413146255909715, relative risk 1.0756232832642514\n",
      "predicted mean 0.3464893698692322, basemean 0.7924355650449901, relative risk 0.4372461120539945\n",
      "-------------------\n",
      "predicted mean 0.608855128288269, basemean 0.13375019063596158, relative risk 4.552181386757332\n",
      "predicted mean 0.3686075210571289, basemean 0.3413146255909715, relative risk 1.0799640373420887\n",
      "predicted mean 0.35065850615501404, basemean 0.7924355650449901, relative risk 0.44250727961093667\n",
      "-------------------\n",
      "predicted mean 0.6186439990997314, basemean 0.13375019063596158, relative risk 4.62536910159286\n",
      "predicted mean 0.36855190992355347, basemean 0.3413146255909715, relative risk 1.0798011051692316\n",
      "predicted mean 0.35737690329551697, basemean 0.7924355650449901, relative risk 0.4509854416683419\n",
      "-------------------\n",
      "predicted mean 0.6132545471191406, basemean 0.13375019063596158, relative risk 4.585074190946641\n",
      "predicted mean 0.36509954929351807, basemean 0.3413146255909715, relative risk 1.0696862130105442\n",
      "predicted mean 0.3496539890766144, basemean 0.7924355650449901, relative risk 0.44123964710842195\n",
      "-------------------\n",
      "predicted mean 0.6071282029151917, basemean 0.13375019063596158, relative risk 4.539269813585988\n",
      "predicted mean 0.36943134665489197, basemean 0.3413146255909715, relative risk 1.0823777211868304\n",
      "predicted mean 0.3535824120044708, basemean 0.7924355650449901, relative risk 0.44619705071464877\n",
      "-------------------\n",
      "predicted mean 0.6029055714607239, basemean 0.13375019063596158, relative risk 4.507698782289585\n",
      "predicted mean 0.3690696060657501, basemean 0.3413146255909715, relative risk 1.0813178762167666\n",
      "predicted mean 0.3559553325176239, basemean 0.7924355650449901, relative risk 0.449191515650127\n",
      "-------------------\n",
      "predicted mean 0.6043623089790344, basemean 0.13375019063596158, relative risk 4.518590262229793\n",
      "predicted mean 0.36638379096984863, basemean 0.3413146255909715, relative risk 1.0734488460184528\n",
      "predicted mean 0.35973891615867615, basemean 0.7924355650449901, relative risk 0.45396614188846024\n",
      "-------------------\n",
      "predicted mean 0.6187425255775452, basemean 0.13375019063596158, relative risk 4.626105747106002\n",
      "predicted mean 0.36955615878105164, basemean 0.3413146255909715, relative risk 1.0827434017548505\n",
      "predicted mean 0.3596232235431671, basemean 0.7924355650449901, relative risk 0.45382014564521683\n",
      "-------------------\n",
      "predicted mean 0.6230882406234741, basemean 0.13375019063596158, relative risk 4.65859702824187\n",
      "predicted mean 0.3691461682319641, basemean 0.3413146255909715, relative risk 1.0815421917323453\n",
      "predicted mean 0.3641292452812195, basemean 0.7924355650449901, relative risk 0.45950643982081524\n",
      "-------------------\n",
      "predicted mean 0.621706485748291, basemean 0.13375019063596158, relative risk 4.648266165395147\n",
      "predicted mean 0.36755457520484924, basemean 0.3413146255909715, relative risk 1.0768790659598733\n",
      "predicted mean 0.36343273520469666, basemean 0.7924355650449901, relative risk 0.4586274912889137\n",
      "-------------------\n",
      "predicted mean 0.6134346127510071, basemean 0.13375019063596158, relative risk 4.5864204741258305\n",
      "predicted mean 0.37226226925849915, basemean 0.3413146255909715, relative risk 1.0906718943377922\n",
      "predicted mean 0.35963308811187744, basemean 0.7924355650449901, relative risk 0.4538325940626598\n",
      "-------------------\n",
      "predicted mean 0.6081663966178894, basemean 0.13375019063596158, relative risk 4.5470319984304455\n",
      "predicted mean 0.3731125295162201, basemean 0.3413146255909715, relative risk 1.0931630277202213\n",
      "predicted mean 0.3565254211425781, basemean 0.7924355650449901, relative risk 0.4499109288744967\n",
      "-------------------\n",
      "predicted mean 0.6058316230773926, basemean 0.13375019063596158, relative risk 4.529575772541007\n",
      "predicted mean 0.3697846829891205, basemean 0.3413146255909715, relative risk 1.0834129429667843\n",
      "predicted mean 0.3602793514728546, basemean 0.7924355650449901, relative risk 0.4546481346434772\n",
      "-------------------\n",
      "predicted mean 0.6110828518867493, basemean 0.13375019063596158, relative risk 4.568837240389298\n",
      "predicted mean 0.37418872117996216, basemean 0.3413146255909715, relative risk 1.096316105798486\n",
      "predicted mean 0.36140257120132446, basemean 0.7924355650449901, relative risk 0.4560655618489385\n",
      "-------------------\n",
      "predicted mean 0.6142656207084656, basemean 0.13375019063596158, relative risk 4.5926336088773185\n",
      "predicted mean 0.3679908215999603, basemean 0.3413146255909715, relative risk 1.078157201622404\n",
      "predicted mean 0.3661678731441498, basemean 0.7924355650449901, relative risk 0.46207905007817357\n",
      "-------------------\n",
      "predicted mean 0.6093817949295044, basemean 0.13375019063596158, relative risk 4.556119075658791\n",
      "predicted mean 0.37020978331565857, basemean 0.3413146255909715, relative risk 1.0846584223417217\n",
      "predicted mean 0.36438679695129395, basemean 0.7924355650449901, relative risk 0.459831452580761\n",
      "-------------------\n",
      "predicted mean 0.6111908555030823, basemean 0.13375019063596158, relative risk 4.56964474291187\n",
      "predicted mean 0.3716481328010559, basemean 0.3413146255909715, relative risk 1.0888725678179283\n",
      "predicted mean 0.36021023988723755, basemean 0.7924355650449901, relative risk 0.45456092050435265\n"
     ]
    }
   ],
   "source": [
    "x = X_whole[pos_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_pos = mdl.predict(X_new)\n",
    "x = X_whole[neg_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_neg = mdl.predict(X_new)\n",
    "x = X_whole[nbc_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_nbc = mdl.predict(X_new)\n",
    "\n",
    "for i in range(1,X_whole.shape[1]):\n",
    "    print(\"-------------------\")\n",
    "    # postive\n",
    "    x = X_whole[pos_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(Y_whole[:,0])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(y), basemean, np.mean(y)/basemean))\n",
    "    y_pos = np.column_stack((y_pos,y))\n",
    "    # negative\n",
    "    x = X_whole[neg_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(1-Y_whole[:,1])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(1-y), basemean, np.mean(1-y)/basemean))\n",
    "    y_neg = np.column_stack((y_neg,y))\n",
    "    # no blood culture\n",
    "    x = X_whole[nbc_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(1-Y_whole[:,2])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(1-y), basemean, np.mean(1-y)/basemean))\n",
    "    y_nbc = np.column_stack((y_nbc,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_prob  time    y_true      risk\n",
      "0  0.863392   -48  positive  6.455257\n",
      "1  0.859521   -47  positive  6.426315\n",
      "2  0.862688   -46  positive  6.449992\n",
      "3  0.863174   -45  positive  6.453628\n",
      "4  0.862604   -44  positive  6.449370\n",
      "(63144, 4)\n",
      "     y_prob  time    y_true      risk\n",
      "0  0.868440   -48  negative  0.385450\n",
      "1  0.864703   -47  negative  0.396401\n",
      "2  0.867793   -46  negative  0.387346\n",
      "3  0.868465   -45  negative  0.385378\n",
      "4  0.868297   -44  negative  0.385871\n",
      "(310968, 4)\n",
      "     y_prob  time    y_true      risk\n",
      "0  0.862071   -48  baseline  0.174058\n",
      "1  0.858172   -47  baseline  0.178977\n",
      "2  0.861345   -46  baseline  0.174973\n",
      "3  0.861797   -45  baseline  0.174403\n",
      "4  0.861139   -44  baseline  0.175233\n",
      "(97992, 4)\n"
     ]
    }
   ],
   "source": [
    "df_pos = pd.DataFrame(data={'y_prob': y_pos.reshape([-1]), 'time': list(range(-48,24))*y_pos.shape[0]})\n",
    "df_pos['y_true'] = 'positive'\n",
    "df_pos['risk'] = df_pos['y_prob']/np.mean(Y_whole[:,0])\n",
    "print(df_pos.head(5))\n",
    "print(df_pos.shape)\n",
    "df_neg = pd.DataFrame(data={'y_prob': y_neg.reshape([-1]), 'time': list(range(-48,24))*y_neg.shape[0]})\n",
    "df_neg['y_true'] = 'negative'\n",
    "df_neg['risk'] = (1-df_neg['y_prob'])/np.mean(1-Y_whole[:,1])\n",
    "print(df_neg.head(5))\n",
    "print(df_neg.shape)\n",
    "df_nbc = pd.DataFrame(data={'y_prob': y_nbc.reshape([-1]), 'time': list(range(-48,24))*y_nbc.shape[0]})\n",
    "df_nbc['y_true'] = 'baseline'\n",
    "df_nbc['risk'] = (1-df_nbc['y_prob'])/np.mean(1-Y_whole[:,2])\n",
    "print(df_nbc.head(5))\n",
    "print(df_nbc.shape)\n",
    "df_res = pd.concat([df_pos,df_neg,df_nbc], axis=0)\n",
    "df_res.to_csv(\"./tte_plot_3class.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res = pd.read_csv(\"./tte_plot_3class.csv\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=df_res, x=\"time\", y=\"risk\", hue=\"y_true\", palette=['red','orange', 'blue']);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# binary raw scale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "# median imputation\n",
    "train_df.fillna(whole_df.median(), inplace=True)\n",
    "valid_df.fillna(whole_df.median(), inplace=True)\n",
    "whole_df.fillna(whole_df.median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 72, 32)\n",
      "(6557, 1)\n",
      "(5226, 72, 32)\n",
      "(5226, 1)\n",
      "(1331, 72, 32)\n",
      "(1331, 1)\n"
     ]
    }
   ],
   "source": [
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos']\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,72,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,1) )[:,0,:]\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_train = train_df[input_vars].values\n",
    "Y_train = train_df[output_var].values\n",
    "X_train = np.reshape(X_train, (-1,72,32) )\n",
    "Y_train = np.reshape(Y_train, (-1,72,1) )[:,0,:]\n",
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_valid = valid_df[input_vars].values\n",
    "Y_valid = valid_df[output_var].values\n",
    "X_valid = np.reshape(X_valid, (-1,72,32) )\n",
    "Y_valid = np.reshape(Y_valid, (-1,72,1) )[:,0,:]\n",
    "print(X_valid.shape)\n",
    "print(Y_valid.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm (LSTM)                  (None, 72, 32)            8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 72, 32)            128       \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 32)                8320      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32)                128       \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 16,929\n",
      "Trainable params: 16,801\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 12s 52ms/step - loss: 0.7100 - AUROC: 0.5394 - AUPRC: 0.1543 - val_loss: 0.4210 - val_AUROC: 0.6200 - val_AUPRC: 0.2305\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.4019 - AUROC: 0.6366 - AUPRC: 0.2277 - val_loss: 0.3920 - val_AUROC: 0.6471 - val_AUPRC: 0.2400\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3805 - AUROC: 0.6515 - AUPRC: 0.2426 - val_loss: 0.4012 - val_AUROC: 0.6296 - val_AUPRC: 0.2314\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3662 - AUROC: 0.6647 - AUPRC: 0.2709 - val_loss: 0.3969 - val_AUROC: 0.6284 - val_AUPRC: 0.2429\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3599 - AUROC: 0.6640 - AUPRC: 0.2510 - val_loss: 0.4012 - val_AUROC: 0.6001 - val_AUPRC: 0.2561\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 35ms/step - loss: 0.3888 - AUROC: 0.6244 - AUPRC: 0.2008 - val_loss: 0.3771 - val_AUROC: 0.6835 - val_AUPRC: 0.3226\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3671 - AUROC: 0.6651 - AUPRC: 0.2326 - val_loss: 0.3875 - val_AUROC: 0.6556 - val_AUPRC: 0.2511\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3550 - AUROC: 0.7045 - AUPRC: 0.2819 - val_loss: 0.3745 - val_AUROC: 0.6897 - val_AUPRC: 0.3297\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3333 - AUROC: 0.7252 - AUPRC: 0.3283 - val_loss: 0.3688 - val_AUROC: 0.7139 - val_AUPRC: 0.3397\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3515 - AUROC: 0.7316 - AUPRC: 0.3316 - val_loss: 0.3757 - val_AUROC: 0.6924 - val_AUPRC: 0.3098\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3422 - AUROC: 0.7446 - AUPRC: 0.3359 - val_loss: 0.3783 - val_AUROC: 0.6746 - val_AUPRC: 0.3176\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3497 - AUROC: 0.7079 - AUPRC: 0.3110 - val_loss: 0.3791 - val_AUROC: 0.6768 - val_AUPRC: 0.3013\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 6s 38ms/step - loss: 0.3415 - AUROC: 0.7429 - AUPRC: 0.3750 - val_loss: 0.3679 - val_AUROC: 0.7008 - val_AUPRC: 0.3583\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3439 - AUROC: 0.7275 - AUPRC: 0.3695 - val_loss: 0.3713 - val_AUROC: 0.7014 - val_AUPRC: 0.3475\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3281 - AUROC: 0.7208 - AUPRC: 0.3696 - val_loss: 0.4111 - val_AUROC: 0.6243 - val_AUPRC: 0.2768\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3222 - AUROC: 0.7372 - AUPRC: 0.3593 - val_loss: 0.3548 - val_AUROC: 0.7475 - val_AUPRC: 0.3796\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3271 - AUROC: 0.7635 - AUPRC: 0.4027 - val_loss: 0.3662 - val_AUROC: 0.7151 - val_AUPRC: 0.3691\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3473 - AUROC: 0.7461 - AUPRC: 0.4007 - val_loss: 0.3813 - val_AUROC: 0.6688 - val_AUPRC: 0.3181\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3206 - AUROC: 0.7589 - AUPRC: 0.3596 - val_loss: 0.3693 - val_AUROC: 0.7140 - val_AUPRC: 0.3738\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3254 - AUROC: 0.7766 - AUPRC: 0.4198 - val_loss: 0.3637 - val_AUROC: 0.7252 - val_AUPRC: 0.3605\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3255 - AUROC: 0.7667 - AUPRC: 0.4100 - val_loss: 0.3664 - val_AUROC: 0.7173 - val_AUPRC: 0.3526\n",
      "Epoch 22/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3436 - AUROC: 0.7218 - AUPRC: 0.3864 - val_loss: 0.3705 - val_AUROC: 0.7084 - val_AUPRC: 0.3412\n",
      "Epoch 23/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3583 - AUROC: 0.7048 - AUPRC: 0.2901 - val_loss: 0.3961 - val_AUROC: 0.6503 - val_AUPRC: 0.2677\n",
      "Epoch 24/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3591 - AUROC: 0.7006 - AUPRC: 0.2824 - val_loss: 0.3974 - val_AUROC: 0.6480 - val_AUPRC: 0.2547\n",
      "Epoch 25/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3608 - AUROC: 0.6996 - AUPRC: 0.2756 - val_loss: 0.3869 - val_AUROC: 0.6763 - val_AUPRC: 0.2421\n",
      "Epoch 26/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3533 - AUROC: 0.7126 - AUPRC: 0.2768 - val_loss: 0.3942 - val_AUROC: 0.6830 - val_AUPRC: 0.2892\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3391 - AUROC: 0.7444 - AUPRC: 0.3585 - val_loss: 0.3559 - val_AUROC: 0.7375 - val_AUPRC: 0.3676\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3304 - AUROC: 0.7603 - AUPRC: 0.3984 - val_loss: 0.3454 - val_AUROC: 0.7596 - val_AUPRC: 0.4046\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3232 - AUROC: 0.7766 - AUPRC: 0.4159 - val_loss: 0.3447 - val_AUROC: 0.7543 - val_AUPRC: 0.4138\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3236 - AUROC: 0.7765 - AUPRC: 0.4205 - val_loss: 0.3408 - val_AUROC: 0.7603 - val_AUPRC: 0.4324\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 9s 57ms/step - loss: 0.3185 - AUROC: 0.7832 - AUPRC: 0.4279 - val_loss: 0.3420 - val_AUROC: 0.7584 - val_AUPRC: 0.4196\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 7s 43ms/step - loss: 0.3172 - AUROC: 0.7889 - AUPRC: 0.4242 - val_loss: 0.3419 - val_AUROC: 0.7602 - val_AUPRC: 0.4212\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3156 - AUROC: 0.7870 - AUPRC: 0.4396 - val_loss: 0.3398 - val_AUROC: 0.7652 - val_AUPRC: 0.4277\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 6s 36ms/step - loss: 0.3172 - AUROC: 0.7837 - AUPRC: 0.4399 - val_loss: 0.3439 - val_AUROC: 0.7508 - val_AUPRC: 0.4305\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3122 - AUROC: 0.7912 - AUPRC: 0.4596 - val_loss: 0.3426 - val_AUROC: 0.7545 - val_AUPRC: 0.4345\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3131 - AUROC: 0.7926 - AUPRC: 0.4521 - val_loss: 0.3414 - val_AUROC: 0.7596 - val_AUPRC: 0.4253\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.3145 - AUROC: 0.7892 - AUPRC: 0.4547 - val_loss: 0.3399 - val_AUROC: 0.7618 - val_AUPRC: 0.4346\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3086 - AUROC: 0.8024 - AUPRC: 0.4652 - val_loss: 0.3420 - val_AUROC: 0.7600 - val_AUPRC: 0.4256\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3110 - AUROC: 0.7984 - AUPRC: 0.4547 - val_loss: 0.3400 - val_AUROC: 0.7647 - val_AUPRC: 0.4374\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3071 - AUROC: 0.8042 - AUPRC: 0.4689 - val_loss: 0.3432 - val_AUROC: 0.7578 - val_AUPRC: 0.4249\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3076 - AUROC: 0.8065 - AUPRC: 0.4553 - val_loss: 0.3428 - val_AUROC: 0.7537 - val_AUPRC: 0.4343\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 7s 43ms/step - loss: 0.3067 - AUROC: 0.8027 - AUPRC: 0.4750 - val_loss: 0.3536 - val_AUROC: 0.7466 - val_AUPRC: 0.4077\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 7s 42ms/step - loss: 0.3061 - AUROC: 0.8070 - AUPRC: 0.4677 - val_loss: 0.3441 - val_AUROC: 0.7539 - val_AUPRC: 0.4229\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3033 - AUROC: 0.8129 - AUPRC: 0.4874 - val_loss: 0.3434 - val_AUROC: 0.7547 - val_AUPRC: 0.4344\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.3031 - AUROC: 0.8118 - AUPRC: 0.4892 - val_loss: 0.3439 - val_AUROC: 0.7556 - val_AUPRC: 0.4308\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3020 - AUROC: 0.8123 - AUPRC: 0.4888 - val_loss: 0.3439 - val_AUROC: 0.7544 - val_AUPRC: 0.4249\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3002 - AUROC: 0.8146 - AUPRC: 0.4992 - val_loss: 0.3438 - val_AUROC: 0.7543 - val_AUPRC: 0.4345\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3008 - AUROC: 0.8140 - AUPRC: 0.4983 - val_loss: 0.3434 - val_AUROC: 0.7526 - val_AUPRC: 0.4366\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 6s 39ms/step - loss: 0.3031 - AUROC: 0.8156 - AUPRC: 0.4804 - val_loss: 0.3433 - val_AUROC: 0.7534 - val_AUPRC: 0.4369\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3038 - AUROC: 0.8111 - AUPRC: 0.4798 - val_loss: 0.3435 - val_AUROC: 0.7532 - val_AUPRC: 0.4382\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.2996 - AUROC: 0.8166 - AUPRC: 0.4987 - val_loss: 0.3435 - val_AUROC: 0.7538 - val_AUPRC: 0.4367\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.3020 - AUROC: 0.8139 - AUPRC: 0.4901 - val_loss: 0.3433 - val_AUROC: 0.7546 - val_AUPRC: 0.4403\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3010 - AUROC: 0.8145 - AUPRC: 0.4962 - val_loss: 0.3431 - val_AUROC: 0.7550 - val_AUPRC: 0.4384\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3016 - AUROC: 0.8156 - AUPRC: 0.4887 - val_loss: 0.3420 - val_AUROC: 0.7584 - val_AUPRC: 0.4391\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 6s 37ms/step - loss: 0.2995 - AUROC: 0.8185 - AUPRC: 0.4958 - val_loss: 0.3421 - val_AUROC: 0.7584 - val_AUPRC: 0.4388\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 6s 38ms/step - loss: 0.3006 - AUROC: 0.8153 - AUPRC: 0.4953 - val_loss: 0.3445 - val_AUROC: 0.7516 - val_AUPRC: 0.4326\n",
      "Epoch 14/50\n",
      "164/164 [==============================] - 7s 40ms/step - loss: 0.3010 - AUROC: 0.8165 - AUPRC: 0.4884 - val_loss: 0.3435 - val_AUROC: 0.7550 - val_AUPRC: 0.4336\n",
      "Epoch 15/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.3011 - AUROC: 0.8154 - AUPRC: 0.4897 - val_loss: 0.3423 - val_AUROC: 0.7581 - val_AUPRC: 0.4395\n",
      "Epoch 16/50\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.3035 - AUROC: 0.8116 - AUPRC: 0.4773 - val_loss: 0.3422 - val_AUROC: 0.7588 - val_AUPRC: 0.4394\n",
      "Epoch 17/50\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.3006 - AUROC: 0.8161 - AUPRC: 0.4891 - val_loss: 0.3423 - val_AUROC: 0.7586 - val_AUPRC: 0.4386\n",
      "Epoch 18/50\n",
      "164/164 [==============================] - 8s 50ms/step - loss: 0.2991 - AUROC: 0.8187 - AUPRC: 0.4966 - val_loss: 0.3434 - val_AUROC: 0.7551 - val_AUPRC: 0.4364\n",
      "Epoch 19/50\n",
      "164/164 [==============================] - 8s 48ms/step - loss: 0.3005 - AUROC: 0.8127 - AUPRC: 0.4934 - val_loss: 0.3427 - val_AUROC: 0.7578 - val_AUPRC: 0.4363\n",
      "Epoch 20/50\n",
      "164/164 [==============================] - 8s 46ms/step - loss: 0.2984 - AUROC: 0.8202 - AUPRC: 0.5032 - val_loss: 0.3434 - val_AUROC: 0.7549 - val_AUPRC: 0.4377\n",
      "Epoch 21/50\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.3010 - AUROC: 0.8119 - AUPRC: 0.4939 - val_loss: 0.3434 - val_AUROC: 0.7557 - val_AUPRC: 0.4352\n",
      "Epoch 1/50\n",
      "164/164 [==============================] - 10s 60ms/step - loss: 0.2990 - AUROC: 0.8195 - AUPRC: 0.4990 - val_loss: 0.3434 - val_AUROC: 0.7556 - val_AUPRC: 0.4359\n",
      "Epoch 2/50\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.3016 - AUROC: 0.8147 - AUPRC: 0.4843 - val_loss: 0.3434 - val_AUROC: 0.7564 - val_AUPRC: 0.4355\n",
      "Epoch 3/50\n",
      "164/164 [==============================] - 7s 45ms/step - loss: 0.2964 - AUROC: 0.8230 - AUPRC: 0.5051 - val_loss: 0.3422 - val_AUROC: 0.7589 - val_AUPRC: 0.4399\n",
      "Epoch 4/50\n",
      "164/164 [==============================] - 9s 54ms/step - loss: 0.3003 - AUROC: 0.8164 - AUPRC: 0.4935 - val_loss: 0.3438 - val_AUROC: 0.7550 - val_AUPRC: 0.4342\n",
      "Epoch 5/50\n",
      "164/164 [==============================] - 8s 49ms/step - loss: 0.3010 - AUROC: 0.8132 - AUPRC: 0.4938 - val_loss: 0.3437 - val_AUROC: 0.7552 - val_AUPRC: 0.4343\n",
      "Epoch 6/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3018 - AUROC: 0.8129 - AUPRC: 0.4859 - val_loss: 0.3427 - val_AUROC: 0.7583 - val_AUPRC: 0.4367\n",
      "Epoch 7/50\n",
      "164/164 [==============================] - 9s 54ms/step - loss: 0.2994 - AUROC: 0.8187 - AUPRC: 0.4924 - val_loss: 0.3433 - val_AUROC: 0.7556 - val_AUPRC: 0.4368\n",
      "Epoch 8/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.2992 - AUROC: 0.8194 - AUPRC: 0.4956 - val_loss: 0.3438 - val_AUROC: 0.7556 - val_AUPRC: 0.4343\n",
      "Epoch 9/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3007 - AUROC: 0.8137 - AUPRC: 0.4954 - val_loss: 0.3430 - val_AUROC: 0.7568 - val_AUPRC: 0.4377\n",
      "Epoch 10/50\n",
      "164/164 [==============================] - 7s 43ms/step - loss: 0.2989 - AUROC: 0.8204 - AUPRC: 0.4986 - val_loss: 0.3433 - val_AUROC: 0.7556 - val_AUPRC: 0.4360\n",
      "Epoch 11/50\n",
      "164/164 [==============================] - 7s 44ms/step - loss: 0.3003 - AUROC: 0.8150 - AUPRC: 0.4934 - val_loss: 0.3434 - val_AUROC: 0.7550 - val_AUPRC: 0.4369\n",
      "Epoch 12/50\n",
      "164/164 [==============================] - 7s 43ms/step - loss: 0.2991 - AUROC: 0.8189 - AUPRC: 0.4957 - val_loss: 0.3425 - val_AUROC: 0.7580 - val_AUPRC: 0.4384\n",
      "Epoch 13/50\n",
      "164/164 [==============================] - 7s 41ms/step - loss: 0.2974 - AUROC: 0.8183 - AUPRC: 0.5169 - val_loss: 0.3435 - val_AUROC: 0.7555 - val_AUPRC: 0.4338\n"
     ]
    }
   ],
   "source": [
    "myMetrics = [\n",
    "    keras.metrics.AUC(name='AUROC', curve='ROC'),\n",
    "    keras.metrics.AUC(name='AUPRC', curve='PR')\n",
    "]\n",
    "\n",
    "keras.backend.clear_session()\n",
    "mdl = keras.models.Sequential([\n",
    "    keras.layers.LSTM(32, return_sequences=True, input_shape=list(X_train.shape)[1:4]),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.LSTM(32, return_sequences=False),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "mdl.summary()\n",
    "mdl.compile(loss=\"binary_crossentropy\", optimizer=keras.optimizers.Adam(learning_rate=1e-3), metrics = myMetrics)\n",
    "callback = EarlyStopping(monitor='val_loss', patience=10)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-4)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-5)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])\n",
    "keras.backend.set_value(mdl.optimizer.learning_rate, 1e-6)\n",
    "his = mdl.fit(X_train, Y_train, \n",
    "              epochs=50, \n",
    "              validation_data=(X_valid,Y_valid), callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 72, 32)\n",
      "(6557, 1)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "\n",
    "# fill na by within group median\n",
    "pos_df = whole_df.loc[whole_df['y___pos']==1.0,:].copy()\n",
    "pos_df.fillna(pos_df.median(), inplace=True)\n",
    "neg_df = whole_df.loc[whole_df['y___neg']==1.0,:].copy()\n",
    "neg_df.fillna(neg_df.median(), inplace=True)\n",
    "nbc_df = whole_df.loc[whole_df['y___nbc']==1.0,:].copy()\n",
    "nbc_df.fillna(nbc_df.median(), inplace=True)\n",
    "\n",
    "whole_df.loc[whole_df['y___pos']==1.0,:] = pos_df\n",
    "whole_df.loc[whole_df['y___neg']==1.0,:] = neg_df\n",
    "whole_df.loc[whole_df['y___nbc']==1.0,:] = nbc_df\n",
    "\n",
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos']\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,72,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,1) )[:,0,:]\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 3)\n",
      "-------------------\n",
      "predicted mean 0.41208890080451965, basemean 0.13375019063596158, relative risk 3.0810341192420014\n",
      "predicted mean 0.9337747693061829, basemean 0.3413146255909715, relative risk 2.7358182137357647\n",
      "predicted mean 0.923815131187439, basemean 0.7924355650449901, relative risk 1.1657921122394221\n",
      "-------------------\n",
      "predicted mean 0.41267016530036926, basemean 0.13375019063596158, relative risk 3.0853800158204345\n",
      "predicted mean 0.9337407946586609, basemean 0.3413146255909715, relative risk 2.7357186731799996\n",
      "predicted mean 0.924470841884613, basemean 0.7924355650449901, relative risk 1.1666195747185157\n",
      "-------------------\n",
      "predicted mean 0.41217347979545593, basemean 0.13375019063596158, relative risk 3.0816664846280553\n",
      "predicted mean 0.933950662612915, basemean 0.3413146255909715, relative risk 2.7363335544025396\n",
      "predicted mean 0.9240179061889648, basemean 0.7924355650449901, relative risk 1.166048000554473\n",
      "-------------------\n",
      "predicted mean 0.4110882580280304, basemean 0.13375019063596158, relative risk 3.0735526885858553\n",
      "predicted mean 0.9335946440696716, basemean 0.3413146255909715, relative risk 2.735290474157657\n",
      "predicted mean 0.9238309264183044, basemean 0.7924355650449901, relative risk 1.1658120447507356\n",
      "-------------------\n",
      "predicted mean 0.410897433757782, basemean 0.13375019063596158, relative risk 3.0721259671035077\n",
      "predicted mean 0.9334201812744141, basemean 0.3413146255909715, relative risk 2.734779324672177\n",
      "predicted mean 0.923995316028595, basemean 0.7924355650449901, relative risk 1.1660194933024437\n",
      "-------------------\n",
      "predicted mean 0.4113155007362366, basemean 0.13375019063596158, relative risk 3.075251697066708\n",
      "predicted mean 0.9330402612686157, basemean 0.3413146255909715, relative risk 2.733666216773152\n",
      "predicted mean 0.9239339828491211, basemean 0.7924355650449901, relative risk 1.1659420949849282\n",
      "-------------------\n",
      "predicted mean 0.41326048970222473, basemean 0.13375019063596158, relative risk 3.0897936499173175\n",
      "predicted mean 0.933204174041748, basemean 0.3413146255909715, relative risk 2.7341464562965783\n",
      "predicted mean 0.924405038356781, basemean 0.7924355650449901, relative risk 1.1665365351242134\n",
      "-------------------\n",
      "predicted mean 0.41282305121421814, basemean 0.13375019063596158, relative risk 3.0865230864442736\n",
      "predicted mean 0.93362957239151, basemean 0.3413146255909715, relative risk 2.735392808834286\n",
      "predicted mean 0.9239068627357483, basemean 0.7924355650449901, relative risk 1.165907871239088\n",
      "-------------------\n",
      "predicted mean 0.4127204120159149, basemean 0.13375019063596158, relative risk 3.0857556916628894\n",
      "predicted mean 0.9337723851203918, basemean 0.3413146255909715, relative risk 2.735811228433606\n",
      "predicted mean 0.9239294528961182, basemean 0.7924355650449901, relative risk 1.1659363784911174\n",
      "-------------------\n",
      "predicted mean 0.41351041197776794, basemean 0.13375019063596158, relative risk 3.091662225015079\n",
      "predicted mean 0.9337597489356995, basemean 0.3413146255909715, relative risk 2.7357742063321635\n",
      "predicted mean 0.9239422082901001, basemean 0.7924355650449901, relative risk 1.1659524749342158\n",
      "-------------------\n",
      "predicted mean 0.4124228358268738, basemean 0.13375019063596158, relative risk 3.0835308261309136\n",
      "predicted mean 0.9341281652450562, basemean 0.3413146255909715, relative risk 2.7368536101482723\n",
      "predicted mean 0.9234455823898315, basemean 0.7924355650449901, relative risk 1.16532576669171\n",
      "-------------------\n",
      "predicted mean 0.41502347588539124, basemean 0.13375019063596158, relative risk 3.102974836237754\n",
      "predicted mean 0.9338122606277466, basemean 0.3413146255909715, relative risk 2.7359280576122136\n",
      "predicted mean 0.923466145992279, basemean 0.7924355650449901, relative risk 1.1653517165649294\n",
      "-------------------\n",
      "predicted mean 0.4151815176010132, basemean 0.13375019063596158, relative risk 3.1041564548572897\n",
      "predicted mean 0.933708131313324, basemean 0.3413146255909715, relative risk 2.7356229745404224\n",
      "predicted mean 0.9246624112129211, basemean 0.7924355650449901, relative risk 1.1668613222330877\n",
      "-------------------\n",
      "predicted mean 0.41577085852622986, basemean 0.13375019063596158, relative risk 3.1085627358682886\n",
      "predicted mean 0.9337577819824219, basemean 0.3413146255909715, relative risk 2.735768443457882\n",
      "predicted mean 0.9237556457519531, basemean 0.7924355650449901, relative risk 1.165717045649645\n",
      "-------------------\n",
      "predicted mean 0.4140017330646515, basemean 0.13375019063596158, relative risk 3.095335648466271\n",
      "predicted mean 0.9336578249931335, basemean 0.3413146255909715, relative risk 2.735475584664869\n",
      "predicted mean 0.9238111972808838, basemean 0.7924355650449901, relative risk 1.1657871479158497\n",
      "-------------------\n",
      "predicted mean 0.4150654971599579, basemean 0.13375019063596158, relative risk 3.1032890135437214\n",
      "predicted mean 0.9337506890296936, basemean 0.3413146255909715, relative risk 2.735747662183959\n",
      "predicted mean 0.9236788749694824, basemean 0.7924355650449901, relative risk 1.1656201661229593\n",
      "-------------------\n",
      "predicted mean 0.4144863784313202, basemean 0.13375019063596158, relative risk 3.098959160061763\n",
      "predicted mean 0.933824360370636, basemean 0.3413146255909715, relative risk 2.7359635080206703\n",
      "predicted mean 0.9240669012069702, basemean 0.7924355650449901, relative risk 1.166109828948057\n",
      "-------------------\n",
      "predicted mean 0.41549211740493774, basemean 0.13375019063596158, relative risk 3.106478693072037\n",
      "predicted mean 0.9333981275558472, basemean 0.3413146255909715, relative risk 2.734714710627207\n",
      "predicted mean 0.9253869652748108, basemean 0.7924355650449901, relative risk 1.1677756603746987\n",
      "-------------------\n",
      "predicted mean 0.4162162244319916, basemean 0.13375019063596158, relative risk 3.1118925696699753\n",
      "predicted mean 0.9332890510559082, basemean 0.3413146255909715, relative risk 2.734395133053436\n",
      "predicted mean 0.9257206320762634, basemean 0.7924355650449901, relative risk 1.1681967252740684\n",
      "-------------------\n",
      "predicted mean 0.41678687930107117, basemean 0.13375019063596158, relative risk 3.1161591420491717\n",
      "predicted mean 0.9332637190818787, basemean 0.3413146255909715, relative risk 2.7343209142179976\n",
      "predicted mean 0.9256442785263062, basemean 0.7924355650449901, relative risk 1.168100372266549\n",
      "-------------------\n",
      "predicted mean 0.4164894223213196, basemean 0.13375019063596158, relative risk 3.1139351678003333\n",
      "predicted mean 0.9330959916114807, basemean 0.3413146255909715, relative risk 2.733829498211117\n",
      "predicted mean 0.9260806441307068, basemean 0.7924355650449901, relative risk 1.1686510360979685\n",
      "-------------------\n",
      "predicted mean 0.4186299741268158, basemean 0.13375019063596158, relative risk 3.1299392706380056\n",
      "predicted mean 0.93277907371521, basemean 0.3413146255909715, relative risk 2.732900976921641\n",
      "predicted mean 0.9256232380867004, basemean 0.7924355650449901, relative risk 1.168073820657139\n",
      "-------------------\n",
      "predicted mean 0.42054057121276855, basemean 0.13375019063596158, relative risk 3.144224088303447\n",
      "predicted mean 0.9328903555870056, basemean 0.3413146255909715, relative risk 2.733227015899909\n",
      "predicted mean 0.9260501265525818, basemean 0.7924355650449901, relative risk 1.1686125249817703\n",
      "-------------------\n",
      "predicted mean 0.4231216609477997, basemean 0.13375019063596158, relative risk 3.163521927975738\n",
      "predicted mean 0.9108695387840271, basemean 0.3413146255909715, relative risk 2.6687093680995826\n",
      "predicted mean 0.8757962584495544, basemean 0.7924355650449901, relative risk 1.105195547854836\n",
      "-------------------\n",
      "predicted mean 0.42514845728874207, basemean 0.13375019063596158, relative risk 3.178675523879454\n",
      "predicted mean 0.8751243352890015, basemean 0.3413146255909715, relative risk 2.563981352319027\n",
      "predicted mean 0.781239926815033, basemean 0.7924355650449901, relative risk 0.9858718629957989\n",
      "-------------------\n",
      "predicted mean 0.42681118845939636, basemean 0.13375019063596158, relative risk 3.191107141081256\n",
      "predicted mean 0.8444012999534607, basemean 0.3413146255909715, relative risk 2.473967526271154\n",
      "predicted mean 0.7442717552185059, basemean 0.7924355650449901, relative risk 0.9392205348282799\n",
      "-------------------\n",
      "predicted mean 0.43169328570365906, basemean 0.13375019063596158, relative risk 3.22760875069429\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean 0.81401127576828, basemean 0.3413146255909715, relative risk 2.384929372302329\n",
      "predicted mean 0.7319506406784058, basemean 0.7924355650449901, relative risk 0.9236721229654169\n",
      "-------------------\n",
      "predicted mean 0.447384238243103, basemean 0.13375019063596158, relative risk 3.344924116488057\n",
      "predicted mean 0.7489262223243713, basemean 0.3413146255909715, relative risk 2.1942400535214044\n",
      "predicted mean 0.7187636494636536, basemean 0.7924355650449901, relative risk 0.9070310333974549\n",
      "-------------------\n",
      "predicted mean 0.46133145689964294, basemean 0.13375019063596158, relative risk 3.4492022381880942\n",
      "predicted mean 0.6669188737869263, basemean 0.3413146255909715, relative risk 1.9539709809744752\n",
      "predicted mean 0.7120497822761536, basemean 0.7924355650449901, relative risk 0.8985585878338604\n",
      "-------------------\n",
      "predicted mean 0.47029978036880493, basemean 0.13375019063596158, relative risk 3.51625502836745\n",
      "predicted mean 0.6306047439575195, basemean 0.3413146255909715, relative risk 1.8475760974662447\n",
      "predicted mean 0.7071627378463745, basemean 0.7924355650449901, relative risk 0.8923914688334637\n",
      "-------------------\n",
      "predicted mean 0.4706774353981018, basemean 0.13375019063596158, relative risk 3.519078613347039\n",
      "predicted mean 0.618859589099884, basemean 0.3413146255909715, relative risk 1.8131645780732528\n",
      "predicted mean 0.7028873562812805, basemean 0.7924355650449901, relative risk 0.8869962269315543\n",
      "-------------------\n",
      "predicted mean 0.4696342349052429, basemean 0.13375019063596158, relative risk 3.511278994610807\n",
      "predicted mean 0.6137164235115051, basemean 0.3413146255909715, relative risk 1.798095884256005\n",
      "predicted mean 0.6970537304878235, basemean 0.7924355650449901, relative risk 0.8796345863758003\n",
      "-------------------\n",
      "predicted mean 0.46829935908317566, basemean 0.13375019063596158, relative risk 3.5012986288579047\n",
      "predicted mean 0.6111693978309631, basemean 0.3413146255909715, relative risk 1.790633485959618\n",
      "predicted mean 0.6906002163887024, basemean 0.7924355650449901, relative risk 0.8714906887722712\n",
      "-------------------\n",
      "predicted mean 0.468607634305954, basemean 0.13375019063596158, relative risk 3.5036034870514707\n",
      "predicted mean 0.6086625456809998, basemean 0.3413146255909715, relative risk 1.7832887900046093\n",
      "predicted mean 0.6867038607597351, basemean 0.7924355650449901, relative risk 0.866573751924862\n",
      "-------------------\n",
      "predicted mean 0.46823081374168396, basemean 0.13375019063596158, relative risk 3.5007861410538443\n",
      "predicted mean 0.6071155071258545, basemean 0.3413146255909715, relative risk 1.7787562020662324\n",
      "predicted mean 0.6831095218658447, basemean 0.7924355650449901, relative risk 0.8620379397371716\n",
      "-------------------\n",
      "predicted mean 0.47065678238868713, basemean 0.13375019063596158, relative risk 3.5189241985434676\n",
      "predicted mean 0.613156259059906, basemean 0.3413146255909715, relative risk 1.796454687513764\n",
      "predicted mean 0.6935778856277466, basemean 0.7924355650449901, relative risk 0.875248305631473\n",
      "-------------------\n",
      "predicted mean 0.4714573323726654, basemean 0.13375019063596158, relative risk 3.5249096104533257\n",
      "predicted mean 0.6133018732070923, basemean 0.3413146255909715, relative risk 1.7968813148431206\n",
      "predicted mean 0.6913572549819946, basemean 0.7924355650449901, relative risk 0.8724460201918666\n",
      "-------------------\n",
      "predicted mean 0.47267910838127136, basemean 0.13375019063596158, relative risk 3.534044371329528\n",
      "predicted mean 0.6136389374732971, basemean 0.3413146255909715, relative risk 1.7978688619358396\n",
      "predicted mean 0.6869301199913025, basemean 0.7924355650449901, relative risk 0.8668592757472999\n",
      "-------------------\n",
      "predicted mean 0.47253862023353577, basemean 0.13375019063596158, relative risk 3.532993994151988\n",
      "predicted mean 0.615047037601471, basemean 0.3413146255909715, relative risk 1.801994381390905\n",
      "predicted mean 0.6858425140380859, basemean 0.7924355650449901, relative risk 0.8654867907135737\n",
      "-------------------\n",
      "predicted mean 0.47309747338294983, basemean 0.13375019063596158, relative risk 3.537172329500572\n",
      "predicted mean 0.6170408725738525, basemean 0.3413146255909715, relative risk 1.8078360149538655\n",
      "predicted mean 0.683898389339447, basemean 0.7924355650449901, relative risk 0.8630334370474892\n",
      "-------------------\n",
      "predicted mean 0.47236889600753784, basemean 0.13375019063596158, relative risk 3.5317250297849774\n",
      "predicted mean 0.6178730726242065, basemean 0.3413146255909715, relative risk 1.8102742346724408\n",
      "predicted mean 0.6808688640594482, basemean 0.7924355650449901, relative risk 0.85921038137756\n",
      "-------------------\n",
      "predicted mean 0.47320207953453064, basemean 0.13375019063596158, relative risk 3.537954430453725\n",
      "predicted mean 0.6167921423912048, basemean 0.3413146255909715, relative risk 1.807107273306135\n",
      "predicted mean 0.6786863803863525, basemean 0.7924355650449901, relative risk 0.8564562348332012\n",
      "-------------------\n",
      "predicted mean 0.47484898567199707, basemean 0.13375019063596158, relative risk 3.5502677298190246\n",
      "predicted mean 0.6158089637756348, basemean 0.3413146255909715, relative risk 1.8042267093283455\n",
      "predicted mean 0.6785815358161926, basemean 0.7924355650449901, relative risk 0.8563239280882938\n",
      "-------------------\n",
      "predicted mean 0.47564759850502014, basemean 0.13375019063596158, relative risk 3.5562386583778984\n",
      "predicted mean 0.6146531701087952, basemean 0.3413146255909715, relative risk 1.8008404094742494\n",
      "predicted mean 0.6761311292648315, basemean 0.7924355650449901, relative risk 0.8532316810218438\n",
      "-------------------\n",
      "predicted mean 0.4760062098503113, basemean 0.13375019063596158, relative risk 3.5589198608762724\n",
      "predicted mean 0.6139363646507263, basemean 0.3413146255909715, relative risk 1.7987402783801665\n",
      "predicted mean 0.6733236312866211, basemean 0.7924355650449901, relative risk 0.849688808765661\n",
      "-------------------\n",
      "predicted mean 0.47572681307792664, basemean 0.13375019063596158, relative risk 3.556830916022765\n",
      "predicted mean 0.613165020942688, basemean 0.3413146255909715, relative risk 1.796480358499198\n",
      "predicted mean 0.6727655529975891, basemean 0.7924355650449901, relative risk 0.8489845517715919\n",
      "-------------------\n",
      "predicted mean 0.4772856533527374, basemean 0.13375019063596158, relative risk 3.5684857799702385\n",
      "predicted mean 0.6125845909118652, basemean 0.3413146255909715, relative risk 1.7947797866886062\n",
      "predicted mean 0.6707537770271301, basemean 0.7924355650449901, relative risk 0.8464458267834665\n",
      "-------------------\n",
      "predicted mean 0.4795750081539154, basemean 0.13375019063596158, relative risk 3.5856024269842908\n",
      "predicted mean 0.6117454171180725, basemean 0.3413146255909715, relative risk 1.792321134961216\n",
      "predicted mean 0.6698522567749023, basemean 0.7924355650449901, relative risk 0.8453081692981206\n",
      "-------------------\n",
      "predicted mean 0.48265597224235535, basemean 0.13375019063596158, relative risk 3.608637639672889\n",
      "predicted mean 0.6111024022102356, basemean 0.3413146255909715, relative risk 1.790437198968952\n",
      "predicted mean 0.6675630807876587, basemean 0.7924355650449901, relative risk 0.8424193842811158\n",
      "-------------------\n",
      "predicted mean 0.4842626452445984, basemean 0.13375019063596158, relative risk 3.6206501309792833\n",
      "predicted mean 0.6108825206756592, basemean 0.3413146255909715, relative risk 1.7897929794773446\n",
      "predicted mean 0.6633320450782776, basemean 0.7924355650449901, relative risk 0.8370801038449318\n",
      "-------------------\n",
      "predicted mean 0.4827505350112915, basemean 0.13375019063596158, relative risk 3.609344650021708\n",
      "predicted mean 0.6113384366035461, basemean 0.3413146255909715, relative risk 1.7911287438826864\n",
      "predicted mean 0.6599915027618408, basemean 0.7924355650449901, relative risk 0.8328645657446863\n",
      "-------------------\n",
      "predicted mean 0.4836306571960449, basemean 0.13375019063596158, relative risk 3.6159249934258453\n",
      "predicted mean 0.6090097427368164, basemean 0.3413146255909715, relative risk 1.7843060246315037\n",
      "predicted mean 0.6593191027641296, basemean 0.7924355650449901, relative risk 0.8320160424989218\n",
      "-------------------\n",
      "predicted mean 0.48936226963996887, basemean 0.13375019063596158, relative risk 3.658778109497464\n",
      "predicted mean 0.6061765551567078, basemean 0.3413146255909715, relative risk 1.776005215443491\n",
      "predicted mean 0.6598901152610779, basemean 0.7924355650449901, relative risk 0.8327366215871608\n",
      "-------------------\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted mean 0.49149787425994873, basemean 0.13375019063596158, relative risk 3.67474522408493\n",
      "predicted mean 0.6041426062583923, basemean 0.3413146255909715, relative risk 1.7700460541717062\n",
      "predicted mean 0.6590443253517151, basemean 0.7924355650449901, relative risk 0.8316692920190908\n",
      "-------------------\n",
      "predicted mean 0.49363258481025696, basemean 0.13375019063596158, relative risk 3.690705654048865\n",
      "predicted mean 0.602493166923523, basemean 0.3413146255909715, relative risk 1.7652134475056032\n",
      "predicted mean 0.6581664681434631, basemean 0.7924355650449901, relative risk 0.8305614956922032\n",
      "-------------------\n",
      "predicted mean 0.49520131945610046, basemean 0.13375019063596158, relative risk 3.702434494496751\n",
      "predicted mean 0.6014642715454102, basemean 0.3413146255909715, relative risk 1.7621989403589162\n",
      "predicted mean 0.6572375297546387, basemean 0.7924355650449901, relative risk 0.829389238375898\n",
      "-------------------\n",
      "predicted mean 0.4984905421733856, basemean 0.13375019063596158, relative risk 3.7270267788265556\n",
      "predicted mean 0.5992435216903687, basemean 0.3413146255909715, relative risk 1.7556924806629792\n",
      "predicted mean 0.6557064056396484, basemean 0.7924355650449901, relative risk 0.8274570634678935\n",
      "-------------------\n",
      "predicted mean 0.4989994168281555, basemean 0.13375019063596158, relative risk 3.730831443719744\n",
      "predicted mean 0.5976485013961792, basemean 0.3413146255909715, relative risk 1.7510193135186538\n",
      "predicted mean 0.6535346508026123, basemean 0.7924355650449901, relative risk 0.8247164559878231\n",
      "-------------------\n",
      "predicted mean 0.4981924295425415, basemean 0.13375019063596158, relative risk 3.724797902520461\n",
      "predicted mean 0.5969176888465881, basemean 0.3413146255909715, relative risk 1.7488781437743872\n",
      "predicted mean 0.6539943814277649, basemean 0.7924355650449901, relative risk 0.8252966048925816\n",
      "-------------------\n",
      "predicted mean 0.49753621220588684, basemean 0.13375019063596158, relative risk 3.719891611669327\n",
      "predicted mean 0.595892608165741, basemean 0.3413146255909715, relative risk 1.7458748131111543\n",
      "predicted mean 0.6496739387512207, basemean 0.7924355650449901, relative risk 0.8198444989206609\n",
      "-------------------\n",
      "predicted mean 0.5012481212615967, basemean 0.13375019063596158, relative risk 3.74764416318391\n",
      "predicted mean 0.5954641699790955, basemean 0.3413146255909715, relative risk 1.7446195543131944\n",
      "predicted mean 0.65362149477005, basemean 0.7924355650449901, relative risk 0.8248260471915354\n",
      "-------------------\n",
      "predicted mean 0.49616023898124695, basemean 0.13375019063596158, relative risk 3.709603976054773\n",
      "predicted mean 0.5954279899597168, basemean 0.3413146255909715, relative risk 1.7445135523529325\n",
      "predicted mean 0.6490914225578308, basemean 0.7924355650449901, relative risk 0.8191094029468238\n",
      "-------------------\n",
      "predicted mean 0.4970177114009857, basemean 0.13375019063596158, relative risk 3.7160149756627856\n",
      "predicted mean 0.5975267887115479, basemean 0.3413146255909715, relative risk 1.7506627138434403\n",
      "predicted mean 0.6478768587112427, basemean 0.7924355650449901, relative risk 0.8175767056523514\n",
      "-------------------\n",
      "predicted mean 0.4954661428928375, basemean 0.13375019063596158, relative risk 3.7044144799866996\n",
      "predicted mean 0.5965033769607544, basemean 0.3413146255909715, relative risk 1.7476642728917189\n",
      "predicted mean 0.6487040519714355, basemean 0.7924355650449901, relative risk 0.8186205675089882\n",
      "-------------------\n",
      "predicted mean 0.4970618784427643, basemean 0.13375019063596158, relative risk 3.716345196065228\n",
      "predicted mean 0.5986438989639282, basemean 0.3413146255909715, relative risk 1.7539356771700079\n",
      "predicted mean 0.648640513420105, basemean 0.7924355650449901, relative risk 0.8185403861615912\n",
      "-------------------\n",
      "predicted mean 0.4979831576347351, basemean 0.13375019063596158, relative risk 3.7232332549725857\n",
      "predicted mean 0.5987491607666016, basemean 0.3413146255909715, relative risk 1.7542440782603246\n",
      "predicted mean 0.648052453994751, basemean 0.7924355650449901, relative risk 0.8177982950045385\n",
      "-------------------\n",
      "predicted mean 0.4980442225933075, basemean 0.13375019063596158, relative risk 3.7236898147597683\n",
      "predicted mean 0.5989000797271729, basemean 0.3413146255909715, relative risk 1.754686247886985\n",
      "predicted mean 0.6476399898529053, basemean 0.7924355650449901, relative risk 0.8172777931996728\n",
      "-------------------\n",
      "predicted mean 0.49981093406677246, basemean 0.13375019063596158, relative risk 3.7368988536782517\n",
      "predicted mean 0.6005970239639282, basemean 0.3413146255909715, relative risk 1.7596580366986048\n",
      "predicted mean 0.6479036211967468, basemean 0.7924355650449901, relative risk 0.8176104780960486\n",
      "-------------------\n",
      "predicted mean 0.5003508925437927, basemean 0.13375019063596158, relative risk 3.7409359206495423\n",
      "predicted mean 0.5989460349082947, basemean 0.3413146255909715, relative risk 1.7548208895860984\n",
      "predicted mean 0.6483115553855896, basemean 0.7924355650449901, relative risk 0.8181252634071037\n",
      "-------------------\n",
      "predicted mean 0.501213550567627, basemean 0.13375019063596158, relative risk 3.747385691074036\n",
      "predicted mean 0.6015515327453613, basemean 0.3413146255909715, relative risk 1.762454602417933\n",
      "predicted mean 0.6533509492874146, basemean 0.7924355650449901, relative risk 0.8244846371203959\n",
      "-------------------\n",
      "predicted mean 0.4981987178325653, basemean 0.13375019063596158, relative risk 3.724844917705964\n",
      "predicted mean 0.6014568209648132, basemean 0.3413146255909715, relative risk 1.7621771112896696\n",
      "predicted mean 0.651577889919281, basemean 0.7924355650449901, relative risk 0.8222471563126877\n"
     ]
    }
   ],
   "source": [
    "# reformat outcome columns into 3 categories\n",
    "output_var = ['y___pos','y___neg','y___nbc']\n",
    "\n",
    "\n",
    "Y_whole = whole_df[output_var].values\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,3) )[:,0,:]\n",
    "print(Y_whole.shape)\n",
    "\n",
    "\n",
    "pos_index = np.where(Y_whole[:,0]==1.0)[0]\n",
    "neg_index = np.where(Y_whole[:,1]==1.0)[0]\n",
    "nbc_index = np.where(Y_whole[:,2]==1.0)[0]\n",
    "\n",
    "\n",
    "\n",
    "x = X_whole[pos_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_pos = mdl.predict(X_new)\n",
    "x = X_whole[neg_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_neg = mdl.predict(X_new)\n",
    "x = X_whole[nbc_index,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_nbc = mdl.predict(X_new)\n",
    "\n",
    "for i in range(1,X_whole.shape[1]):\n",
    "    print(\"-------------------\")\n",
    "    # postive\n",
    "    x = X_whole[pos_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(Y_whole[:,0])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(y), basemean, np.mean(y)/basemean))\n",
    "    y_pos = np.column_stack((y_pos,y))\n",
    "    # negative\n",
    "    x = X_whole[neg_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(1-Y_whole[:,1])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(1-y), basemean, np.mean(1-y)/basemean))\n",
    "    y_neg = np.column_stack((y_neg,y))\n",
    "    # no blood culture\n",
    "    x = X_whole[nbc_index,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y = mdl.predict(X_new)\n",
    "    basemean = np.mean(1-Y_whole[:,2])\n",
    "    print(\"predicted mean {}, basemean {}, relative risk {}\".format(np.mean(1-y), basemean, np.mean(1-y)/basemean))\n",
    "    y_nbc = np.column_stack((y_nbc,y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     y_prob  time    y_true      risk\n",
      "0  0.336653   -48  positive  2.517027\n",
      "1  0.336653   -47  positive  2.517027\n",
      "2  0.336653   -46  positive  2.517027\n",
      "3  0.336653   -45  positive  2.517027\n",
      "4  0.336653   -44  positive  2.517027\n",
      "(63144, 4)\n",
      "     y_prob  time    y_true      risk\n",
      "0  0.034173   -48  negative  2.829726\n",
      "1  0.034173   -47  negative  2.829726\n",
      "2  0.034173   -46  negative  2.829726\n",
      "3  0.034173   -45  negative  2.829726\n",
      "4  0.034173   -44  negative  2.829726\n",
      "(310968, 4)\n",
      "     y_prob  time    y_true      risk\n",
      "0  0.032376   -48  baseline  1.221076\n",
      "1  0.032376   -47  baseline  1.221076\n",
      "2  0.032376   -46  baseline  1.221076\n",
      "3  0.032376   -45  baseline  1.221076\n",
      "4  0.032376   -44  baseline  1.221076\n",
      "(97992, 4)\n"
     ]
    }
   ],
   "source": [
    "df_pos = pd.DataFrame(data={'y_prob': y_pos.reshape([-1]), 'time': list(range(-48,24))*y_pos.shape[0]})\n",
    "df_pos['y_true'] = 'positive'\n",
    "df_pos['risk'] = df_pos['y_prob']/np.mean(Y_whole[:,0])\n",
    "print(df_pos.head(5))\n",
    "print(df_pos.shape)\n",
    "df_neg = pd.DataFrame(data={'y_prob': y_neg.reshape([-1]), 'time': list(range(-48,24))*y_neg.shape[0]})\n",
    "df_neg['y_true'] = 'negative'\n",
    "df_neg['risk'] = (1-df_neg['y_prob'])/np.mean(1-Y_whole[:,1])\n",
    "print(df_neg.head(5))\n",
    "print(df_neg.shape)\n",
    "df_nbc = pd.DataFrame(data={'y_prob': y_nbc.reshape([-1]), 'time': list(range(-48,24))*y_nbc.shape[0]})\n",
    "df_nbc['y_true'] = 'baseline'\n",
    "df_nbc['risk'] = (1-df_nbc['y_prob'])/np.mean(1-Y_whole[:,2])\n",
    "print(df_nbc.head(5))\n",
    "print(df_nbc.shape)\n",
    "df_res = pd.concat([df_pos,df_neg,df_nbc], axis=0)\n",
    "df_res.to_csv(\"./tte_plot_3class_raw.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df_res = pd.read_csv(\"./tte_plot_3class_raw.csv\")\n",
    "plt.figure(figsize=(10,6))\n",
    "sns.lineplot(data=df_res, x=\"time\", y=\"risk\", hue=\"y_true\", palette=['red','orange', 'blue']);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# performance over time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6557, 72, 32)\n",
      "(6557, 1)\n"
     ]
    }
   ],
   "source": [
    "train_df = pd.read_csv(\"./train_df.csv\")\n",
    "valid_df = pd.read_csv(\"./valid_df.csv\")\n",
    "whole_df = pd.concat([train_df, valid_df], axis=0)\n",
    "# median imputation\n",
    "train_df.fillna(whole_df.median(), inplace=True)\n",
    "valid_df.fillna(whole_df.median(), inplace=True)\n",
    "whole_df.fillna(whole_df.median(), inplace=True)\n",
    "\n",
    "input_vars = ['txp___yes', 'age___vital', 'temp___vital', 'heart_rate___vital', 'resp_rate___vital', 'spo2___vital', 'x_hr_rr___vital', 's_hr___vital', 's_rr___vital', 's_so2___vital', 'systolic_blood_pressure___vital', 'diastolic_blood_pressure___vital', 'glucose___vital', 'bilirubin___vital', 'potassium___vital', 'albumin___vital', 'calcium___vital', 'sodium___vital', 'wbc___vital', 'phosphorus___vital', 'creatinine___vital', 'platelet_count___vital', 'alt___vital', 'alp___vital', 'ast___vital', 'pco2___vital', 'chloride___vital', 'troponin___vital', 'ptt___vital', 'lactate___vital', 'bun___vital', 'magnesium___vital']\n",
    "output_var = ['y___pos']\n",
    "\n",
    "# reformat inputs to be 2d image and 1 output per image\n",
    "X_whole = whole_df[input_vars].values\n",
    "Y_whole = whole_df[output_var].values\n",
    "X_whole = np.reshape(X_whole, (-1,72,32) )\n",
    "Y_whole = np.reshape(Y_whole, (-1,72,1) )[:,0,:]\n",
    "print(X_whole.shape)\n",
    "print(Y_whole.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n",
      "-------------------\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "score_list = list()\n",
    "y_true = Y_whole[:,0]\n",
    "x = X_whole[:,0,:]\n",
    "X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "y_pred = mdl.predict(X_new)\n",
    "score = sklearn.metrics.roc_auc_score(y_true, y_pred)\n",
    "score_list.append(score)\n",
    "\n",
    "for i in range(1,X_whole.shape[1]):\n",
    "    print(\"-------------------\")\n",
    "    # postive\n",
    "    x = X_whole[:,i,:]\n",
    "    X_new = np.repeat(x[:, np.newaxis, :], 72, axis=1)\n",
    "    y_pred = mdl.predict(X_new)\n",
    "    score=sklearn.metrics.roc_auc_score(y_true, y_pred)\n",
    "    score_list.append(score)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa6af2d9310>]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_res = pd.read_csv(\"./tte_plot.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>y_prob</th>\n",
       "      <th>time</th>\n",
       "      <th>y_true</th>\n",
       "      <th>risk</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-48</td>\n",
       "      <td>event</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-47</td>\n",
       "      <td>event</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-46</td>\n",
       "      <td>event</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-45</td>\n",
       "      <td>event</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.005454</td>\n",
       "      <td>-44</td>\n",
       "      <td>event</td>\n",
       "      <td>0.040777</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472099</td>\n",
       "      <td>0.517914</td>\n",
       "      <td>19</td>\n",
       "      <td>control</td>\n",
       "      <td>3.872245</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472100</td>\n",
       "      <td>0.479352</td>\n",
       "      <td>20</td>\n",
       "      <td>control</td>\n",
       "      <td>3.583938</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472101</td>\n",
       "      <td>0.442411</td>\n",
       "      <td>21</td>\n",
       "      <td>control</td>\n",
       "      <td>3.307738</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472102</td>\n",
       "      <td>0.494195</td>\n",
       "      <td>22</td>\n",
       "      <td>control</td>\n",
       "      <td>3.694911</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>472103</td>\n",
       "      <td>0.010263</td>\n",
       "      <td>23</td>\n",
       "      <td>control</td>\n",
       "      <td>0.076735</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>472104 rows  5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          y_prob  time   y_true      risk  y\n",
       "0       0.005454   -48    event  0.040777  1\n",
       "1       0.005454   -47    event  0.040777  1\n",
       "2       0.005454   -46    event  0.040777  1\n",
       "3       0.005454   -45    event  0.040777  1\n",
       "4       0.005454   -44    event  0.040777  1\n",
       "...          ...   ...      ...       ... ..\n",
       "472099  0.517914    19  control  3.872245  0\n",
       "472100  0.479352    20  control  3.583938  0\n",
       "472101  0.442411    21  control  3.307738  0\n",
       "472102  0.494195    22  control  3.694911  0\n",
       "472103  0.010263    23  control  0.076735  0\n",
       "\n",
       "[472104 rows x 5 columns]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_res['y'] = 0\n",
    "df_res.loc[df_res['y_true']=='event','y'] = 1\n",
    "df_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_list = list()\n",
    "for i in range(-48,24,1):\n",
    "    y_true = df_res.loc[df_res['time']==i, 'y']\n",
    "    y_pred = df_res.loc[df_res['time']==i, 'y_prob']\n",
    "    score=sklearn.metrics.roc_auc_score(y_true, y_pred)\n",
    "    score_list.append(score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fa7be3cc190>]"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(score_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
